{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main-run-rgb.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y1PXD2NL4Nxf","colab_type":"text"},"source":["**Install requirements**"]},{"cell_type":"code","metadata":{"id":"HjRb9K14hW_l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593361217539,"user_tz":-120,"elapsed":5519,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"8e4be98a-4b27-490e-89f9-11c2646336a4"},"source":["#!pip3 install 'torch==0.3.1'\n","!pip3 install 'tensorboardX' "],"execution_count":2,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jBdMq5aF4YHP","colab_type":"text"},"source":["**Import Google Drive**"]},{"cell_type":"code","metadata":{"id":"4Db3Jwa4tG-q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593361217544,"user_tz":-120,"elapsed":4492,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"78e48de5-c44f-4c5f-8e4b-1733ab42cd03"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","\n","path = 'drive/My Drive/ego-rnn/'\n","os.chdir(path)\n","cwd = os.getcwd()\n","print(\"Current dir: \"+cwd)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Current dir: /content/drive/My Drive/ego-rnn\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KhQZjOdN4Unu","colab_type":"text"},"source":["**Import libraries**"]},{"cell_type":"code","metadata":{"id":"t3mf6kG2OBPO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593361217545,"user_tz":-120,"elapsed":3263,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["from __future__ import print_function, division\n","#from objectAttentionModelConvLSTM import *\n","from objectModelConvLSTM import *\n","from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n","                                RandomHorizontalFlip)\n","from tensorboardX import SummaryWriter\n","from makeDatasetRGB import *\n","\n","import argparse\n","import sys\n","import matplotlib.pyplot as plt"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6NIyeyZDWOM","colab_type":"text"},"source":["**Set Arguments**"]},{"cell_type":"code","metadata":{"id":"wV7T6n-Iqecv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593361217546,"user_tz":-120,"elapsed":1301,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["data_dir = \"GTEA61/processed_frames2\"\n","user_train = ['S1','S3','S4']\n","user_val = ['S2']\n","out_dir = 'experiments'\n","trainBatchSize = 32\n","valBatchSize = 64\n","memSize = 512\n","num_classes = 61\n","\n","frame = 7\n","seqLen = frame\n"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"05aii3lCDt_4","colab_type":"text"},"source":["**Prepare Dataset and Dataloader**"]},{"cell_type":"code","metadata":{"id":"wzBtJm6BsiHA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593361219318,"user_tz":-120,"elapsed":1537,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"6038788e-3fb2-4c10-e022-a8854de55aba"},"source":["# Data loader\n","normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224),\n","                              ToTensor(), normalize])\n","\n","vid_seq_train = makeDataset(data_dir, user_train, frame,\n","                            spatial_transform=spatial_transform, seqLen=seqLen, fmt='.png')\n","\n","train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n","                        shuffle=True, num_workers=4, pin_memory=True)\n","\n","\n","vid_seq_val = makeDataset(data_dir, user_val, frame,\n","                            spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n","                            seqLen=seqLen, fmt='.png')\n","\n","val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize,\n","                        shuffle=False, num_workers=2, pin_memory=True)\n","\n","\n","valInstances = vid_seq_val.__len__()\n","trainInstances = vid_seq_train.__len__()\n","\n","print('Number of samples in the dataset: training = {} | validation = {}'.format(trainInstances, valInstances))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Number of samples in the dataset: training = 336 | validation = 116\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SDySVP823BzL","colab_type":"text"},"source":["**Stage 1**"]},{"cell_type":"markdown","metadata":{"id":"iQsOS2Ud4iXR","colab_type":"text"},"source":["**Set Parameters**"]},{"cell_type":"code","metadata":{"id":"it3Mrum47Uvm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593359458288,"user_tz":-120,"elapsed":5199,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["numEpochs = 200\n","lr1 = 1e-3\n","decay_step = [25, 75, 150]\n","decay_factor = 0.1"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"sk3yUeiFqo_J","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593360880991,"user_tz":-120,"elapsed":1208,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["model_folder = os.path.join('./', out_dir, 'rgb', 'ConvLSTM-Attention', 'stage1')  # Dir for saving models and log files\n","# Create the dir\n","if os.path.exists(model_folder):\n","    print('Directory {} exists!'.format(model_folder))\n","    #sys.exit()\n","#os.makedirs(model_folder)\n","\n","# Log files\n","writer = SummaryWriter(model_folder)\n","train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n","train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n","val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n","val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKwZ3cSg5CEi","colab_type":"text"},"source":["**Prepare Network and Training**"]},{"cell_type":"code","metadata":{"id":"PmuMN_PD24P-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593360867474,"user_tz":-120,"elapsed":1903,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"e580fc6b-a8e3-4173-edaf-d39a54033138"},"source":["train_params = []\n","\n","model = attentionModel(num_classes=num_classes, mem_size=memSize)\n","#model = convLSTMModel(num_classes=num_classes, mem_size=memSize)\n","model.train(False)\n","for params in model.parameters():\n","    params.requires_grad = False\n","\n","for params in model.lstm_cell.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.classifier.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.lstm_cell.train(True)\n","\n","model.classifier.train(True)\n","model.cuda()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["attentionModel(\n","  (resNet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (lstm_cell): MyConvLSTMCell(\n","    (conv_i_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_i_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_f_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_f_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_c_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_c_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_o_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_o_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n","  (dropout): Dropout(p=0.7, inplace=False)\n","  (fc): Linear(in_features=512, out_features=61, bias=True)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.7, inplace=False)\n","    (1): Linear(in_features=512, out_features=61, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"R5R07KTJ5LMk","colab_type":"text"},"source":["**Define Data Preprocessing**"]},{"cell_type":"code","metadata":{"id":"cs-Yds-A3KG8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593359462712,"user_tz":-120,"elapsed":9558,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n","\n","optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n","                                                        gamma=decay_factor)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U7oq97yK5QI_","colab_type":"text"},"source":["**Train**"]},{"cell_type":"code","metadata":{"id":"BIQFpDTStC51","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1593360840896,"user_tz":-120,"elapsed":1387734,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"dd10e439-2083-45cc-de42-bdef01d5ab2e"},"source":["train_iter = 0\n","min_accuracy = 0\n","\n","for epoch in range(numEpochs):\n","    \n","    epoch_loss = 0\n","    numCorrTrain = 0\n","    trainSamples = 0\n","    iterPerEpoch = 0\n","    model.lstm_cell.train(True)\n","    model.classifier.train(True)\n","    writer.add_scalar('lr', optimizer_fn.param_groups[0]['lr'], epoch+1)\n","    for i, (inputs, targets) in enumerate(train_loader):\n","        train_iter += 1\n","        iterPerEpoch += 1\n","        optimizer_fn.zero_grad()\n","        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","        labelVariable = Variable(targets.cuda())\n","        trainSamples += inputs.size(0)\n","        output_label, _ = model(inputVariable)\n","        loss = loss_fn(output_label, labelVariable)\n","        loss.backward()\n","        optimizer_fn.step()\n","        _, predicted = torch.max(output_label.data, 1)\n","        numCorrTrain += (predicted == targets.cuda()).sum()\n","        epoch_loss += loss.item()\n","    avg_loss = epoch_loss/iterPerEpoch\n","    trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n","\n","    print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch+1, avg_loss, trainAccuracy))\n","    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n","    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n","    train_log_loss.write('Train Loss after {} epochs = {}\\n'.format(epoch + 1, avg_loss))\n","    train_log_acc.write('Train Accuracy after {} epochs = {}%\\n'.format(epoch + 1, trainAccuracy))\n","    \n","    if (epoch+1) % 1 == 0:\n","        model.train(False)\n","        val_loss_epoch = 0\n","        val_iter = 0\n","        val_samples = 0\n","        numCorr = 0\n","        for j, (inputs, targets) in enumerate(val_loader):\n","            val_iter += 1\n","            val_samples += inputs.size(0)\n","            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","            labelVariable = Variable(targets.cuda(non_blocking=True))\n","            output_label, _ = model(inputVariable)\n","            val_loss = loss_fn(output_label, labelVariable)\n","            val_loss_epoch += val_loss.item()\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorr += (predicted == targets.cuda()).sum()\n","        val_accuracy = (numCorr.item() / val_samples) * 100\n","        avg_val_loss = val_loss_epoch / val_iter\n","        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n","        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n","        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n","        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n","        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n","        if val_accuracy > min_accuracy:\n","            stage1_dict = (model_folder + '/model_rgb_state_dict.pth')\n","            torch.save(model.state_dict(), stage1_dict)\n","            min_accuracy = val_accuracy\n","    \n","    optim_scheduler.step()\n","\n","train_log_loss.close()\n","train_log_acc.close()\n","val_log_acc.close()\n","val_log_loss.close()\n","writer.export_scalars_to_json(model_folder + \"/all_scalars.json\")\n","writer.close()\n","\n","print('Best accuracy after {} epochs = {}'.format(epoch, min_accuracy))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Train: Epoch = 1 | Loss = 4.078752149235118 | Accuracy = 2.976190476190476\n","Val: Epoch = 1 | Loss 3.961909055709839 | Accuracy = 6.0344827586206895\n","Train: Epoch = 2 | Loss = 4.051681865345348 | Accuracy = 6.845238095238096\n","Val: Epoch = 2 | Loss 3.9288421869277954 | Accuracy = 6.0344827586206895\n","Train: Epoch = 3 | Loss = 4.01118523424322 | Accuracy = 6.845238095238096\n","Val: Epoch = 3 | Loss 3.8730334043502808 | Accuracy = 8.620689655172415\n","Train: Epoch = 4 | Loss = 3.9233627536080102 | Accuracy = 7.738095238095238\n","Val: Epoch = 4 | Loss 3.923434257507324 | Accuracy = 6.896551724137931\n","Train: Epoch = 5 | Loss = 3.8082044558091597 | Accuracy = 10.119047619047619\n","Val: Epoch = 5 | Loss 3.691694498062134 | Accuracy = 6.896551724137931\n","Train: Epoch = 6 | Loss = 3.7218796123157847 | Accuracy = 8.928571428571429\n","Val: Epoch = 6 | Loss 3.6967068910598755 | Accuracy = 16.379310344827587\n","Train: Epoch = 7 | Loss = 3.6786505092274058 | Accuracy = 8.630952380952381\n","Val: Epoch = 7 | Loss 3.5861862897872925 | Accuracy = 9.482758620689655\n","Train: Epoch = 8 | Loss = 3.630524852059104 | Accuracy = 9.821428571428571\n","Val: Epoch = 8 | Loss 3.6622735261917114 | Accuracy = 14.655172413793101\n","Train: Epoch = 9 | Loss = 3.531683640046553 | Accuracy = 11.30952380952381\n","Val: Epoch = 9 | Loss 3.614704728126526 | Accuracy = 11.206896551724139\n","Train: Epoch = 10 | Loss = 3.474244572899558 | Accuracy = 10.714285714285714\n","Val: Epoch = 10 | Loss 3.4630976915359497 | Accuracy = 17.24137931034483\n","Train: Epoch = 11 | Loss = 3.335878307169134 | Accuracy = 16.964285714285715\n","Val: Epoch = 11 | Loss 3.5558393001556396 | Accuracy = 11.206896551724139\n","Train: Epoch = 12 | Loss = 3.448351578278975 | Accuracy = 11.30952380952381\n","Val: Epoch = 12 | Loss 3.3467094898223877 | Accuracy = 15.517241379310345\n","Train: Epoch = 13 | Loss = 3.236640605059537 | Accuracy = 15.773809523809524\n","Val: Epoch = 13 | Loss 3.2582746744155884 | Accuracy = 17.24137931034483\n","Train: Epoch = 14 | Loss = 3.262213425202803 | Accuracy = 17.261904761904763\n","Val: Epoch = 14 | Loss 3.3140265941619873 | Accuracy = 12.931034482758621\n","Train: Epoch = 15 | Loss = 3.322080308740789 | Accuracy = 14.583333333333334\n","Val: Epoch = 15 | Loss 3.3465445041656494 | Accuracy = 13.793103448275861\n","Train: Epoch = 16 | Loss = 3.253364259546453 | Accuracy = 17.261904761904763\n","Val: Epoch = 16 | Loss 3.2744404077529907 | Accuracy = 18.103448275862068\n","Train: Epoch = 17 | Loss = 3.144483457912098 | Accuracy = 17.559523809523807\n","Val: Epoch = 17 | Loss 3.1540963649749756 | Accuracy = 17.24137931034483\n","Train: Epoch = 18 | Loss = 3.0436007976531982 | Accuracy = 19.047619047619047\n","Val: Epoch = 18 | Loss 3.1203296184539795 | Accuracy = 23.275862068965516\n","Train: Epoch = 19 | Loss = 3.0099077874963935 | Accuracy = 21.13095238095238\n","Val: Epoch = 19 | Loss 3.060065507888794 | Accuracy = 26.72413793103448\n","Train: Epoch = 20 | Loss = 2.9566019014878706 | Accuracy = 22.916666666666664\n","Val: Epoch = 20 | Loss 3.0183281898498535 | Accuracy = 19.82758620689655\n","Train: Epoch = 21 | Loss = 3.062688849189065 | Accuracy = 19.345238095238095\n","Val: Epoch = 21 | Loss 3.1435916423797607 | Accuracy = 18.96551724137931\n","Train: Epoch = 22 | Loss = 2.9580975879322398 | Accuracy = 20.535714285714285\n","Val: Epoch = 22 | Loss 2.9756137132644653 | Accuracy = 25.0\n","Train: Epoch = 23 | Loss = 2.8835947513580322 | Accuracy = 27.976190476190478\n","Val: Epoch = 23 | Loss 3.03080153465271 | Accuracy = 24.137931034482758\n","Train: Epoch = 24 | Loss = 2.889313047582453 | Accuracy = 21.428571428571427\n","Val: Epoch = 24 | Loss 2.9978251457214355 | Accuracy = 24.137931034482758\n","Train: Epoch = 25 | Loss = 2.6902618408203125 | Accuracy = 27.083333333333332\n","Val: Epoch = 25 | Loss 2.86315381526947 | Accuracy = 26.72413793103448\n","Train: Epoch = 26 | Loss = 2.609573385932229 | Accuracy = 33.63095238095239\n","Val: Epoch = 26 | Loss 2.846359133720398 | Accuracy = 25.0\n","Train: Epoch = 27 | Loss = 2.5491361076181587 | Accuracy = 32.142857142857146\n","Val: Epoch = 27 | Loss 2.814080834388733 | Accuracy = 25.862068965517242\n","Train: Epoch = 28 | Loss = 2.5895771980285645 | Accuracy = 26.488095238095237\n","Val: Epoch = 28 | Loss 2.798911452293396 | Accuracy = 25.0\n","Train: Epoch = 29 | Loss = 2.592207735235041 | Accuracy = 30.357142857142854\n","Val: Epoch = 29 | Loss 2.8330365419387817 | Accuracy = 26.72413793103448\n","Train: Epoch = 30 | Loss = 2.393626267259771 | Accuracy = 30.654761904761905\n","Val: Epoch = 30 | Loss 2.7822649478912354 | Accuracy = 27.586206896551722\n","Train: Epoch = 31 | Loss = 2.4327259063720703 | Accuracy = 33.33333333333333\n","Val: Epoch = 31 | Loss 2.735783576965332 | Accuracy = 27.586206896551722\n","Train: Epoch = 32 | Loss = 2.397999568419023 | Accuracy = 29.166666666666668\n","Val: Epoch = 32 | Loss 2.7192684412002563 | Accuracy = 28.448275862068968\n","Train: Epoch = 33 | Loss = 2.414253451607444 | Accuracy = 32.73809523809524\n","Val: Epoch = 33 | Loss 2.744455099105835 | Accuracy = 29.310344827586203\n","Train: Epoch = 34 | Loss = 2.3758835142309014 | Accuracy = 31.547619047619047\n","Val: Epoch = 34 | Loss 2.7454718351364136 | Accuracy = 27.586206896551722\n","Train: Epoch = 35 | Loss = 2.55420539595864 | Accuracy = 27.976190476190478\n","Val: Epoch = 35 | Loss 2.732965350151062 | Accuracy = 26.72413793103448\n","Train: Epoch = 36 | Loss = 2.298794052817605 | Accuracy = 35.41666666666667\n","Val: Epoch = 36 | Loss 2.7666196823120117 | Accuracy = 26.72413793103448\n","Train: Epoch = 37 | Loss = 2.425634362480857 | Accuracy = 30.952380952380953\n","Val: Epoch = 37 | Loss 2.731009602546692 | Accuracy = 26.72413793103448\n","Train: Epoch = 38 | Loss = 2.305480263449929 | Accuracy = 37.202380952380956\n","Val: Epoch = 38 | Loss 2.7176945209503174 | Accuracy = 30.17241379310345\n","Train: Epoch = 39 | Loss = 2.3569813424890693 | Accuracy = 32.73809523809524\n","Val: Epoch = 39 | Loss 2.7347689867019653 | Accuracy = 26.72413793103448\n","Train: Epoch = 40 | Loss = 2.2487425153905694 | Accuracy = 35.41666666666667\n","Val: Epoch = 40 | Loss 2.7685885429382324 | Accuracy = 26.72413793103448\n","Train: Epoch = 41 | Loss = 2.390593745491721 | Accuracy = 28.869047619047617\n","Val: Epoch = 41 | Loss 2.747219443321228 | Accuracy = 26.72413793103448\n","Train: Epoch = 42 | Loss = 2.252632596276023 | Accuracy = 36.904761904761905\n","Val: Epoch = 42 | Loss 2.7072606086730957 | Accuracy = 25.862068965517242\n","Train: Epoch = 43 | Loss = 2.3146027651700107 | Accuracy = 35.41666666666667\n","Val: Epoch = 43 | Loss 2.7475852966308594 | Accuracy = 27.586206896551722\n","Train: Epoch = 44 | Loss = 2.274033091285012 | Accuracy = 33.63095238095239\n","Val: Epoch = 44 | Loss 2.7330210208892822 | Accuracy = 26.72413793103448\n","Train: Epoch = 45 | Loss = 2.13278714093295 | Accuracy = 39.285714285714285\n","Val: Epoch = 45 | Loss 2.7041183710098267 | Accuracy = 29.310344827586203\n","Train: Epoch = 46 | Loss = 2.250815066424283 | Accuracy = 38.392857142857146\n","Val: Epoch = 46 | Loss 2.6906795501708984 | Accuracy = 30.17241379310345\n","Train: Epoch = 47 | Loss = 2.453280210494995 | Accuracy = 33.33333333333333\n","Val: Epoch = 47 | Loss 2.729404091835022 | Accuracy = 31.03448275862069\n","Train: Epoch = 48 | Loss = 2.325394131920554 | Accuracy = 34.82142857142857\n","Val: Epoch = 48 | Loss 2.6742511987686157 | Accuracy = 29.310344827586203\n","Train: Epoch = 49 | Loss = 2.3621828989549116 | Accuracy = 33.33333333333333\n","Val: Epoch = 49 | Loss 2.664340376853943 | Accuracy = 27.586206896551722\n","Train: Epoch = 50 | Loss = 2.2623508410020308 | Accuracy = 34.226190476190474\n","Val: Epoch = 50 | Loss 2.6830798387527466 | Accuracy = 29.310344827586203\n","Train: Epoch = 51 | Loss = 2.4414707097140225 | Accuracy = 32.44047619047619\n","Val: Epoch = 51 | Loss 2.752617359161377 | Accuracy = 29.310344827586203\n","Train: Epoch = 52 | Loss = 2.1729128035632046 | Accuracy = 39.88095238095239\n","Val: Epoch = 52 | Loss 2.7208399772644043 | Accuracy = 29.310344827586203\n","Train: Epoch = 53 | Loss = 2.2591238997199317 | Accuracy = 35.11904761904761\n","Val: Epoch = 53 | Loss 2.6977975368499756 | Accuracy = 28.448275862068968\n","Train: Epoch = 54 | Loss = 2.1375608444213867 | Accuracy = 41.36904761904761\n","Val: Epoch = 54 | Loss 2.695172905921936 | Accuracy = 30.17241379310345\n","Train: Epoch = 55 | Loss = 2.1783756126057017 | Accuracy = 37.202380952380956\n","Val: Epoch = 55 | Loss 2.676840305328369 | Accuracy = 25.862068965517242\n","Train: Epoch = 56 | Loss = 2.078065883029591 | Accuracy = 42.55952380952381\n","Val: Epoch = 56 | Loss 2.7426235675811768 | Accuracy = 25.0\n","Train: Epoch = 57 | Loss = 2.1839961030266504 | Accuracy = 38.98809523809524\n","Val: Epoch = 57 | Loss 2.7165530920028687 | Accuracy = 30.17241379310345\n","Train: Epoch = 58 | Loss = 2.161351897499778 | Accuracy = 40.476190476190474\n","Val: Epoch = 58 | Loss 2.6773009300231934 | Accuracy = 29.310344827586203\n","Train: Epoch = 59 | Loss = 2.1569192192771216 | Accuracy = 34.523809523809526\n","Val: Epoch = 59 | Loss 2.7012598514556885 | Accuracy = 28.448275862068968\n","Train: Epoch = 60 | Loss = 2.2181000926277856 | Accuracy = 38.98809523809524\n","Val: Epoch = 60 | Loss 2.7303696870803833 | Accuracy = 27.586206896551722\n","Train: Epoch = 61 | Loss = 2.011021841656078 | Accuracy = 43.154761904761905\n","Val: Epoch = 61 | Loss 2.6638755798339844 | Accuracy = 30.17241379310345\n","Train: Epoch = 62 | Loss = 2.111662647940896 | Accuracy = 38.095238095238095\n","Val: Epoch = 62 | Loss 2.6954758167266846 | Accuracy = 33.62068965517241\n","Train: Epoch = 63 | Loss = 2.0974763198332353 | Accuracy = 40.17857142857143\n","Val: Epoch = 63 | Loss 2.7128387689590454 | Accuracy = 29.310344827586203\n","Train: Epoch = 64 | Loss = 2.111131928183816 | Accuracy = 41.07142857142857\n","Val: Epoch = 64 | Loss 2.6456717252731323 | Accuracy = 28.448275862068968\n","Train: Epoch = 65 | Loss = 2.064632394097068 | Accuracy = 43.154761904761905\n","Val: Epoch = 65 | Loss 2.6225286722183228 | Accuracy = 29.310344827586203\n","Train: Epoch = 66 | Loss = 2.1001010591333564 | Accuracy = 42.26190476190476\n","Val: Epoch = 66 | Loss 2.657443642616272 | Accuracy = 31.03448275862069\n","Train: Epoch = 67 | Loss = 2.0027155117555098 | Accuracy = 44.047619047619044\n","Val: Epoch = 67 | Loss 2.6861129999160767 | Accuracy = 31.03448275862069\n","Train: Epoch = 68 | Loss = 2.0071353262121026 | Accuracy = 44.047619047619044\n","Val: Epoch = 68 | Loss 2.652721643447876 | Accuracy = 31.896551724137932\n","Train: Epoch = 69 | Loss = 2.061895901506597 | Accuracy = 38.98809523809524\n","Val: Epoch = 69 | Loss 2.6768311262130737 | Accuracy = 30.17241379310345\n","Train: Epoch = 70 | Loss = 2.084269231015986 | Accuracy = 40.476190476190474\n","Val: Epoch = 70 | Loss 2.7405192852020264 | Accuracy = 31.03448275862069\n","Train: Epoch = 71 | Loss = 2.0258750156922773 | Accuracy = 42.857142857142854\n","Val: Epoch = 71 | Loss 2.649664878845215 | Accuracy = 31.03448275862069\n","Train: Epoch = 72 | Loss = 2.118247086351568 | Accuracy = 38.98809523809524\n","Val: Epoch = 72 | Loss 2.612659215927124 | Accuracy = 32.758620689655174\n","Train: Epoch = 73 | Loss = 1.9474107135425915 | Accuracy = 43.154761904761905\n","Val: Epoch = 73 | Loss 2.6114989519119263 | Accuracy = 31.896551724137932\n","Train: Epoch = 74 | Loss = 1.9798820343884556 | Accuracy = 44.642857142857146\n","Val: Epoch = 74 | Loss 2.617186427116394 | Accuracy = 31.03448275862069\n","Train: Epoch = 75 | Loss = 2.0750642039559106 | Accuracy = 44.642857142857146\n","Val: Epoch = 75 | Loss 2.6204913854599 | Accuracy = 35.3448275862069\n","Train: Epoch = 76 | Loss = 1.9497107375751843 | Accuracy = 43.452380952380956\n","Val: Epoch = 76 | Loss 2.621376395225525 | Accuracy = 35.3448275862069\n","Train: Epoch = 77 | Loss = 1.9358626712452283 | Accuracy = 44.94047619047619\n","Val: Epoch = 77 | Loss 2.6250487565994263 | Accuracy = 36.206896551724135\n","Train: Epoch = 78 | Loss = 1.874600973996249 | Accuracy = 44.047619047619044\n","Val: Epoch = 78 | Loss 2.6317766904830933 | Accuracy = 35.3448275862069\n","Train: Epoch = 79 | Loss = 1.9499544555490667 | Accuracy = 45.83333333333333\n","Val: Epoch = 79 | Loss 2.633711576461792 | Accuracy = 35.3448275862069\n","Train: Epoch = 80 | Loss = 1.9563582702116533 | Accuracy = 46.726190476190474\n","Val: Epoch = 80 | Loss 2.6373443603515625 | Accuracy = 35.3448275862069\n","Train: Epoch = 81 | Loss = 1.9845927195115523 | Accuracy = 45.535714285714285\n","Val: Epoch = 81 | Loss 2.6373125314712524 | Accuracy = 35.3448275862069\n","Train: Epoch = 82 | Loss = 2.0430627194317905 | Accuracy = 42.857142857142854\n","Val: Epoch = 82 | Loss 2.6360881328582764 | Accuracy = 35.3448275862069\n","Train: Epoch = 83 | Loss = 1.9460139274597168 | Accuracy = 44.642857142857146\n","Val: Epoch = 83 | Loss 2.6440757513046265 | Accuracy = 34.48275862068966\n","Train: Epoch = 84 | Loss = 1.953088478608565 | Accuracy = 43.452380952380956\n","Val: Epoch = 84 | Loss 2.650960683822632 | Accuracy = 35.3448275862069\n","Train: Epoch = 85 | Loss = 1.9954362565820867 | Accuracy = 44.642857142857146\n","Val: Epoch = 85 | Loss 2.653389573097229 | Accuracy = 35.3448275862069\n","Train: Epoch = 86 | Loss = 1.9079516150734641 | Accuracy = 44.94047619047619\n","Val: Epoch = 86 | Loss 2.6527998447418213 | Accuracy = 35.3448275862069\n","Train: Epoch = 87 | Loss = 1.8741143508390947 | Accuracy = 47.32142857142857\n","Val: Epoch = 87 | Loss 2.652356743812561 | Accuracy = 35.3448275862069\n","Train: Epoch = 88 | Loss = 1.8950226306915283 | Accuracy = 44.345238095238095\n","Val: Epoch = 88 | Loss 2.6566245555877686 | Accuracy = 35.3448275862069\n","Train: Epoch = 89 | Loss = 1.998572826385498 | Accuracy = 42.26190476190476\n","Val: Epoch = 89 | Loss 2.6624804735183716 | Accuracy = 34.48275862068966\n","Train: Epoch = 90 | Loss = 1.936978968706998 | Accuracy = 46.13095238095239\n","Val: Epoch = 90 | Loss 2.6631165742874146 | Accuracy = 33.62068965517241\n","Train: Epoch = 91 | Loss = 1.9716994762420654 | Accuracy = 41.07142857142857\n","Val: Epoch = 91 | Loss 2.672943353652954 | Accuracy = 35.3448275862069\n","Train: Epoch = 92 | Loss = 1.8931939601898193 | Accuracy = 51.19047619047619\n","Val: Epoch = 92 | Loss 2.6722010374069214 | Accuracy = 35.3448275862069\n","Train: Epoch = 93 | Loss = 1.9135062477805398 | Accuracy = 43.75\n","Val: Epoch = 93 | Loss 2.675384759902954 | Accuracy = 35.3448275862069\n","Train: Epoch = 94 | Loss = 1.997399633580988 | Accuracy = 41.66666666666667\n","Val: Epoch = 94 | Loss 2.681783437728882 | Accuracy = 35.3448275862069\n","Train: Epoch = 95 | Loss = 1.9460833289406516 | Accuracy = 46.13095238095239\n","Val: Epoch = 95 | Loss 2.6865599155426025 | Accuracy = 35.3448275862069\n","Train: Epoch = 96 | Loss = 1.9428307251496748 | Accuracy = 42.26190476190476\n","Val: Epoch = 96 | Loss 2.675901770591736 | Accuracy = 34.48275862068966\n","Train: Epoch = 97 | Loss = 1.8634120334278454 | Accuracy = 46.13095238095239\n","Val: Epoch = 97 | Loss 2.669333577156067 | Accuracy = 34.48275862068966\n","Train: Epoch = 98 | Loss = 1.9496503309770064 | Accuracy = 44.94047619047619\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-20919ced9107>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mval_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mnumCorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0mval_iter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mval_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"e4dU_oN43NX2","colab_type":"text"},"source":["**Stage 2**"]},{"cell_type":"markdown","metadata":{"id":"kULTC6MA5TSC","colab_type":"text"},"source":["**Set Parameters**"]},{"cell_type":"code","metadata":{"id":"4EaY--DY7a-f","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593361225382,"user_tz":-120,"elapsed":732,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["numEpochs = 150\n","lr1 = 1e-4\n","decay_step = [25, 75]\n","decay_factor = 0.1"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FNoKjb1v6Ey4","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593361226264,"user_tz":-120,"elapsed":701,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"255338d0-53f1-4129-971b-e5d78f68a1ae"},"source":["model_folder = os.path.join('./', out_dir, 'rgb', 'ConvLSTM-Attention', 'stage2')  # Dir for saving models and log files\n","# Create the dir\n","if os.path.exists(model_folder):\n","    print('Directory {} exists!'.format(model_folder))\n","    #sys.exit()\n","#os.makedirs(model_folder)\n","\n","# Log files\n","writer = SummaryWriter(model_folder)\n","train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n","train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n","val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n","val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Directory ./experiments/rgb/ConvLSTM-Attention/stage2 exists!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9QW6v8Fk5Ysd","colab_type":"text"},"source":["**Prepare Network and Train**"]},{"cell_type":"code","metadata":{"id":"4o1qNkv63MgT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593361232439,"user_tz":-120,"elapsed":5078,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"2588a8dd-e757-4a47-f6f5-3b468e220031"},"source":["train_params = []\n","stage1_dict = (out_dir + '/rgb/ConvLSMT/7frame/stage1/model_rgb_state_dict.pth')\n","\n","#model = attentionModel(num_classes=num_classes, mem_size=memSize)\n","model = convLSTMModel(num_classes=num_classes, mem_size=memSize)\n","\n","model.load_state_dict(torch.load(stage1_dict))\n","model.train(False)\n","for params in model.parameters():\n","    params.requires_grad = False\n","#\n","for params in model.resNet.layer4[0].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[0].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[1].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[1].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[2].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","#\n","for params in model.resNet.layer4[2].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","#\n","for params in model.resNet.fc.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.resNet.layer4[0].conv1.train(True)\n","model.resNet.layer4[0].conv2.train(True)\n","model.resNet.layer4[1].conv1.train(True)\n","model.resNet.layer4[1].conv2.train(True)\n","model.resNet.layer4[2].conv1.train(True)\n","model.resNet.layer4[2].conv2.train(True)\n","model.resNet.fc.train(True)\n","\n","for params in model.lstm_cell.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.classifier.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.lstm_cell.train(True)\n","\n","model.classifier.train(True)\n","model.cuda()"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["convLSTMModel(\n","  (resNet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (lstm_cell): MyConvLSTMCell(\n","    (conv_i_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_i_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_f_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_f_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_c_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_c_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_o_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_o_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n","  (dropout): Dropout(p=0.7, inplace=False)\n","  (fc): Linear(in_features=512, out_features=61, bias=True)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.7, inplace=False)\n","    (1): Linear(in_features=512, out_features=61, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"GK9_SZbs5hMB","colab_type":"text"},"source":["**Define Data Preprocessing**"]},{"cell_type":"code","metadata":{"id":"9v9OXl9mLw80","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593361233651,"user_tz":-120,"elapsed":603,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}}},"source":["loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=4e-5, eps=1e-4)\n","\n","optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n","                                                        gamma=decay_factor)"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HoF8FCyj5jnh","colab_type":"text"},"source":["**Train**"]},{"cell_type":"code","metadata":{"id":"ButMUOcS3qvI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"85d50d6a-04eb-4302-ed73-707dfba7184c"},"source":["train_iter = 0\n","min_accuracy = 0\n","\n","for epoch in range(numEpochs):\n","    epoch_loss = 0\n","    numCorrTrain = 0\n","    trainSamples = 0\n","    iterPerEpoch = 0\n","    model.lstm_cell.train(True)\n","    model.classifier.train(True)\n","    writer.add_scalar('lr', optimizer_fn.param_groups[0]['lr'], epoch+1)\n","\n","    model.resNet.layer4[0].conv1.train(True)\n","    model.resNet.layer4[0].conv2.train(True)\n","    model.resNet.layer4[1].conv1.train(True)\n","    model.resNet.layer4[1].conv2.train(True)\n","    model.resNet.layer4[2].conv1.train(True)\n","    model.resNet.layer4[2].conv2.train(True)\n","    model.resNet.fc.train(True)\n","\n","    for i, (inputs, targets) in enumerate(train_loader):\n","        train_iter += 1\n","        iterPerEpoch += 1\n","        optimizer_fn.zero_grad()\n","        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","        labelVariable = Variable(targets.cuda())\n","        trainSamples += inputs.size(0)\n","        output_label, _ = model(inputVariable)\n","        loss = loss_fn(output_label, labelVariable)\n","        loss.backward()\n","        optimizer_fn.step()\n","        _, predicted = torch.max(output_label.data, 1)\n","        numCorrTrain += (predicted == targets.cuda()).sum()\n","        epoch_loss += loss.item()\n","    avg_loss = epoch_loss/iterPerEpoch\n","    trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n","\n","    print('Train: Epoch = {} | Loss = {} | Accuracy = {}'.format(epoch+1, avg_loss, trainAccuracy))\n","    \n","    train_log_loss.write('Train Loss after {} epochs = {}\\n'.format(epoch + 1, avg_loss))\n","    train_log_acc.write('Train Accuracy after {} epochs = {}%\\n'.format(epoch + 1, trainAccuracy))\n","    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n","    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n","    \n","    if (epoch+1) % 1 == 0:\n","        model.train(False)\n","        val_loss_epoch = 0\n","        val_iter = 0\n","        val_samples = 0\n","        numCorr = 0\n","        for j, (inputs, targets) in enumerate(val_loader):\n","            val_iter += 1\n","            val_samples += inputs.size(0)\n","            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","            labelVariable = Variable(targets.cuda(non_blocking=True))\n","            output_label, _ = model(inputVariable)\n","            val_loss = loss_fn(output_label, labelVariable)\n","            val_loss_epoch += val_loss.item()\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorr += (predicted == targets.cuda()).sum()\n","        val_accuracy = (numCorr.item() / val_samples) * 100\n","        avg_val_loss = val_loss_epoch / val_iter\n","        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n","        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n","        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n","        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n","        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n","        if val_accuracy > min_accuracy:\n","            save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n","            torch.save(model.state_dict(), save_path_model)\n","            min_accuracy = val_accuracy\n","    \n","    optim_scheduler.step()\n","\n","train_log_loss.close()\n","train_log_acc.close()\n","val_log_acc.close()\n","val_log_loss.close()\n","writer.export_scalars_to_json(model_folder + \"/all_scalars.json\")\n","writer.close()\n","\n","print('Best accuracy after {} epochs = {}'.format(epoch, min_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train: Epoch = 1 | Loss = 3.471258661963723 | Accuracy = 14.285714285714285\n","Val: Epoch = 1 | Loss 3.194247245788574 | Accuracy = 16.379310344827587\n","Train: Epoch = 2 | Loss = 3.039696129885587 | Accuracy = 20.238095238095237\n","Val: Epoch = 2 | Loss 2.91312313079834 | Accuracy = 22.413793103448278\n","Train: Epoch = 3 | Loss = 2.898478551344438 | Accuracy = 25.0\n","Val: Epoch = 3 | Loss 2.8342032432556152 | Accuracy = 22.413793103448278\n","Train: Epoch = 4 | Loss = 2.723279606212269 | Accuracy = 27.976190476190478\n","Val: Epoch = 4 | Loss 2.8456143140792847 | Accuracy = 23.275862068965516\n","Train: Epoch = 5 | Loss = 2.73574237389998 | Accuracy = 24.702380952380953\n","Val: Epoch = 5 | Loss 2.8176686763763428 | Accuracy = 21.551724137931032\n","Train: Epoch = 6 | Loss = 2.7690666805614126 | Accuracy = 23.809523809523807\n","Val: Epoch = 6 | Loss 3.038485288619995 | Accuracy = 22.413793103448278\n","Train: Epoch = 7 | Loss = 2.7501590685410933 | Accuracy = 24.107142857142858\n","Val: Epoch = 7 | Loss 2.7722268104553223 | Accuracy = 22.413793103448278\n","Train: Epoch = 8 | Loss = 2.6711755882609975 | Accuracy = 25.892857142857146\n","Val: Epoch = 8 | Loss 2.6496814489364624 | Accuracy = 27.586206896551722\n","Train: Epoch = 9 | Loss = 2.5729398944161157 | Accuracy = 30.059523809523807\n","Val: Epoch = 9 | Loss 2.717783808708191 | Accuracy = 25.862068965517242\n","Train: Epoch = 10 | Loss = 2.621027036146684 | Accuracy = 27.380952380952383\n","Val: Epoch = 10 | Loss 2.763382315635681 | Accuracy = 23.275862068965516\n","Train: Epoch = 11 | Loss = 2.6136900945143267 | Accuracy = 30.357142857142854\n","Val: Epoch = 11 | Loss 2.770957350730896 | Accuracy = 19.82758620689655\n","Train: Epoch = 12 | Loss = 2.5350536649877373 | Accuracy = 29.761904761904763\n","Val: Epoch = 12 | Loss 2.9121203422546387 | Accuracy = 19.82758620689655\n","Train: Epoch = 13 | Loss = 2.5582586851986973 | Accuracy = 27.380952380952383\n","Val: Epoch = 13 | Loss 2.8047635555267334 | Accuracy = 28.448275862068968\n","Train: Epoch = 14 | Loss = 2.4651659618724477 | Accuracy = 31.547619047619047\n","Val: Epoch = 14 | Loss 2.684398055076599 | Accuracy = 23.275862068965516\n","Train: Epoch = 15 | Loss = 2.3343443870544434 | Accuracy = 32.44047619047619\n","Val: Epoch = 15 | Loss 2.5827311277389526 | Accuracy = 30.17241379310345\n","Train: Epoch = 16 | Loss = 2.302309989929199 | Accuracy = 36.904761904761905\n","Val: Epoch = 16 | Loss 2.5870959758758545 | Accuracy = 26.72413793103448\n","Train: Epoch = 17 | Loss = 2.391964067112316 | Accuracy = 33.92857142857143\n","Val: Epoch = 17 | Loss 2.603825092315674 | Accuracy = 25.0\n","Train: Epoch = 18 | Loss = 2.3302821787920864 | Accuracy = 33.035714285714285\n","Val: Epoch = 18 | Loss 2.615648865699768 | Accuracy = 24.137931034482758\n","Train: Epoch = 19 | Loss = 2.392018502408808 | Accuracy = 33.63095238095239\n","Val: Epoch = 19 | Loss 2.6317542791366577 | Accuracy = 24.137931034482758\n","Train: Epoch = 20 | Loss = 2.292267387563532 | Accuracy = 36.30952380952381\n","Val: Epoch = 20 | Loss 2.5905208587646484 | Accuracy = 31.896551724137932\n","Train: Epoch = 21 | Loss = 2.3010851361534814 | Accuracy = 35.11904761904761\n","Val: Epoch = 21 | Loss 2.563663959503174 | Accuracy = 29.310344827586203\n","Train: Epoch = 22 | Loss = 2.2204785346984863 | Accuracy = 36.30952380952381\n","Val: Epoch = 22 | Loss 2.445557713508606 | Accuracy = 30.17241379310345\n","Train: Epoch = 23 | Loss = 2.1285409168763594 | Accuracy = 36.607142857142854\n","Val: Epoch = 23 | Loss 2.3567811250686646 | Accuracy = 35.3448275862069\n","Train: Epoch = 24 | Loss = 2.265113267031583 | Accuracy = 35.714285714285715\n","Val: Epoch = 24 | Loss 2.4212844371795654 | Accuracy = 33.62068965517241\n","Train: Epoch = 25 | Loss = 2.0959774364124644 | Accuracy = 38.98809523809524\n","Val: Epoch = 25 | Loss 2.6040698289871216 | Accuracy = 26.72413793103448\n","Train: Epoch = 26 | Loss = 2.0423225597901777 | Accuracy = 39.58333333333333\n","Val: Epoch = 26 | Loss 2.347436785697937 | Accuracy = 33.62068965517241\n","Train: Epoch = 27 | Loss = 1.9652287743308328 | Accuracy = 44.94047619047619\n","Val: Epoch = 27 | Loss 2.2825464010238647 | Accuracy = 35.3448275862069\n","Train: Epoch = 28 | Loss = 1.9321667822924526 | Accuracy = 39.58333333333333\n","Val: Epoch = 28 | Loss 2.2746447324752808 | Accuracy = 34.48275862068966\n","Train: Epoch = 29 | Loss = 1.9268327951431274 | Accuracy = 45.23809523809524\n","Val: Epoch = 29 | Loss 2.21960711479187 | Accuracy = 37.06896551724138\n","Train: Epoch = 30 | Loss = 1.9086903767152266 | Accuracy = 49.107142857142854\n","Val: Epoch = 30 | Loss 2.1979217529296875 | Accuracy = 37.93103448275862\n","Train: Epoch = 31 | Loss = 1.8138781677592883 | Accuracy = 45.535714285714285\n","Val: Epoch = 31 | Loss 2.188507318496704 | Accuracy = 37.93103448275862\n","Train: Epoch = 32 | Loss = 1.9276211586865513 | Accuracy = 44.047619047619044\n","Val: Epoch = 32 | Loss 2.2034847736358643 | Accuracy = 38.793103448275865\n","Train: Epoch = 33 | Loss = 1.8333191871643066 | Accuracy = 46.42857142857143\n","Val: Epoch = 33 | Loss 2.1716314554214478 | Accuracy = 37.93103448275862\n","Train: Epoch = 34 | Loss = 1.937699404629794 | Accuracy = 43.75\n","Val: Epoch = 34 | Loss 2.1566383838653564 | Accuracy = 37.93103448275862\n","Train: Epoch = 35 | Loss = 1.7025403759696267 | Accuracy = 47.91666666666667\n","Val: Epoch = 35 | Loss 2.159438371658325 | Accuracy = 38.793103448275865\n","Train: Epoch = 36 | Loss = 1.8583429618315264 | Accuracy = 48.51190476190476\n","Val: Epoch = 36 | Loss 2.1404730081558228 | Accuracy = 38.793103448275865\n","Train: Epoch = 37 | Loss = 1.776484261859547 | Accuracy = 46.42857142857143\n","Val: Epoch = 37 | Loss 2.17282772064209 | Accuracy = 39.6551724137931\n","Train: Epoch = 38 | Loss = 1.8438198999925093 | Accuracy = 48.80952380952381\n","Val: Epoch = 38 | Loss 2.151451587677002 | Accuracy = 38.793103448275865\n","Train: Epoch = 39 | Loss = 1.8153899041089145 | Accuracy = 48.51190476190476\n","Val: Epoch = 39 | Loss 2.0559319257736206 | Accuracy = 42.241379310344826\n","Train: Epoch = 40 | Loss = 1.8040008003061467 | Accuracy = 47.61904761904761\n","Val: Epoch = 40 | Loss 2.1025127172470093 | Accuracy = 37.93103448275862\n","Train: Epoch = 41 | Loss = 1.8086129101839932 | Accuracy = 47.91666666666667\n","Val: Epoch = 41 | Loss 2.065162420272827 | Accuracy = 37.93103448275862\n","Train: Epoch = 42 | Loss = 1.7625537568872625 | Accuracy = 46.726190476190474\n","Val: Epoch = 42 | Loss 2.0608123540878296 | Accuracy = 36.206896551724135\n","Train: Epoch = 43 | Loss = 1.739608959718184 | Accuracy = 46.726190476190474\n","Val: Epoch = 43 | Loss 2.0914212465286255 | Accuracy = 39.6551724137931\n","Train: Epoch = 44 | Loss = 1.770290125500072 | Accuracy = 49.404761904761905\n","Val: Epoch = 44 | Loss 2.0942444801330566 | Accuracy = 38.793103448275865\n","Train: Epoch = 45 | Loss = 1.7585542635484175 | Accuracy = 48.80952380952381\n","Val: Epoch = 45 | Loss 2.078252911567688 | Accuracy = 38.793103448275865\n","Train: Epoch = 46 | Loss = 1.7088385820388794 | Accuracy = 51.19047619047619\n","Val: Epoch = 46 | Loss 2.0921257734298706 | Accuracy = 39.6551724137931\n","Train: Epoch = 47 | Loss = 1.7580514712767168 | Accuracy = 54.46428571428571\n","Val: Epoch = 47 | Loss 2.0287874937057495 | Accuracy = 41.37931034482759\n","Train: Epoch = 48 | Loss = 1.7486930110237815 | Accuracy = 47.91666666666667\n","Val: Epoch = 48 | Loss 2.0440752506256104 | Accuracy = 39.6551724137931\n","Train: Epoch = 49 | Loss = 1.7901370958848433 | Accuracy = 48.214285714285715\n","Val: Epoch = 49 | Loss 2.038759469985962 | Accuracy = 38.793103448275865\n","Train: Epoch = 50 | Loss = 1.733781478621743 | Accuracy = 48.214285714285715\n","Val: Epoch = 50 | Loss 2.120131254196167 | Accuracy = 37.93103448275862\n","Train: Epoch = 51 | Loss = 1.722170504656705 | Accuracy = 53.86904761904761\n","Val: Epoch = 51 | Loss 2.0113229751586914 | Accuracy = 39.6551724137931\n","Train: Epoch = 52 | Loss = 1.6892985213886609 | Accuracy = 52.38095238095239\n","Val: Epoch = 52 | Loss 2.027114152908325 | Accuracy = 40.51724137931034\n","Train: Epoch = 53 | Loss = 1.6275406317277388 | Accuracy = 52.67857142857143\n","Val: Epoch = 53 | Loss 1.9920144081115723 | Accuracy = 39.6551724137931\n","Train: Epoch = 54 | Loss = 1.7204855680465698 | Accuracy = 52.976190476190474\n","Val: Epoch = 54 | Loss 1.9720138907432556 | Accuracy = 41.37931034482759\n","Train: Epoch = 55 | Loss = 1.7209089669314297 | Accuracy = 49.702380952380956\n","Val: Epoch = 55 | Loss 2.039015054702759 | Accuracy = 37.93103448275862\n","Train: Epoch = 56 | Loss = 1.6285917650569568 | Accuracy = 52.083333333333336\n","Val: Epoch = 56 | Loss 1.9903018474578857 | Accuracy = 38.793103448275865\n","Train: Epoch = 57 | Loss = 1.6369814547625454 | Accuracy = 53.273809523809526\n","Val: Epoch = 57 | Loss 2.0139424204826355 | Accuracy = 38.793103448275865\n","Train: Epoch = 58 | Loss = 1.6591713320125232 | Accuracy = 53.86904761904761\n","Val: Epoch = 58 | Loss 1.9826005101203918 | Accuracy = 41.37931034482759\n","Train: Epoch = 59 | Loss = 1.5306223197416826 | Accuracy = 54.166666666666664\n","Val: Epoch = 59 | Loss 1.9294244647026062 | Accuracy = 44.827586206896555\n","Train: Epoch = 60 | Loss = 1.6270378936420788 | Accuracy = 54.166666666666664\n","Val: Epoch = 60 | Loss 2.0382402539253235 | Accuracy = 35.3448275862069\n","Train: Epoch = 61 | Loss = 1.6185806014321067 | Accuracy = 53.57142857142857\n","Val: Epoch = 61 | Loss 1.9008467197418213 | Accuracy = 44.827586206896555\n","Train: Epoch = 62 | Loss = 1.6357548128474841 | Accuracy = 52.083333333333336\n","Val: Epoch = 62 | Loss 1.9667362570762634 | Accuracy = 38.793103448275865\n","Train: Epoch = 63 | Loss = 1.473509062420238 | Accuracy = 57.14285714285714\n","Val: Epoch = 63 | Loss 1.9883339405059814 | Accuracy = 39.6551724137931\n","Train: Epoch = 64 | Loss = 1.5713273611935703 | Accuracy = 53.57142857142857\n","Val: Epoch = 64 | Loss 1.9627462029457092 | Accuracy = 44.827586206896555\n","Train: Epoch = 65 | Loss = 1.639707868749445 | Accuracy = 52.083333333333336\n","Val: Epoch = 65 | Loss 2.0265697836875916 | Accuracy = 39.6551724137931\n","Train: Epoch = 66 | Loss = 1.625662554394115 | Accuracy = 51.488095238095234\n","Val: Epoch = 66 | Loss 1.919092059135437 | Accuracy = 40.51724137931034\n","Train: Epoch = 67 | Loss = 1.6399204947731711 | Accuracy = 52.38095238095239\n","Val: Epoch = 67 | Loss 1.9695953130722046 | Accuracy = 43.103448275862064\n","Train: Epoch = 68 | Loss = 1.5105330835689197 | Accuracy = 54.761904761904766\n","Val: Epoch = 68 | Loss 1.9483408331871033 | Accuracy = 42.241379310344826\n","Train: Epoch = 69 | Loss = 1.5707561644640835 | Accuracy = 53.273809523809526\n","Val: Epoch = 69 | Loss 1.9899067878723145 | Accuracy = 42.241379310344826\n","Train: Epoch = 70 | Loss = 1.598398425362327 | Accuracy = 54.166666666666664\n","Val: Epoch = 70 | Loss 1.9686686396598816 | Accuracy = 42.241379310344826\n","Train: Epoch = 71 | Loss = 1.5933515375310725 | Accuracy = 54.46428571428571\n","Val: Epoch = 71 | Loss 1.9732720255851746 | Accuracy = 42.241379310344826\n","Train: Epoch = 72 | Loss = 1.5033669038252397 | Accuracy = 56.25\n","Val: Epoch = 72 | Loss 1.95023512840271 | Accuracy = 43.103448275862064\n","Train: Epoch = 73 | Loss = 1.618778412992304 | Accuracy = 52.67857142857143\n","Val: Epoch = 73 | Loss 1.9206190705299377 | Accuracy = 39.6551724137931\n","Train: Epoch = 74 | Loss = 1.489504261450334 | Accuracy = 55.952380952380956\n","Val: Epoch = 74 | Loss 1.9427112936973572 | Accuracy = 43.103448275862064\n","Train: Epoch = 75 | Loss = 1.5675517049702732 | Accuracy = 54.761904761904766\n","Val: Epoch = 75 | Loss 1.98855721950531 | Accuracy = 44.827586206896555\n","Train: Epoch = 76 | Loss = 1.514236179265109 | Accuracy = 53.57142857142857\n","Val: Epoch = 76 | Loss 1.9799631834030151 | Accuracy = 44.827586206896555\n","Train: Epoch = 77 | Loss = 1.589990962635387 | Accuracy = 53.86904761904761\n","Val: Epoch = 77 | Loss 1.9548993110656738 | Accuracy = 42.241379310344826\n","Train: Epoch = 78 | Loss = 1.344343434680592 | Accuracy = 58.92857142857143\n","Val: Epoch = 78 | Loss 1.9461422562599182 | Accuracy = 42.241379310344826\n","Train: Epoch = 79 | Loss = 1.4491948973048816 | Accuracy = 55.05952380952381\n","Val: Epoch = 79 | Loss 1.9346411228179932 | Accuracy = 43.96551724137931\n","Train: Epoch = 80 | Loss = 1.5878127163106746 | Accuracy = 54.46428571428571\n","Val: Epoch = 80 | Loss 1.9326143860816956 | Accuracy = 44.827586206896555\n","Train: Epoch = 81 | Loss = 1.5668775710192593 | Accuracy = 53.273809523809526\n","Val: Epoch = 81 | Loss 1.9383593797683716 | Accuracy = 43.96551724137931\n","Train: Epoch = 82 | Loss = 1.5031666972420432 | Accuracy = 54.761904761904766\n","Val: Epoch = 82 | Loss 1.9322342276573181 | Accuracy = 42.241379310344826\n","Train: Epoch = 83 | Loss = 1.5225421515378086 | Accuracy = 56.25\n","Val: Epoch = 83 | Loss 1.9311808943748474 | Accuracy = 43.96551724137931\n","Train: Epoch = 84 | Loss = 1.4866381775249133 | Accuracy = 55.952380952380956\n","Val: Epoch = 84 | Loss 1.9369330406188965 | Accuracy = 44.827586206896555\n","Train: Epoch = 85 | Loss = 1.4861220013011585 | Accuracy = 56.845238095238095\n","Val: Epoch = 85 | Loss 1.9407103657722473 | Accuracy = 44.827586206896555\n","Train: Epoch = 86 | Loss = 1.3742974454706365 | Accuracy = 60.11904761904761\n","Val: Epoch = 86 | Loss 1.9467436075210571 | Accuracy = 43.103448275862064\n","Train: Epoch = 87 | Loss = 1.5374720746820623 | Accuracy = 52.38095238095239\n","Val: Epoch = 87 | Loss 1.944142460823059 | Accuracy = 43.96551724137931\n","Train: Epoch = 88 | Loss = 1.4666943495923823 | Accuracy = 59.226190476190474\n","Val: Epoch = 88 | Loss 1.9371453523635864 | Accuracy = 43.103448275862064\n","Train: Epoch = 89 | Loss = 1.4459534666754983 | Accuracy = 58.333333333333336\n","Val: Epoch = 89 | Loss 1.9352352023124695 | Accuracy = 43.103448275862064\n","Train: Epoch = 90 | Loss = 1.509690826589411 | Accuracy = 52.976190476190474\n","Val: Epoch = 90 | Loss 1.9289332628250122 | Accuracy = 44.827586206896555\n","Train: Epoch = 91 | Loss = 1.4642677957361394 | Accuracy = 59.523809523809526\n","Val: Epoch = 91 | Loss 1.91646009683609 | Accuracy = 43.103448275862064\n","Train: Epoch = 92 | Loss = 1.4505159746516834 | Accuracy = 58.333333333333336\n","Val: Epoch = 92 | Loss 1.9219022989273071 | Accuracy = 43.96551724137931\n","Train: Epoch = 93 | Loss = 1.443081790750677 | Accuracy = 55.654761904761905\n","Val: Epoch = 93 | Loss 1.9296584725379944 | Accuracy = 43.103448275862064\n","Train: Epoch = 94 | Loss = 1.453681999986822 | Accuracy = 53.57142857142857\n","Val: Epoch = 94 | Loss 1.9364653825759888 | Accuracy = 44.827586206896555\n","Train: Epoch = 95 | Loss = 1.4163411964069714 | Accuracy = 55.654761904761905\n","Val: Epoch = 95 | Loss 1.935358464717865 | Accuracy = 44.827586206896555\n","Train: Epoch = 96 | Loss = 1.5110940391367131 | Accuracy = 58.92857142857143\n","Val: Epoch = 96 | Loss 1.9250062704086304 | Accuracy = 44.827586206896555\n","Train: Epoch = 97 | Loss = 1.4690422469919378 | Accuracy = 56.845238095238095\n","Val: Epoch = 97 | Loss 1.92591392993927 | Accuracy = 44.827586206896555\n","Train: Epoch = 98 | Loss = 1.5068496140566738 | Accuracy = 52.67857142857143\n","Val: Epoch = 98 | Loss 1.9222771525382996 | Accuracy = 43.96551724137931\n","Train: Epoch = 99 | Loss = 1.4791963317177512 | Accuracy = 55.952380952380956\n","Val: Epoch = 99 | Loss 1.9104264974594116 | Accuracy = 44.827586206896555\n","Train: Epoch = 100 | Loss = 1.4051565798846157 | Accuracy = 59.82142857142857\n","Val: Epoch = 100 | Loss 1.9058622121810913 | Accuracy = 44.827586206896555\n","Train: Epoch = 101 | Loss = 1.4487149498679421 | Accuracy = 58.92857142857143\n","Val: Epoch = 101 | Loss 1.9133514165878296 | Accuracy = 44.827586206896555\n","Train: Epoch = 102 | Loss = 1.4971888823942705 | Accuracy = 56.845238095238095\n","Val: Epoch = 102 | Loss 1.9231025576591492 | Accuracy = 44.827586206896555\n","Train: Epoch = 103 | Loss = 1.4513418457724832 | Accuracy = 57.14285714285714\n","Val: Epoch = 103 | Loss 1.9307140707969666 | Accuracy = 43.96551724137931\n","Train: Epoch = 104 | Loss = 1.528545011173595 | Accuracy = 55.35714285714286\n","Val: Epoch = 104 | Loss 1.9337499737739563 | Accuracy = 43.96551724137931\n","Train: Epoch = 105 | Loss = 1.4708219333128496 | Accuracy = 55.654761904761905\n","Val: Epoch = 105 | Loss 1.9242025017738342 | Accuracy = 43.96551724137931\n","Train: Epoch = 106 | Loss = 1.5100705948742954 | Accuracy = 55.952380952380956\n","Val: Epoch = 106 | Loss 1.921108901500702 | Accuracy = 45.689655172413794\n","Train: Epoch = 107 | Loss = 1.4895327199589123 | Accuracy = 56.845238095238095\n","Val: Epoch = 107 | Loss 1.9093210101127625 | Accuracy = 45.689655172413794\n","Train: Epoch = 108 | Loss = 1.3549931699579412 | Accuracy = 59.226190476190474\n","Val: Epoch = 108 | Loss 1.8997092247009277 | Accuracy = 44.827586206896555\n","Train: Epoch = 109 | Loss = 1.5135243697599932 | Accuracy = 54.761904761904766\n","Val: Epoch = 109 | Loss 1.8957247734069824 | Accuracy = 44.827586206896555\n","Train: Epoch = 110 | Loss = 1.466282925822518 | Accuracy = 57.14285714285714\n","Val: Epoch = 110 | Loss 1.8977544903755188 | Accuracy = 45.689655172413794\n","Train: Epoch = 111 | Loss = 1.3637729232961482 | Accuracy = 60.416666666666664\n","Val: Epoch = 111 | Loss 1.9015379548072815 | Accuracy = 44.827586206896555\n","Train: Epoch = 112 | Loss = 1.4542927091771907 | Accuracy = 55.952380952380956\n","Val: Epoch = 112 | Loss 1.9083533883094788 | Accuracy = 45.689655172413794\n","Train: Epoch = 113 | Loss = 1.4548762494867498 | Accuracy = 56.25\n","Val: Epoch = 113 | Loss 1.9146149158477783 | Accuracy = 43.96551724137931\n","Train: Epoch = 114 | Loss = 1.4793852676044812 | Accuracy = 57.44047619047619\n","Val: Epoch = 114 | Loss 1.9202109575271606 | Accuracy = 43.96551724137931\n","Train: Epoch = 115 | Loss = 1.3947229818864302 | Accuracy = 58.333333333333336\n","Val: Epoch = 115 | Loss 1.9198007583618164 | Accuracy = 44.827586206896555\n","Train: Epoch = 116 | Loss = 1.35698894479058 | Accuracy = 60.11904761904761\n","Val: Epoch = 116 | Loss 1.9168000221252441 | Accuracy = 44.827586206896555\n","Train: Epoch = 117 | Loss = 1.4105213988911023 | Accuracy = 56.547619047619044\n","Val: Epoch = 117 | Loss 1.9181461930274963 | Accuracy = 45.689655172413794\n","Train: Epoch = 118 | Loss = 1.4204799045215954 | Accuracy = 58.03571428571429\n","Val: Epoch = 118 | Loss 1.9172664284706116 | Accuracy = 44.827586206896555\n","Train: Epoch = 119 | Loss = 1.4955410090359775 | Accuracy = 54.166666666666664\n","Val: Epoch = 119 | Loss 1.9145989418029785 | Accuracy = 43.103448275862064\n","Train: Epoch = 120 | Loss = 1.5068790912628174 | Accuracy = 57.44047619047619\n","Val: Epoch = 120 | Loss 1.9092720746994019 | Accuracy = 43.103448275862064\n","Train: Epoch = 121 | Loss = 1.3870677189393477 | Accuracy = 60.11904761904761\n","Val: Epoch = 121 | Loss 1.9119948148727417 | Accuracy = 43.96551724137931\n","Train: Epoch = 122 | Loss = 1.5081212303855203 | Accuracy = 53.86904761904761\n","Val: Epoch = 122 | Loss 1.923294484615326 | Accuracy = 45.689655172413794\n","Train: Epoch = 123 | Loss = 1.411959713155573 | Accuracy = 55.654761904761905\n","Val: Epoch = 123 | Loss 1.9243021607398987 | Accuracy = 45.689655172413794\n"],"name":"stdout"}]}]}