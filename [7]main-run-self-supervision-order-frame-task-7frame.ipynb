{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[7]main-run-self-supervision-order-frame-task-7frame.ipynb","provenance":[{"file_id":"1_kL7S7gV2ViVkfDpl2Yu7sfXQ7qEiQyM","timestamp":1593365003987},{"file_id":"1yY2yCYV2x_mc_2G8p0AAGvsGleOUzWR4","timestamp":1593341228163},{"file_id":"1_jLW1lBjVXQP7dzTVxRPbe0R0mwmxQD8","timestamp":1593331106754},{"file_id":"1TDK4af2_QYZFGad4A_FuUWOPmwDG9Jsm","timestamp":1593288338250},{"file_id":"1STeTl111HNDVstz3no9L3XEYu-h0VgP-","timestamp":1593273590149},{"file_id":"17k1c8DNm4_OqwAZZvpfGGtDX0xiRiiGJ","timestamp":1593154626125},{"file_id":"1c8zt-uJk3GrWvhejPlyge3p1OzqIY13Y","timestamp":1593123364356},{"file_id":"1usVuxmxfl5_nyCEHzaTY1OmZ1tYP26RF","timestamp":1593112974129},{"file_id":"17pIXf2DMmnxHCFPE2q7MTUWaL7OO6agh","timestamp":1592993427869},{"file_id":"1qKvOEF_HpFgfNeLIVccrQkPvdpsntD13","timestamp":1592578578043},{"file_id":"1AUBzt934w_qGM2iFZ1W1E-shHOsrZ7xd","timestamp":1591609652291},{"file_id":"1mUQO5jmnTOUFlkOJ_bByUyBmf1UQz4yN","timestamp":1590686870832}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y1PXD2NL4Nxf","colab_type":"text"},"source":["**Install requirements**"]},{"cell_type":"code","metadata":{"id":"HjRb9K14hW_l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593433617096,"user_tz":-120,"elapsed":5453,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"81a61e57-4272-4b25-a898-62b20c60f244"},"source":["!pip3 install 'tensorboardX' "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jBdMq5aF4YHP","colab_type":"text"},"source":["**Import Google Drive**"]},{"cell_type":"code","metadata":{"id":"4Db3Jwa4tG-q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593433617101,"user_tz":-120,"elapsed":5441,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"a445e8e7-1675-421a-997b-1c7d59ee43ff"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","\n","path = 'drive/My Drive/ego-rnn/'\n","os.chdir(path)\n","cwd = os.getcwd()\n","print(\"Current dir: \"+cwd)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Current dir: /content/drive/My Drive/ego-rnn\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KhQZjOdN4Unu","colab_type":"text"},"source":["**Import libraries**"]},{"cell_type":"code","metadata":{"id":"t3mf6kG2OBPO","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n","                                RandomHorizontalFlip)\n","from tensorboardX import SummaryWriter\n","from makeDatasetRGB import *\n","from MyConvLSTMCell import *\n","\n","import argparse\n","import sys\n","import matplotlib.pyplot as plt\n","\n","import os\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import numpy as np\n","import glob\n","from random import random\n","\n","import torch.nn as nn\n","import math\n","import torch.utils.model_zoo as model_zoo\n","import torchvision\n","\n","from torchvision import transforms\n","from itertools import permutations, combinations\n","import spatial_transforms \n","\n","from torch.autograd import Variable\n","from torch.nn import functional as F\n","from resnetMod import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtG7gqJQ8c8i","colab_type":"code","colab":{}},"source":["def build_permutations(frame, classes=100):\n","  a_list = np.linspace(0, frame, frame, endpoint=False, dtype=int)\n","\n","  permutations_object = permutations(a_list)\n","  permutations_list = np.array(list(permutations_object))[:2020]\n","  hamming_dist = []\n","\n","  for i,(A) in enumerate(permutations_list):\n","    hamming_dist.append(sum([np.count_nonzero((A == B) == False) for B in permutations_list]))\n","\n","  permutations_list = np.array([permutations_list[i] for i in sorted(range(len(hamming_dist)), key=hamming_dist.__getitem__, reverse=True)])[:classes]\n","  np.random.shuffle(permutations_list)\n","\n","  return permutations_list\n","\n","def gen_split_mmaps(root_dir, stackSize, dir_users):\n","    Dataset = []\n","    Mmaps = []\n","    Labels = []\n","    \n","    classes = []\n","    \n","    for user in ['S1','S2','S3','S4']:\n","        user_dir = os.path.join(root_dir, user)\n","        classes.extend(dir for dir in os.listdir(user_dir) if os.path.isdir(os.path.join(user_dir, dir)))\n","    \n","    classes = list(set(classes))\n","    classes.sort()\n","    class_to_idx = {classes[i]: i for i in range(len(classes))}\n","        \n","    for dir_user in dir_users:\n","\n","        dir = os.path.join(root_dir, dir_user)\n","\n","        for target in sorted(os.listdir(dir)): # into folder user\n","            dir1 = os.path.join(dir, target) \n","            if os.path.isdir(dir1):\n","                insts = sorted(os.listdir(dir1)) # into single action folder\n","                if insts != []:\n","                    for inst in insts:\n","                        inst_dir = os.path.join(dir1, inst+'/mmaps') # into element folder of action\n","                        numFrames_mmaps = len(glob.glob1(inst_dir, '*.png'))\n","                        numFrames_rgb = len(glob.glob1(os.path.join(dir1, inst+'/rgb'), '*.png'))\n","                        if numFrames_mmaps >= stackSize and numFrames_mmaps >= stackSize  >= stackSize:\n","                            Mmaps.append(inst_dir)\n","                            Dataset.append(os.path.join(dir1, inst+'/rgb'))\n","                            Labels.append(class_to_idx[target])\n","                \n","    return Dataset, Mmaps, Labels\n","\n","class makeDatasetMmaps(Dataset):\n","    def __init__(self, root_dir, dir_users, numFrame, orders_classes = 1000, spatial_transform=None, normalize=None, seqLen=20,\n","                 train=True, mulSeg=False, numSeg=1, fmt='.png'):\n","\n","        self.images, self.mmaps, self.labels = gen_split_mmaps(root_dir, numFrame, dir_users)\n","        self.spatial_transform = spatial_transform \n","        self.normalize = normalize\n","        self.train = train\n","        self.mulSeg = mulSeg\n","        self.numSeg = numSeg\n","        self.numFrame = numFrame\n","        self.seqLen = seqLen\n","        self.fmt = fmt\n","\n","        self.spatial_transform_rgb = spatial_transforms.Compose([spatial_transforms.ToTensor(), self.normalize])\n","        self.spatial_transform_mmaps = transforms.Compose([transforms.Resize(7), transforms.ToTensor()])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        vid_name = self.images[idx]\n","        vid_mmaps = self.mmaps[idx]\n","        label = self.labels[idx]\n","        inpSeq = []\n","        inpSeq_mmaps = []\n","\n","        order = np.random.randint(orders_classes)\n","        \n","        self.spatial_transform.randomize_parameters()\n","\n","        for i in np.linspace(1, self.numFrame, self.numFrame, endpoint=True):\n","            fl_name = vid_name + '/' + 'rgb' + str(int(np.floor(i))).zfill(4) + self.fmt\n","            img = Image.open(fl_name)\n","            inpSeq.append(self.spatial_transform_rgb(self.spatial_transform(img.convert('RGB'))))\n","            \n","\n","            fl_name_mmaps = vid_mmaps + '/' + 'map' + str(int(np.floor(i))).zfill(4) + self.fmt\n","            if not os.path.exists(fl_name_mmaps):\n","                fl_name_mmaps = vid_mmaps + '/' + 'map' + str(int(np.floor(i+1))).zfill(4) + self.fmt\n","            \n","            img_mmap = Image.open(fl_name_mmaps)\n","            inpSeq_mmaps.append(self.spatial_transform_mmaps(self.spatial_transform(img_mmap.convert('1'))))\n","\n","        inpSeq = torch.stack(inpSeq, 0)\n","        inpSeq_mmaps = torch.stack(inpSeq_mmaps, 0)\n","        return inpSeq, inpSeq_mmaps, label, int(order)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRoOMlKgKWEZ","colab_type":"code","colab":{}},"source":["class MyMotionSegCell(nn.Module):\n","\n","    def __init__(self, kernel_size=1, stride=1, padding=0):\n","        super(MyMotionSegCell, self).__init__()\n","\n","        self.relu = nn.ReLU()\n","        self.ms_conv = nn.Conv2d(512, 100, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.ms_fc = nn.Linear(100 * 7 * 7, 2 * 7 * 7)\n","\n","    def forward(self, x):\n","        x = self.relu(x)\n","        x = self.ms_conv(x)\n","        x = x.view(x.size(0),100*7*7)\n","        x = self.ms_fc(x)\n","        x = x.view(x.size(0),2,7,7)\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxsAZ6NXUOvc","colab_type":"code","colab":{}},"source":["def build_combinations(frame):\n","  a_list = np.linspace(0, frame, frame, endpoint=False, dtype=int)\n","  combinations_list = np.array(list(combinations(a_list, 2)))\n","  return combinations_list\n","\n","\n","class ordersModel(nn.Module):\n","    def __init__(self, mem_size=512, orders_classes = 100, frame = 7):\n","        super(ordersModel, self).__init__()\n","        self.mem_size = mem_size\n","        self.frame = frame\n","        self.combinations = build_combinations(7)\n","        self.permutations = build_permutations(7,orders_classes)\n","        self.fc6 = nn.Linear(mem_size*7*7, mem_size*2)\n","        self.fc7 = nn.Sequential(nn.Linear(mem_size*4, mem_size))\n","        self.orders_classifier = nn.Linear(mem_size*len(self.combinations), orders_classes)\n","\n","    def forward(self, feat_orders, orderVariable):\n","      feat_orders_shuffle = []\n","      \n","      for t in range(feat_orders.size(0)):\n","        order = orderVariable[t].item()\n","\n","        feat = self.fc6(feat_orders[t].view(feat_orders[t].size(0),self.mem_size*7*7))\n","        feat_orders_shuffle.append(torch.index_select(feat, 0, torch.LongTensor(self.permutations[order]).cuda()))\n","\n","      feat_orders_shuffle = torch.stack(feat_orders_shuffle, 0)\n","\n","      feat_orders = [self.fc7(torch.index_select(feat_orders_shuffle, 1, torch.LongTensor([r,c]).cuda()).view(feat_orders_shuffle.size(0),self.mem_size*4)) for r,c in self.combinations]\n","      feat_orders = torch.stack(feat_orders, 0).permute(1,0,2)\n","\n","      feat_orders = torch.reshape(feat_orders,(feat_orders.size(0),self.mem_size*len(self.combinations)))\n","      \n","      return self.orders_classifier(feat_orders)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs6-NQYvMAsK","colab_type":"code","colab":{}},"source":["class convLSTMModel(nn.Module):\n","    def __init__(self, num_classes=61, mem_size=512, orders_classes = 100, frame = 7):\n","        super(convLSTMModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.resNet = resnet34(True, True)\n","        self.mem_size = mem_size\n","        self.weight_softmax = self.resNet.fc.weight\n","        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n","        self.ms_cell = MyMotionSegCell()\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc = nn.Linear(mem_size, self.num_classes)\n","        self.classifier = nn.Sequential(self.dropout, self.fc)\n","        self.orders_classifier = ordersModel(mem_size, orders_classes, frame)\n","\n","    def forward(self, inputVariable, orderVariable = None, ORD = True, CAM = False, MS = False):\n","        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n","                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n","        \n","        feats_ms = []\n","        feat_orders = []\n","\n","        for t in range(inputVariable.size(0)):\n","            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n","            feat_orders.append(feature_conv)\n","\n","            if MS: \n","              feats_ms.append(self.ms_cell(feature_conv))\n","\n","            if CAM:\n","              bz, nc, h, w = feature_conv.size()\n","              feature_conv1 = feature_conv.view(bz, nc, h*w)\n","              probs, idxs = logit.sort(1, True)\n","              class_idx = idxs[:, 0]\n","              cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n","              attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n","              attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n","              attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n","              state = self.lstm_cell(attentionFeat, state)\n","            else:\n","              state = self.lstm_cell(feature_conv, state)\n","        \n","        if MS:\n","          feats_ms = torch.stack(feats_ms, 0)\n","\n","        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n","        feats = self.classifier(feats1)\n","\n","        if ORD:\n","          feat_orders = self.orders_classifier(torch.stack(feat_orders, 0).permute(1,0,2,3,4),orderVariable)\n","\n","        return feats, feats_ms, feats1, feat_orders\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6NIyeyZDWOM","colab_type":"text"},"source":["**Set Arguments**"]},{"cell_type":"code","metadata":{"id":"wV7T6n-Iqecv","colab_type":"code","colab":{}},"source":["data_dir = \"GTEA61/processed_frames2\"\n","out_dir = 'experiments'\n","\n","user_train = ['S1','S3','S4']\n","user_val = ['S2']\n","trainBatchSize = 32\n","valBatchSize = 64\n","memSize = 512\n","num_classes = 61\n","\n","frame = 7\n","seqLen = frame\n","\n","orders_classes = 1000\n","\n","CAM = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"05aii3lCDt_4","colab_type":"text"},"source":["**Prepare Dataset and Dataloader**"]},{"cell_type":"code","metadata":{"id":"4EaY--DY7a-f","colab_type":"code","colab":{}},"source":["numEpochs = 150\n","lr1 = 1e-4\n","decay_step = [25, 75]\n","decay_factor = 0.1\n","MS = True\n","weight_jig = 1\n","\n","model_folder = os.path.join('./', out_dir, 'self-supervised-orders', 'Conv', '1000', '7frm')  # Dir for saving models and log files\n","stage1_dict = (out_dir + '/rgb/ConvLSMT/16frame/stage1/model_rgb_state_dict.pth')\n","\n","weight_decay = 4e-5\n","weight_mmaps = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzBtJm6BsiHA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593433618836,"user_tz":-120,"elapsed":7017,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"9d953af4-5b63-44a3-8333-4c4de4b1d02d"},"source":["# Data loader\n","normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224)])\n","\n","vid_seq_train = makeDatasetMmaps(data_dir, user_train, frame, orders_classes = orders_classes,\n","                            spatial_transform=spatial_transform, normalize=normalize, seqLen=seqLen, fmt='.png')\n","\n","train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n","                        shuffle=True, num_workers=4, pin_memory=True)\n","\n","\n","vid_seq_val = makeDataset(data_dir, user_val, frame, \n","                            spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n","                            seqLen=seqLen, fmt='.png')\n","\n","val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize, \n","                        shuffle=False, num_workers=2, pin_memory=True)\n","\n","valInstances = vid_seq_val.__len__()\n","trainInstances = vid_seq_train.__len__()\n","\n","print('Number of samples in the dataset: training = {} | validation = {}'.format(trainInstances, valInstances))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of samples in the dataset: training = 333 | validation = 116\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kULTC6MA5TSC","colab_type":"text"},"source":["**Set Parameters**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FNoKjb1v6Ey4","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593433618837,"user_tz":-120,"elapsed":6922,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"b91c580c-7582-4ccc-93f0-738da19a4d36"},"source":["# Create the dir\n","if os.path.exists(model_folder):\n","    print('Directory {} exists!'.format(model_folder))\n","   # sys.exit()\n","#os.makedirs(model_folder)\n","\n","# Log files\n","writer = SummaryWriter(model_folder)\n","train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n","train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n","val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n","val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Directory ./experiments/self-supervised-orders/Conv/stage21000/7frm exists!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9QW6v8Fk5Ysd","colab_type":"text"},"source":["**Prepare Network and Train**"]},{"cell_type":"code","metadata":{"id":"4o1qNkv63MgT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593433634807,"user_tz":-120,"elapsed":22858,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"6b5c028f-fee7-4fe5-fccb-87ab0a75dbc2"},"source":["train_params = []\n","\n","model = convLSTMModel(num_classes=num_classes, orders_classes=orders_classes, mem_size=memSize, frame=frame)\n","model.load_state_dict(torch.load(stage1_dict), strict=False)\n","model.train(False)\n","for params in model.parameters():\n","    params.requires_grad = False\n","#\n","for params in model.resNet.layer4[0].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[0].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[1].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[1].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[2].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","#\n","for params in model.resNet.layer4[2].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","#\n","for params in model.resNet.fc.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.resNet.layer4[0].conv1.train(True)\n","model.resNet.layer4[0].conv2.train(True)\n","model.resNet.layer4[1].conv1.train(True)\n","model.resNet.layer4[1].conv2.train(True)\n","model.resNet.layer4[2].conv1.train(True)\n","model.resNet.layer4[2].conv2.train(True)\n","model.resNet.fc.train(True)\n","\n","for params in model.ms_cell.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.lstm_cell.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.classifier.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.orders_classifier.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.lstm_cell.train(True)\n","model.ms_cell.train(True)\n","\n","model.classifier.train(True)\n","model.orders_classifier.train(True)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["convLSTMModel(\n","  (resNet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (lstm_cell): MyConvLSTMCell(\n","    (conv_i_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_i_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_f_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_f_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_c_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_c_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_o_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_o_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (ms_cell): MyMotionSegCell(\n","    (relu): ReLU()\n","    (ms_conv): Conv2d(512, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (ms_fc): Linear(in_features=4900, out_features=98, bias=True)\n","  )\n","  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n","  (dropout): Dropout(p=0.7, inplace=False)\n","  (fc): Linear(in_features=512, out_features=61, bias=True)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.7, inplace=False)\n","    (1): Linear(in_features=512, out_features=61, bias=True)\n","  )\n","  (orders_classifier): ordersModel(\n","    (fc6): Linear(in_features=25088, out_features=1024, bias=True)\n","    (fc7): Sequential(\n","      (0): Linear(in_features=2048, out_features=512, bias=True)\n","    )\n","    (orders_classifier): Linear(in_features=10752, out_features=1000, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"GK9_SZbs5hMB","colab_type":"text"},"source":["**Define Data Preprocessing**"]},{"cell_type":"code","metadata":{"id":"9v9OXl9mLw80","colab_type":"code","colab":{}},"source":["loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=weight_decay, eps=1e-4)\n","\n","optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n","                                                        gamma=decay_factor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HoF8FCyj5jnh","colab_type":"text"},"source":["**Train**"]},{"cell_type":"code","metadata":{"id":"ButMUOcS3qvI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593436484145,"user_tz":-120,"elapsed":2872171,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"0c30ccfc-21b8-4714-e095-a402444b2ec9"},"source":["train_iter = 0\n","min_accuracy = 0\n","\n","\n","for epoch in range(numEpochs):\n","    epoch_loss = 0\n","    epoch_loss_ord = 0\n","    numCorrTrain = 0\n","    numCorrTrainOrd = 0\n","    numCorrTrainMmap = 0\n","    \n","    trainSamples = 0\n","    iterPerEpoch = 0\n","\n","    model.lstm_cell.train(True)\n","    model.ms_cell.train(True)\n","    model.orders_classifier.train(True)\n","    model.classifier.train(True)\n","    writer.add_scalar('lr', optimizer_fn.param_groups[0]['lr'], epoch+1)\n","    \n","    model.resNet.layer4[0].conv1.train(True)\n","    model.resNet.layer4[0].conv2.train(True)\n","    model.resNet.layer4[1].conv1.train(True)\n","    model.resNet.layer4[1].conv2.train(True)\n","    model.resNet.layer4[2].conv1.train(True)\n","    model.resNet.layer4[2].conv2.train(True)\n","    model.resNet.fc.train(True)\n","\n","    for i, (inputs, mmaps, targets, ords_lb) in enumerate(train_loader):\n","        train_iter += 1\n","        iterPerEpoch += 1\n","        optimizer_fn.zero_grad()\n","\n","        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","        labelVariable = Variable(targets.cuda())\n","        ords_lbVariable = Variable(torch.squeeze(ords_lb).cuda())\n","        trainSamples += inputs.size(0)\n","\n","        output_label, output_mmaps, _ , orders_logit = model(inputVariable,ords_lbVariable,CAM=CAM, MS=MS)\n","        \n","        loss = loss_fn(output_label, labelVariable) + loss_fn(orders_logit, ords_lbVariable) * weight_jig\n","        \n","        if MS:\n","          mmapsVariable = Variable(torch.squeeze(mmaps).cuda())\n","          output_mmaps = output_mmaps.permute(1, 2, 0, 3, 4)\n","          loss+=loss_fn(output_mmaps, mmapsVariable.long()) * weight_mmaps\n","\n","          _, predictedMmap = torch.max(output_mmaps.data, 1)\n","          numCorrTrainMmap += (predictedMmap == mmapsVariable.cuda()).sum()\n","          mmapAccuracy = (numCorrTrainMmap.item() / (trainSamples*frame*49)) * 100\n","          \n","        \n","        loss.backward()\n","        optimizer_fn.step()\n","        _, predicted = torch.max(output_label.data, 1)\n","        _, predictedOrd = torch.max(orders_logit.data, 1)\n","        numCorrTrain += (predicted == targets.cuda()).sum()\n","        numCorrTrainOrd += (predictedOrd == ords_lb.cuda()).sum()\n","\n","        epoch_loss += loss.item()\n","    \n","    avg_loss = epoch_loss/iterPerEpoch\n","    trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n","    ordersAccuracy = (numCorrTrainOrd.item() / (trainSamples)) * 100\n","\n","    print('Train: Epoch = {} | Loss = {} | Loss_orders = {} | Accuracy = {} | Accuracy_orders = {} | Accuracy_mmap = {}'.format(epoch+1, avg_loss, loss_fn(orders_logit, ords_lbVariable).item(), trainAccuracy, ordersAccuracy, mmapAccuracy))\n","    \n","    train_log_loss.write('Train Loss after {} epochs = {} \\n'.format(epoch + 1, avg_loss))\n","    train_log_acc.write('Train Accuracy after {} epochs = {} | Accuracy_orders = {}%\\n'.format(epoch + 1, trainAccuracy,ordersAccuracy))\n","    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n","    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n","    \n","    if (epoch+1) % 1 == 0:\n","        model.train(False)\n","        val_loss_epoch = 0\n","        val_iter = 0\n","        val_samples = 0\n","        numCorr = 0\n","        for j, (inputs, targets) in enumerate(val_loader):\n","            val_iter += 1\n","            val_samples += inputs.size(0)\n","            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","            labelVariable = Variable(targets.cuda(non_blocking=True))\n","            output_label, _, _, _ = model(inputVariable, ORD=False, CAM=CAM, MS=False)\n","            val_loss = loss_fn(output_label, labelVariable)\n","            val_loss_epoch += val_loss.item()\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorr += (predicted == targets.cuda()).sum()\n","\n","        val_accuracy = (numCorr.item() / val_samples) * 100\n","\n","        avg_val_loss = val_loss_epoch / val_iter\n","        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n","        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n","        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n","        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n","        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n","        \n","        if val_accuracy > min_accuracy:\n","            save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n","            torch.save(model.state_dict(), save_path_model)\n","            min_accuracy = val_accuracy\n","    \n","    # Step the scheduler\n","    optim_scheduler.step()\n","    \n","\n","train_log_loss.close()\n","train_log_acc.close()\n","val_log_acc.close()\n","val_log_loss.close()\n","writer.export_scalars_to_json(model_folder + \"/all_scalars.json\")\n","writer.close()\n","\n","print('Best accuracy after {} epochs = {}'.format(epoch, min_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train: Epoch = 1 | Loss = 10.043387933210893 | Loss_orders = 5.97104549407959 | Accuracy = 28.22822822822823 | Accuracy_orders = 1.8018018018018018 | Accuracy_mmap = 85.62936113956522\n","Val: Epoch = 1 | Loss 3.260405659675598 | Accuracy = 20.689655172413794\n","Train: Epoch = 2 | Loss = 9.61958594755693 | Loss_orders = 6.589447975158691 | Accuracy = 18.01801801801802 | Accuracy_orders = 0.9009009009009009 | Accuracy_mmap = 94.84323974119893\n","Val: Epoch = 2 | Loss 3.0401822328567505 | Accuracy = 18.103448275862068\n","Train: Epoch = 3 | Loss = 8.11908500844782 | Loss_orders = 4.279300212860107 | Accuracy = 23.423423423423422 | Accuracy_orders = 0.9009009009009009 | Accuracy_mmap = 94.5578231292517\n","Val: Epoch = 3 | Loss 2.9515483379364014 | Accuracy = 25.862068965517242\n","Train: Epoch = 4 | Loss = 7.928595499558882 | Loss_orders = 5.035255432128906 | Accuracy = 26.726726726726728 | Accuracy_orders = 1.2012012012012012 | Accuracy_mmap = 94.28816571673715\n","Val: Epoch = 4 | Loss 2.6303025484085083 | Accuracy = 37.06896551724138\n","Train: Epoch = 5 | Loss = 7.624220111153343 | Loss_orders = 4.715226173400879 | Accuracy = 27.027027027027028 | Accuracy_orders = 1.8018018018018018 | Accuracy_mmap = 95.00783582416236\n","Val: Epoch = 5 | Loss 2.5901917219161987 | Accuracy = 32.758620689655174\n","Train: Epoch = 6 | Loss = 7.508430177515203 | Loss_orders = 4.550268650054932 | Accuracy = 28.22822822822823 | Accuracy_orders = 1.2012012012012012 | Accuracy_mmap = 94.56657824004763\n","Val: Epoch = 6 | Loss 2.5308268070220947 | Accuracy = 31.896551724137932\n","Train: Epoch = 7 | Loss = 7.317624438892711 | Loss_orders = 4.638567924499512 | Accuracy = 36.03603603603604 | Accuracy_orders = 1.2012012012012012 | Accuracy_mmap = 95.11202164263389\n","Val: Epoch = 7 | Loss 2.4032546281814575 | Accuracy = 35.3448275862069\n","Train: Epoch = 8 | Loss = 7.220849297263405 | Loss_orders = 4.457634925842285 | Accuracy = 36.63663663663664 | Accuracy_orders = 0.6006006006006006 | Accuracy_mmap = 94.80471725369685\n","Val: Epoch = 8 | Loss 2.3761643171310425 | Accuracy = 37.06896551724138\n","Train: Epoch = 9 | Loss = 7.305878595872358 | Loss_orders = 4.922688961029053 | Accuracy = 37.23723723723724 | Accuracy_orders = 1.5015015015015014 | Accuracy_mmap = 94.88001120654181\n","Val: Epoch = 9 | Loss 2.4875102043151855 | Accuracy = 33.62068965517241\n","Train: Epoch = 10 | Loss = 7.172246542843905 | Loss_orders = 4.490726947784424 | Accuracy = 37.83783783783784 | Accuracy_orders = 1.2012012012012012 | Accuracy_mmap = 94.53155779686392\n","Val: Epoch = 10 | Loss 2.329333186149597 | Accuracy = 35.3448275862069\n","Train: Epoch = 11 | Loss = 7.206296530636874 | Loss_orders = 4.772181034088135 | Accuracy = 39.03903903903904 | Accuracy_orders = 2.4024024024024024 | Accuracy_mmap = 94.49391082044143\n","Val: Epoch = 11 | Loss 2.297546863555908 | Accuracy = 38.793103448275865\n","Train: Epoch = 12 | Loss = 7.077808770266446 | Loss_orders = 4.613373279571533 | Accuracy = 40.24024024024024 | Accuracy_orders = 1.8018018018018018 | Accuracy_mmap = 95.03147462331137\n","Val: Epoch = 12 | Loss 2.3106298446655273 | Accuracy = 34.48275862068966\n","Train: Epoch = 13 | Loss = 6.78830471905795 | Loss_orders = 4.498703479766846 | Accuracy = 42.64264264264264 | Accuracy_orders = 0.9009009009009009 | Accuracy_mmap = 95.0507358670624\n","Val: Epoch = 13 | Loss 2.218691647052765 | Accuracy = 37.06896551724138\n","Train: Epoch = 14 | Loss = 6.955465056679466 | Loss_orders = 4.83534574508667 | Accuracy = 44.74474474474475 | Accuracy_orders = 0.3003003003003003 | Accuracy_mmap = 94.94655004859086\n","Val: Epoch = 14 | Loss 2.22510826587677 | Accuracy = 39.6551724137931\n","Train: Epoch = 15 | Loss = 6.955897591330788 | Loss_orders = 4.6198601722717285 | Accuracy = 42.04204204204204 | Accuracy_orders = 0.9009009009009009 | Accuracy_mmap = 94.63399259317626\n","Val: Epoch = 15 | Loss 2.1458070278167725 | Accuracy = 39.6551724137931\n","Train: Epoch = 16 | Loss = 6.796078291806308 | Loss_orders = 4.235091686248779 | Accuracy = 44.14414414414414 | Accuracy_orders = 1.2012012012012012 | Accuracy_mmap = 94.76794578835394\n","Val: Epoch = 16 | Loss 2.1129176020622253 | Accuracy = 39.6551724137931\n","Train: Epoch = 17 | Loss = 6.716027780012651 | Loss_orders = 4.669829845428467 | Accuracy = 42.94294294294294 | Accuracy_orders = 1.8018018018018018 | Accuracy_mmap = 94.95793169262558\n","Val: Epoch = 17 | Loss 1.9739317297935486 | Accuracy = 43.96551724137931\n","Train: Epoch = 18 | Loss = 6.703626069155606 | Loss_orders = 4.741125583648682 | Accuracy = 46.246246246246244 | Accuracy_orders = 1.8018018018018018 | Accuracy_mmap = 95.27224017019935\n","Val: Epoch = 18 | Loss 2.2152445316314697 | Accuracy = 41.37931034482759\n","Train: Epoch = 19 | Loss = 6.665383165532893 | Loss_orders = 4.101306915283203 | Accuracy = 42.94294294294294 | Accuracy_orders = 3.6036036036036037 | Accuracy_mmap = 95.12602981990737\n","Val: Epoch = 19 | Loss 1.9649089574813843 | Accuracy = 43.96551724137931\n","Train: Epoch = 20 | Loss = 6.5657782554626465 | Loss_orders = 4.619501113891602 | Accuracy = 50.750750750750754 | Accuracy_orders = 3.303303303303303 | Accuracy_mmap = 95.50950367276899\n","Val: Epoch = 20 | Loss 1.966298758983612 | Accuracy = 48.275862068965516\n","Train: Epoch = 21 | Loss = 6.162458723241633 | Loss_orders = 4.363922595977783 | Accuracy = 51.651651651651655 | Accuracy_orders = 2.4024024024024024 | Accuracy_mmap = 94.6418721928926\n","Val: Epoch = 21 | Loss 1.9061673283576965 | Accuracy = 44.827586206896555\n","Train: Epoch = 22 | Loss = 6.15328428962014 | Loss_orders = 3.8888609409332275 | Accuracy = 51.35135135135135 | Accuracy_orders = 4.504504504504505 | Accuracy_mmap = 94.664635480962\n","Val: Epoch = 22 | Loss 2.0932129621505737 | Accuracy = 41.37931034482759\n","Train: Epoch = 23 | Loss = 6.074178132143888 | Loss_orders = 3.7156260013580322 | Accuracy = 49.849849849849846 | Accuracy_orders = 10.81081081081081 | Accuracy_mmap = 94.57445783976397\n","Val: Epoch = 23 | Loss 2.3260217905044556 | Accuracy = 35.3448275862069\n","Train: Epoch = 24 | Loss = 6.625657991929487 | Loss_orders = 4.615876197814941 | Accuracy = 43.54354354354354 | Accuracy_orders = 5.105105105105105 | Accuracy_mmap = 94.7014069463049\n","Val: Epoch = 24 | Loss 2.27023184299469 | Accuracy = 37.06896551724138\n","Train: Epoch = 25 | Loss = 6.252205675298518 | Loss_orders = 3.822812080383301 | Accuracy = 47.44744744744745 | Accuracy_orders = 6.906906906906906 | Accuracy_mmap = 94.44313117782505\n","Val: Epoch = 25 | Loss 2.141422152519226 | Accuracy = 43.103448275862064\n","Train: Epoch = 26 | Loss = 5.701904860409823 | Loss_orders = 3.2504827976226807 | Accuracy = 53.753753753753756 | Accuracy_orders = 10.21021021021021 | Accuracy_mmap = 94.5578231292517\n","Val: Epoch = 26 | Loss 1.9863956570625305 | Accuracy = 43.103448275862064\n","Train: Epoch = 27 | Loss = 5.583247531544078 | Loss_orders = 3.581925392150879 | Accuracy = 54.35435435435435 | Accuracy_orders = 8.108108108108109 | Accuracy_mmap = 94.51842513067002\n","Val: Epoch = 27 | Loss 1.811989963054657 | Accuracy = 43.96551724137931\n","Train: Epoch = 28 | Loss = 5.2235636711120605 | Loss_orders = 3.273822546005249 | Accuracy = 56.45645645645646 | Accuracy_orders = 16.216216216216218 | Accuracy_mmap = 94.74343147812534\n","Val: Epoch = 28 | Loss 1.7855486273765564 | Accuracy = 45.689655172413794\n","Train: Epoch = 29 | Loss = 5.165295080705122 | Loss_orders = 3.6005985736846924 | Accuracy = 63.36336336336337 | Accuracy_orders = 15.015015015015015 | Accuracy_mmap = 94.48165366532713\n","Val: Epoch = 29 | Loss 1.780443251132965 | Accuracy = 46.55172413793103\n","Train: Epoch = 30 | Loss = 5.1927126104181465 | Loss_orders = 3.2028238773345947 | Accuracy = 56.75675675675676 | Accuracy_orders = 15.615615615615615 | Accuracy_mmap = 94.85374587415404\n","Val: Epoch = 30 | Loss 1.7389289736747742 | Accuracy = 49.137931034482754\n","Train: Epoch = 31 | Loss = 5.120129628614946 | Loss_orders = 4.111934661865234 | Accuracy = 59.15915915915916 | Accuracy_orders = 16.516516516516518 | Accuracy_mmap = 94.63749463749464\n","Val: Epoch = 31 | Loss 1.7413665056228638 | Accuracy = 45.689655172413794\n","Train: Epoch = 32 | Loss = 4.958461024544456 | Loss_orders = 3.08453631401062 | Accuracy = 57.35735735735735 | Accuracy_orders = 17.417417417417415 | Accuracy_mmap = 95.04373177842565\n","Val: Epoch = 32 | Loss 1.721055805683136 | Accuracy = 46.55172413793103\n","Train: Epoch = 33 | Loss = 5.118944211439653 | Loss_orders = 3.2217366695404053 | Accuracy = 54.35435435435435 | Accuracy_orders = 14.414414414414415 | Accuracy_mmap = 95.16717884064822\n","Val: Epoch = 33 | Loss 1.6894648671150208 | Accuracy = 48.275862068965516\n","Train: Epoch = 34 | Loss = 4.560946291143244 | Loss_orders = 3.0447962284088135 | Accuracy = 60.96096096096096 | Accuracy_orders = 22.52252252252252 | Accuracy_mmap = 94.64712525937016\n","Val: Epoch = 34 | Loss 1.7179211378097534 | Accuracy = 46.55172413793103\n","Train: Epoch = 35 | Loss = 4.948941360820424 | Loss_orders = 3.7824695110321045 | Accuracy = 62.46246246246246 | Accuracy_orders = 18.01801801801802 | Accuracy_mmap = 94.80821929801522\n","Val: Epoch = 35 | Loss 1.6800325512886047 | Accuracy = 47.41379310344828\n","Train: Epoch = 36 | Loss = 4.750547582452947 | Loss_orders = 3.279716968536377 | Accuracy = 63.66366366366366 | Accuracy_orders = 22.822822822822822 | Accuracy_mmap = 94.87038058466631\n","Val: Epoch = 36 | Loss 1.6923956274986267 | Accuracy = 45.689655172413794\n","Train: Epoch = 37 | Loss = 4.718867822126909 | Loss_orders = 4.044644832611084 | Accuracy = 58.85885885885885 | Accuracy_orders = 24.024024024024023 | Accuracy_mmap = 95.09013386564406\n","Val: Epoch = 37 | Loss 1.68427973985672 | Accuracy = 48.275862068965516\n","Train: Epoch = 38 | Loss = 4.5319178321144795 | Loss_orders = 3.2630794048309326 | Accuracy = 61.261261261261254 | Accuracy_orders = 24.624624624624623 | Accuracy_mmap = 94.85462138523363\n","Val: Epoch = 38 | Loss 1.6553610563278198 | Accuracy = 49.137931034482754\n","Train: Epoch = 39 | Loss = 4.487617622722279 | Loss_orders = 2.807500123977661 | Accuracy = 60.66066066066066 | Accuracy_orders = 22.52252252252252 | Accuracy_mmap = 94.51492308635166\n","Val: Epoch = 39 | Loss 1.6847177743911743 | Accuracy = 49.137931034482754\n","Train: Epoch = 40 | Loss = 4.527598012577403 | Loss_orders = 2.161391496658325 | Accuracy = 61.261261261261254 | Accuracy_orders = 24.924924924924923 | Accuracy_mmap = 94.27941060594122\n","Val: Epoch = 40 | Loss 1.6981794238090515 | Accuracy = 48.275862068965516\n","Train: Epoch = 41 | Loss = 4.362370859492909 | Loss_orders = 2.9234273433685303 | Accuracy = 63.36336336336337 | Accuracy_orders = 26.426426426426424 | Accuracy_mmap = 94.58496397271907\n","Val: Epoch = 41 | Loss 1.6631945371627808 | Accuracy = 49.137931034482754\n","Train: Epoch = 42 | Loss = 4.357957363128662 | Loss_orders = 2.559366464614868 | Accuracy = 62.76276276276276 | Accuracy_orders = 28.52852852852853 | Accuracy_mmap = 94.32493718208003\n","Val: Epoch = 42 | Loss 1.6735979914665222 | Accuracy = 47.41379310344828\n","Train: Epoch = 43 | Loss = 4.549671433188698 | Loss_orders = 3.4604649543762207 | Accuracy = 57.35735735735735 | Accuracy_orders = 25.225225225225223 | Accuracy_mmap = 94.93604391563575\n","Val: Epoch = 43 | Loss 1.6596540808677673 | Accuracy = 50.0\n","Train: Epoch = 44 | Loss = 4.239344293420965 | Loss_orders = 3.4438300132751465 | Accuracy = 66.36636636636636 | Accuracy_orders = 29.429429429429426 | Accuracy_mmap = 94.28641469457796\n","Val: Epoch = 44 | Loss 1.6154246926307678 | Accuracy = 50.86206896551724\n","Train: Epoch = 45 | Loss = 4.291240041906184 | Loss_orders = 2.8993940353393555 | Accuracy = 62.76276276276276 | Accuracy_orders = 26.726726726726728 | Accuracy_mmap = 94.64537423721097\n","Val: Epoch = 45 | Loss 1.631041407585144 | Accuracy = 51.724137931034484\n","Train: Epoch = 46 | Loss = 4.110496390949596 | Loss_orders = 3.016488790512085 | Accuracy = 62.46246246246246 | Accuracy_orders = 34.53453453453454 | Accuracy_mmap = 94.63661912641504\n","Val: Epoch = 46 | Loss 1.6467758417129517 | Accuracy = 51.724137931034484\n","Train: Epoch = 47 | Loss = 4.272110223770142 | Loss_orders = 3.3690438270568848 | Accuracy = 61.56156156156156 | Accuracy_orders = 35.43543543543544 | Accuracy_mmap = 94.30742696048819\n","Val: Epoch = 47 | Loss 1.6527047753334045 | Accuracy = 50.86206896551724\n","Train: Epoch = 48 | Loss = 4.030084826729515 | Loss_orders = 2.010215997695923 | Accuracy = 63.36336336336337 | Accuracy_orders = 31.53153153153153 | Accuracy_mmap = 94.68302121363345\n","Val: Epoch = 48 | Loss 1.6559255123138428 | Accuracy = 51.724137931034484\n","Train: Epoch = 49 | Loss = 4.192458564584905 | Loss_orders = 2.9604616165161133 | Accuracy = 63.96396396396396 | Accuracy_orders = 32.732732732732735 | Accuracy_mmap = 94.74168045596618\n","Val: Epoch = 49 | Loss 1.6578377485275269 | Accuracy = 50.86206896551724\n","Train: Epoch = 50 | Loss = 3.9885584007609975 | Loss_orders = 2.4590070247650146 | Accuracy = 64.26426426426426 | Accuracy_orders = 32.13213213213213 | Accuracy_mmap = 94.67426610283754\n","Val: Epoch = 50 | Loss 1.6903823614120483 | Accuracy = 49.137931034482754\n","Train: Epoch = 51 | Loss = 4.208865382454612 | Loss_orders = 2.3754217624664307 | Accuracy = 61.261261261261254 | Accuracy_orders = 28.22822822822823 | Accuracy_mmap = 94.5455659741374\n","Val: Epoch = 51 | Loss 1.664616882801056 | Accuracy = 49.137931034482754\n","Train: Epoch = 52 | Loss = 4.244793219999834 | Loss_orders = 3.3447134494781494 | Accuracy = 58.55855855855856 | Accuracy_orders = 30.33033033033033 | Accuracy_mmap = 95.13916248610126\n","Val: Epoch = 52 | Loss 1.6588698029518127 | Accuracy = 50.86206896551724\n","Train: Epoch = 53 | Loss = 3.8051647272976963 | Loss_orders = 2.849097728729248 | Accuracy = 69.36936936936937 | Accuracy_orders = 34.234234234234236 | Accuracy_mmap = 94.73380085624984\n","Val: Epoch = 53 | Loss 1.643427848815918 | Accuracy = 49.137931034482754\n","Train: Epoch = 54 | Loss = 3.8659832694313745 | Loss_orders = 1.6648814678192139 | Accuracy = 64.86486486486487 | Accuracy_orders = 32.13213213213213 | Accuracy_mmap = 94.56395170680885\n","Val: Epoch = 54 | Loss 1.6492528915405273 | Accuracy = 49.137931034482754\n","Train: Epoch = 55 | Loss = 3.780953125520186 | Loss_orders = 2.573106050491333 | Accuracy = 66.36636636636636 | Accuracy_orders = 35.43543543543544 | Accuracy_mmap = 94.4632679326557\n","Val: Epoch = 55 | Loss 1.640550971031189 | Accuracy = 50.86206896551724\n","Train: Epoch = 56 | Loss = 3.9848006421869453 | Loss_orders = 2.7900233268737793 | Accuracy = 65.46546546546547 | Accuracy_orders = 30.630630630630627 | Accuracy_mmap = 94.88351325086019\n","Val: Epoch = 56 | Loss 1.6193290948867798 | Accuracy = 50.86206896551724\n","Train: Epoch = 57 | Loss = 3.7465513836253774 | Loss_orders = 1.8916513919830322 | Accuracy = 66.96696696696696 | Accuracy_orders = 36.63663663663664 | Accuracy_mmap = 94.45538833293935\n","Val: Epoch = 57 | Loss 1.6198965311050415 | Accuracy = 50.0\n","Train: Epoch = 58 | Loss = 3.7514623295177114 | Loss_orders = 1.342604160308838 | Accuracy = 64.56456456456456 | Accuracy_orders = 36.63663663663664 | Accuracy_mmap = 95.05598893353996\n","Val: Epoch = 58 | Loss 1.6264581680297852 | Accuracy = 50.86206896551724\n","Train: Epoch = 59 | Loss = 3.7992019436576148 | Loss_orders = 2.387850046157837 | Accuracy = 65.76576576576578 | Accuracy_orders = 35.13513513513514 | Accuracy_mmap = 94.65062730368852\n","Val: Epoch = 59 | Loss 1.6089556217193604 | Accuracy = 50.86206896551724\n","Train: Epoch = 60 | Loss = 3.831046386198564 | Loss_orders = 2.379932403564453 | Accuracy = 64.86486486486487 | Accuracy_orders = 36.03603603603604 | Accuracy_mmap = 94.67426610283754\n","Val: Epoch = 60 | Loss 1.609035611152649 | Accuracy = 49.137931034482754\n","Train: Epoch = 61 | Loss = 3.6851692416451196 | Loss_orders = 2.8074848651885986 | Accuracy = 68.16816816816817 | Accuracy_orders = 35.13513513513514 | Accuracy_mmap = 94.37571682469643\n","Val: Epoch = 61 | Loss 1.6332589387893677 | Accuracy = 50.0\n","Train: Epoch = 62 | Loss = 3.647514755075628 | Loss_orders = 2.0038034915924072 | Accuracy = 60.96096096096096 | Accuracy_orders = 36.93693693693694 | Accuracy_mmap = 94.20586767525543\n","Val: Epoch = 62 | Loss 1.6142740845680237 | Accuracy = 51.724137931034484\n","Train: Epoch = 63 | Loss = 3.603950175372037 | Loss_orders = 1.7297232151031494 | Accuracy = 65.46546546546547 | Accuracy_orders = 40.24024024024024 | Accuracy_mmap = 94.56044966249047\n","Val: Epoch = 63 | Loss 1.6166932582855225 | Accuracy = 50.0\n","Train: Epoch = 64 | Loss = 3.4720927585255015 | Loss_orders = 1.6947803497314453 | Accuracy = 66.96696696696696 | Accuracy_orders = 40.24024024024024 | Accuracy_mmap = 94.54994352953537\n","Val: Epoch = 64 | Loss 1.6358723044395447 | Accuracy = 50.86206896551724\n","Train: Epoch = 65 | Loss = 3.4365517659620806 | Loss_orders = 2.0480222702026367 | Accuracy = 69.06906906906907 | Accuracy_orders = 38.13813813813814 | Accuracy_mmap = 94.34682495906985\n","Val: Epoch = 65 | Loss 1.6547428369522095 | Accuracy = 49.137931034482754\n","Train: Epoch = 66 | Loss = 3.701574997468428 | Loss_orders = 2.7429628372192383 | Accuracy = 69.36936936936937 | Accuracy_orders = 37.83783783783784 | Accuracy_mmap = 94.53856188550066\n","Val: Epoch = 66 | Loss 1.6166019439697266 | Accuracy = 50.86206896551724\n","Train: Epoch = 67 | Loss = 3.619805769486861 | Loss_orders = 2.1938815116882324 | Accuracy = 66.06606606606607 | Accuracy_orders = 38.13813813813814 | Accuracy_mmap = 94.74168045596618\n","Val: Epoch = 67 | Loss 1.6093143224716187 | Accuracy = 51.724137931034484\n","Train: Epoch = 68 | Loss = 3.4727091139013115 | Loss_orders = 1.9288063049316406 | Accuracy = 66.96696696696696 | Accuracy_orders = 42.94294294294294 | Accuracy_mmap = 94.40898624572094\n","Val: Epoch = 68 | Loss 1.621947705745697 | Accuracy = 49.137931034482754\n","Train: Epoch = 69 | Loss = 3.510294892571189 | Loss_orders = 1.8707671165466309 | Accuracy = 65.76576576576578 | Accuracy_orders = 39.33933933933934 | Accuracy_mmap = 94.93954595995412\n","Val: Epoch = 69 | Loss 1.6023111939430237 | Accuracy = 50.0\n","Train: Epoch = 70 | Loss = 3.3435697122053667 | Loss_orders = 2.3231706619262695 | Accuracy = 69.36936936936937 | Accuracy_orders = 45.04504504504504 | Accuracy_mmap = 94.60247419431093\n","Val: Epoch = 70 | Loss 1.6004164218902588 | Accuracy = 50.86206896551724\n","Train: Epoch = 71 | Loss = 3.5010192827744917 | Loss_orders = 2.8589818477630615 | Accuracy = 69.96996996996997 | Accuracy_orders = 42.04204204204204 | Accuracy_mmap = 95.1452910636584\n","Val: Epoch = 71 | Loss 1.5884347558021545 | Accuracy = 50.86206896551724\n","Train: Epoch = 72 | Loss = 3.512189648368142 | Loss_orders = 2.5126729011535645 | Accuracy = 63.36336336336337 | Accuracy_orders = 45.94594594594595 | Accuracy_mmap = 94.664635480962\n","Val: Epoch = 72 | Loss 1.6001739501953125 | Accuracy = 52.58620689655172\n","Train: Epoch = 73 | Loss = 3.471353227441961 | Loss_orders = 1.7169963121414185 | Accuracy = 69.06906906906907 | Accuracy_orders = 42.34234234234234 | Accuracy_mmap = 94.48953326504346\n","Val: Epoch = 73 | Loss 1.6209876537322998 | Accuracy = 51.724137931034484\n","Train: Epoch = 74 | Loss = 3.5750069184736772 | Loss_orders = 2.5891926288604736 | Accuracy = 68.46846846846847 | Accuracy_orders = 42.64264264264264 | Accuracy_mmap = 94.39497806844746\n","Val: Epoch = 74 | Loss 1.6046638488769531 | Accuracy = 53.44827586206896\n","Train: Epoch = 75 | Loss = 3.1658195582303135 | Loss_orders = 1.252977967262268 | Accuracy = 68.76876876876878 | Accuracy_orders = 45.94594594594595 | Accuracy_mmap = 94.91853369404389\n","Val: Epoch = 75 | Loss 1.6144349575042725 | Accuracy = 52.58620689655172\n","Train: Epoch = 76 | Loss = 3.3296303098851983 | Loss_orders = 2.1371943950653076 | Accuracy = 64.56456456456456 | Accuracy_orders = 42.64264264264264 | Accuracy_mmap = 94.48077815424755\n","Val: Epoch = 76 | Loss 1.6140245199203491 | Accuracy = 52.58620689655172\n","Train: Epoch = 77 | Loss = 3.4385370124470103 | Loss_orders = 2.343066930770874 | Accuracy = 66.06606606606607 | Accuracy_orders = 42.94294294294294 | Accuracy_mmap = 94.61385583834564\n","Val: Epoch = 77 | Loss 1.6143656373023987 | Accuracy = 51.724137931034484\n","Train: Epoch = 78 | Loss = 3.2616123502904717 | Loss_orders = 1.8165758848190308 | Accuracy = 69.06906906906907 | Accuracy_orders = 44.14414414414414 | Accuracy_mmap = 94.82572951960707\n","Val: Epoch = 78 | Loss 1.6152299046516418 | Accuracy = 50.86206896551724\n","Train: Epoch = 79 | Loss = 3.30628041787581 | Loss_orders = 2.9637184143066406 | Accuracy = 66.36636636636636 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.41949237867605\n","Val: Epoch = 79 | Loss 1.6102924346923828 | Accuracy = 50.86206896551724\n","Train: Epoch = 80 | Loss = 3.0658136281100186 | Loss_orders = 1.457914113998413 | Accuracy = 71.77177177177178 | Accuracy_orders = 44.44444444444444 | Accuracy_mmap = 94.76269272187639\n","Val: Epoch = 80 | Loss 1.610958993434906 | Accuracy = 51.724137931034484\n","Train: Epoch = 81 | Loss = 3.242935960943049 | Loss_orders = 1.7925351858139038 | Accuracy = 66.66666666666666 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.41949237867605\n","Val: Epoch = 81 | Loss 1.6102373003959656 | Accuracy = 51.724137931034484\n","Train: Epoch = 82 | Loss = 3.256767511367798 | Loss_orders = 2.202956199645996 | Accuracy = 72.37237237237237 | Accuracy_orders = 45.34534534534534 | Accuracy_mmap = 94.76794578835394\n","Val: Epoch = 82 | Loss 1.6101818680763245 | Accuracy = 53.44827586206896\n","Train: Epoch = 83 | Loss = 3.105177402496338 | Loss_orders = 1.528650164604187 | Accuracy = 68.16816816816817 | Accuracy_orders = 44.74474474474475 | Accuracy_mmap = 94.00975319342666\n","Val: Epoch = 83 | Loss 1.6078041195869446 | Accuracy = 52.58620689655172\n","Train: Epoch = 84 | Loss = 3.2944899689067495 | Loss_orders = 2.0620977878570557 | Accuracy = 69.96996996996997 | Accuracy_orders = 47.147147147147145 | Accuracy_mmap = 94.34507393691067\n","Val: Epoch = 84 | Loss 1.6035122871398926 | Accuracy = 51.724137931034484\n","Train: Epoch = 85 | Loss = 3.343696507540616 | Loss_orders = 2.44132661819458 | Accuracy = 69.66966966966966 | Accuracy_orders = 43.84384384384384 | Accuracy_mmap = 94.6068517497089\n","Val: Epoch = 85 | Loss 1.5994035601615906 | Accuracy = 51.724137931034484\n","Train: Epoch = 86 | Loss = 3.2535976496609775 | Loss_orders = 1.6243927478790283 | Accuracy = 67.86786786786787 | Accuracy_orders = 44.44444444444444 | Accuracy_mmap = 94.95880720370516\n","Val: Epoch = 86 | Loss 1.595943033695221 | Accuracy = 53.44827586206896\n","Train: Epoch = 87 | Loss = 2.9470336003737017 | Loss_orders = 1.73483145236969 | Accuracy = 67.86786786786787 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.26802896190651\n","Val: Epoch = 87 | Loss 1.5922004580497742 | Accuracy = 52.58620689655172\n","Train: Epoch = 88 | Loss = 3.0978009700775146 | Loss_orders = 1.8308981657028198 | Accuracy = 69.66966966966966 | Accuracy_orders = 47.44744744744745 | Accuracy_mmap = 94.41774135651687\n","Val: Epoch = 88 | Loss 1.5906023383140564 | Accuracy = 52.58620689655172\n","Train: Epoch = 89 | Loss = 3.0297635902057993 | Loss_orders = 1.75363290309906 | Accuracy = 69.66966966966966 | Accuracy_orders = 50.45045045045045 | Accuracy_mmap = 94.73029881193146\n","Val: Epoch = 89 | Loss 1.5931906700134277 | Accuracy = 52.58620689655172\n","Train: Epoch = 90 | Loss = 3.294728777625344 | Loss_orders = 1.8188375234603882 | Accuracy = 68.46846846846847 | Accuracy_orders = 43.84384384384384 | Accuracy_mmap = 95.27749323667692\n","Val: Epoch = 90 | Loss 1.5900853276252747 | Accuracy = 52.58620689655172\n","Train: Epoch = 91 | Loss = 3.060897848822854 | Loss_orders = 1.9300733804702759 | Accuracy = 70.57057057057057 | Accuracy_orders = 49.549549549549546 | Accuracy_mmap = 94.58583948379868\n","Val: Epoch = 91 | Loss 1.5901690125465393 | Accuracy = 52.58620689655172\n","Train: Epoch = 92 | Loss = 3.2457838275215845 | Loss_orders = 2.845089912414551 | Accuracy = 68.76876876876878 | Accuracy_orders = 49.849849849849846 | Accuracy_mmap = 94.61385583834564\n","Val: Epoch = 92 | Loss 1.5904000997543335 | Accuracy = 52.58620689655172\n","Train: Epoch = 93 | Loss = 3.276537309993397 | Loss_orders = 2.1606028079986572 | Accuracy = 67.56756756756756 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.27590856162284\n","Val: Epoch = 93 | Loss 1.5905181169509888 | Accuracy = 51.724137931034484\n","Train: Epoch = 94 | Loss = 3.1631443067030474 | Loss_orders = 1.5802279710769653 | Accuracy = 70.27027027027027 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 94.89139285057652\n","Val: Epoch = 94 | Loss 1.5910359621047974 | Accuracy = 52.58620689655172\n","Train: Epoch = 95 | Loss = 3.1604198109019888 | Loss_orders = 1.5437918901443481 | Accuracy = 67.86786786786787 | Accuracy_orders = 45.04504504504504 | Accuracy_mmap = 94.69265183550898\n","Val: Epoch = 95 | Loss 1.5867001414299011 | Accuracy = 52.58620689655172\n","Train: Epoch = 96 | Loss = 3.1610031344673852 | Loss_orders = 1.4874987602233887 | Accuracy = 70.57057057057057 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 95.07962773268895\n","Val: Epoch = 96 | Loss 1.5852208733558655 | Accuracy = 52.58620689655172\n","Train: Epoch = 97 | Loss = 2.9307498281652276 | Loss_orders = 1.4857394695281982 | Accuracy = 73.27327327327328 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 94.76882129943355\n","Val: Epoch = 97 | Loss 1.589967429637909 | Accuracy = 52.58620689655172\n","Train: Epoch = 98 | Loss = 3.0125413591211494 | Loss_orders = 1.3871738910675049 | Accuracy = 69.96996996996997 | Accuracy_orders = 51.35135135135135 | Accuracy_mmap = 94.63136605993749\n","Val: Epoch = 98 | Loss 1.5918514132499695 | Accuracy = 52.58620689655172\n","Train: Epoch = 99 | Loss = 3.2024353417483242 | Loss_orders = 1.2461439371109009 | Accuracy = 68.46846846846847 | Accuracy_orders = 50.45045045045045 | Accuracy_mmap = 94.30917798264737\n","Val: Epoch = 99 | Loss 1.5917091965675354 | Accuracy = 52.58620689655172\n","Train: Epoch = 100 | Loss = 3.1564875732768667 | Loss_orders = 2.6657919883728027 | Accuracy = 72.67267267267268 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.72241921221513\n","Val: Epoch = 100 | Loss 1.590282142162323 | Accuracy = 52.58620689655172\n","Train: Epoch = 101 | Loss = 3.191291267221624 | Loss_orders = 1.013393521308899 | Accuracy = 71.77177177177178 | Accuracy_orders = 46.246246246246244 | Accuracy_mmap = 94.88876631733774\n","Val: Epoch = 101 | Loss 1.5857458114624023 | Accuracy = 52.58620689655172\n","Train: Epoch = 102 | Loss = 2.849107698960738 | Loss_orders = 1.9208635091781616 | Accuracy = 74.77477477477478 | Accuracy_orders = 51.35135135135135 | Accuracy_mmap = 94.18748194258399\n","Val: Epoch = 102 | Loss 1.5839704275131226 | Accuracy = 52.58620689655172\n","Train: Epoch = 103 | Loss = 2.9628396684473213 | Loss_orders = 1.621034860610962 | Accuracy = 71.77177177177178 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.72154370113553\n","Val: Epoch = 103 | Loss 1.5824328660964966 | Accuracy = 53.44827586206896\n","Train: Epoch = 104 | Loss = 3.0520192926580254 | Loss_orders = 1.7833117246627808 | Accuracy = 71.47147147147147 | Accuracy_orders = 46.246246246246244 | Accuracy_mmap = 94.84936831875608\n","Val: Epoch = 104 | Loss 1.5778213739395142 | Accuracy = 53.44827586206896\n","Train: Epoch = 105 | Loss = 3.210328774018721 | Loss_orders = 1.403071641921997 | Accuracy = 65.76576576576578 | Accuracy_orders = 45.94594594594595 | Accuracy_mmap = 94.82748054176625\n","Val: Epoch = 105 | Loss 1.575439453125 | Accuracy = 53.44827586206896\n","Train: Epoch = 106 | Loss = 3.17561767318032 | Loss_orders = 2.6497578620910645 | Accuracy = 71.17117117117117 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 94.61998441590278\n","Val: Epoch = 106 | Loss 1.573621153831482 | Accuracy = 52.58620689655172\n","Train: Epoch = 107 | Loss = 3.0988802909851074 | Loss_orders = 1.8277256488800049 | Accuracy = 71.77177177177178 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.17872683178805\n","Val: Epoch = 107 | Loss 1.571172833442688 | Accuracy = 53.44827586206896\n","Train: Epoch = 108 | Loss = 2.896943612532182 | Loss_orders = 2.1276204586029053 | Accuracy = 73.87387387387388 | Accuracy_orders = 49.849849849849846 | Accuracy_mmap = 94.62173543806198\n","Val: Epoch = 108 | Loss 1.5709913969039917 | Accuracy = 53.44827586206896\n","Train: Epoch = 109 | Loss = 3.0867796377702192 | Loss_orders = 1.376391887664795 | Accuracy = 68.76876876876878 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 95.10326653183796\n","Val: Epoch = 109 | Loss 1.5705780982971191 | Accuracy = 53.44827586206896\n","Train: Epoch = 110 | Loss = 3.135284120386297 | Loss_orders = 1.2627155780792236 | Accuracy = 71.47147147147147 | Accuracy_orders = 45.645645645645644 | Accuracy_mmap = 95.1452910636584\n","Val: Epoch = 110 | Loss 1.5723432302474976 | Accuracy = 53.44827586206896\n","Train: Epoch = 111 | Loss = 3.169337511062622 | Loss_orders = 2.1260170936584473 | Accuracy = 67.26726726726727 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.94042147103372\n","Val: Epoch = 111 | Loss 1.5748658776283264 | Accuracy = 53.44827586206896\n","Train: Epoch = 112 | Loss = 3.0878766883503306 | Loss_orders = 1.5530779361724854 | Accuracy = 66.66666666666666 | Accuracy_orders = 48.348348348348345 | Accuracy_mmap = 94.55081904061497\n","Val: Epoch = 112 | Loss 1.5765659809112549 | Accuracy = 53.44827586206896\n","Train: Epoch = 113 | Loss = 3.076405070044778 | Loss_orders = 1.493013858795166 | Accuracy = 70.27027027027027 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 94.79946418721929\n","Val: Epoch = 113 | Loss 1.579345941543579 | Accuracy = 53.44827586206896\n","Train: Epoch = 114 | Loss = 3.149487473747947 | Loss_orders = 1.542267084121704 | Accuracy = 64.86486486486487 | Accuracy_orders = 47.147147147147145 | Accuracy_mmap = 94.72241921221513\n","Val: Epoch = 114 | Loss 1.5848041772842407 | Accuracy = 52.58620689655172\n","Train: Epoch = 115 | Loss = 3.215416431427002 | Loss_orders = 2.068265914916992 | Accuracy = 69.06906906906907 | Accuracy_orders = 49.549549549549546 | Accuracy_mmap = 95.07612568837058\n","Val: Epoch = 115 | Loss 1.5885273814201355 | Accuracy = 52.58620689655172\n","Train: Epoch = 116 | Loss = 2.973631988872181 | Loss_orders = 1.2826842069625854 | Accuracy = 71.77177177177178 | Accuracy_orders = 46.846846846846844 | Accuracy_mmap = 94.31092900480655\n","Val: Epoch = 116 | Loss 1.5875679850578308 | Accuracy = 52.58620689655172\n","Train: Epoch = 117 | Loss = 3.003155686638572 | Loss_orders = 1.7155753374099731 | Accuracy = 69.66966966966966 | Accuracy_orders = 51.35135135135135 | Accuracy_mmap = 94.79683765398052\n","Val: Epoch = 117 | Loss 1.5903218984603882 | Accuracy = 52.58620689655172\n","Train: Epoch = 118 | Loss = 2.8295679959383877 | Loss_orders = 1.6634987592697144 | Accuracy = 74.47447447447448 | Accuracy_orders = 58.25825825825825 | Accuracy_mmap = 94.75393761108046\n","Val: Epoch = 118 | Loss 1.593545377254486 | Accuracy = 52.58620689655172\n","Train: Epoch = 119 | Loss = 3.234371943907304 | Loss_orders = 1.85049569606781 | Accuracy = 65.46546546546547 | Accuracy_orders = 49.549549549549546 | Accuracy_mmap = 94.6191089048232\n","Val: Epoch = 119 | Loss 1.5876651406288147 | Accuracy = 52.58620689655172\n","Train: Epoch = 120 | Loss = 3.1630513884804468 | Loss_orders = 2.355513572692871 | Accuracy = 69.36936936936937 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.8353601414826\n","Val: Epoch = 120 | Loss 1.5855742692947388 | Accuracy = 53.44827586206896\n","Train: Epoch = 121 | Loss = 3.0340440706773237 | Loss_orders = 2.566512107849121 | Accuracy = 71.77177177177178 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.33106575963718\n","Val: Epoch = 121 | Loss 1.5892939567565918 | Accuracy = 53.44827586206896\n","Train: Epoch = 122 | Loss = 2.9838945215398613 | Loss_orders = 1.9760286808013916 | Accuracy = 70.57057057057057 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.76269272187639\n","Val: Epoch = 122 | Loss 1.591619610786438 | Accuracy = 53.44827586206896\n","Train: Epoch = 123 | Loss = 3.0278353040868584 | Loss_orders = 1.3169214725494385 | Accuracy = 70.87087087087087 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.37396580253723\n","Val: Epoch = 123 | Loss 1.5934399366378784 | Accuracy = 53.44827586206896\n","Train: Epoch = 124 | Loss = 3.1629201390526513 | Loss_orders = 2.5170907974243164 | Accuracy = 70.27027027027027 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.23563505196158\n","Val: Epoch = 124 | Loss 1.5935652256011963 | Accuracy = 53.44827586206896\n","Train: Epoch = 125 | Loss = 2.8441017757762563 | Loss_orders = 1.6453826427459717 | Accuracy = 71.17117117117117 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 94.40373317924339\n","Val: Epoch = 125 | Loss 1.595111608505249 | Accuracy = 53.44827586206896\n","Train: Epoch = 126 | Loss = 3.261834903196855 | Loss_orders = 1.6357072591781616 | Accuracy = 66.06606606606607 | Accuracy_orders = 43.84384384384384 | Accuracy_mmap = 94.64099668181301\n","Val: Epoch = 126 | Loss 1.5949174165725708 | Accuracy = 53.44827586206896\n","Train: Epoch = 127 | Loss = 3.1488111235878686 | Loss_orders = 1.5364209413528442 | Accuracy = 67.86786786786787 | Accuracy_orders = 48.348348348348345 | Accuracy_mmap = 94.54381495197822\n","Val: Epoch = 127 | Loss 1.5931820273399353 | Accuracy = 54.310344827586206\n","Train: Epoch = 128 | Loss = 2.9962050264531914 | Loss_orders = 2.22756028175354 | Accuracy = 72.07207207207207 | Accuracy_orders = 52.552552552552555 | Accuracy_mmap = 94.69177632442938\n","Val: Epoch = 128 | Loss 1.5911412239074707 | Accuracy = 54.310344827586206\n","Train: Epoch = 129 | Loss = 2.839919393712824 | Loss_orders = 1.758716344833374 | Accuracy = 73.57357357357357 | Accuracy_orders = 53.453453453453456 | Accuracy_mmap = 94.74518250028454\n","Val: Epoch = 129 | Loss 1.5929772853851318 | Accuracy = 54.310344827586206\n","Train: Epoch = 130 | Loss = 3.2673466205596924 | Loss_orders = 2.170630931854248 | Accuracy = 62.46246246246246 | Accuracy_orders = 45.04504504504504 | Accuracy_mmap = 94.99645418012766\n","Val: Epoch = 130 | Loss 1.5902199149131775 | Accuracy = 54.310344827586206\n","Train: Epoch = 131 | Loss = 3.1048143993724477 | Loss_orders = 1.7922892570495605 | Accuracy = 66.96696696696696 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.82047645312952\n","Val: Epoch = 131 | Loss 1.5883954763412476 | Accuracy = 54.310344827586206\n","Train: Epoch = 132 | Loss = 3.2384472543543037 | Loss_orders = 2.293915033340454 | Accuracy = 66.06606606606607 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.95618067046638\n","Val: Epoch = 132 | Loss 1.5897462964057922 | Accuracy = 54.310344827586206\n","Train: Epoch = 133 | Loss = 2.9864705259149726 | Loss_orders = 1.3749260902404785 | Accuracy = 72.07207207207207 | Accuracy_orders = 49.849849849849846 | Accuracy_mmap = 94.71016205710083\n","Val: Epoch = 133 | Loss 1.59173184633255 | Accuracy = 54.310344827586206\n","Train: Epoch = 134 | Loss = 3.026752320202914 | Loss_orders = 1.4574661254882812 | Accuracy = 67.86786786786787 | Accuracy_orders = 51.35135135135135 | Accuracy_mmap = 94.75218658892129\n","Val: Epoch = 134 | Loss 1.5920682549476624 | Accuracy = 52.58620689655172\n","Train: Epoch = 135 | Loss = 2.761190327731046 | Loss_orders = 0.9310836791992188 | Accuracy = 73.87387387387388 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.24876771815546\n","Val: Epoch = 135 | Loss 1.5914550423622131 | Accuracy = 53.44827586206896\n","Train: Epoch = 136 | Loss = 2.928068919615312 | Loss_orders = 1.19878089427948 | Accuracy = 70.87087087087087 | Accuracy_orders = 48.94894894894895 | Accuracy_mmap = 94.33194127071678\n","Val: Epoch = 136 | Loss 1.5905723571777344 | Accuracy = 53.44827586206896\n","Train: Epoch = 137 | Loss = 3.0522876652804287 | Loss_orders = 2.0485682487487793 | Accuracy = 68.76876876876878 | Accuracy_orders = 52.25225225225225 | Accuracy_mmap = 94.48428019856591\n","Val: Epoch = 137 | Loss 1.5892388820648193 | Accuracy = 53.44827586206896\n","Train: Epoch = 138 | Loss = 3.0242539535869253 | Loss_orders = 1.3182365894317627 | Accuracy = 69.06906906906907 | Accuracy_orders = 48.348348348348345 | Accuracy_mmap = 94.7014069463049\n","Val: Epoch = 138 | Loss 1.5844556093215942 | Accuracy = 52.58620689655172\n","Train: Epoch = 139 | Loss = 3.037356571717696 | Loss_orders = 2.1953585147857666 | Accuracy = 72.37237237237237 | Accuracy_orders = 54.65465465465466 | Accuracy_mmap = 94.62173543806198\n","Val: Epoch = 139 | Loss 1.5786941051483154 | Accuracy = 52.58620689655172\n","Train: Epoch = 140 | Loss = 3.013802246613936 | Loss_orders = 2.0719025135040283 | Accuracy = 72.67267267267268 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.61035379402728\n","Val: Epoch = 140 | Loss 1.5769314765930176 | Accuracy = 53.44827586206896\n","Train: Epoch = 141 | Loss = 3.015521851452914 | Loss_orders = 1.5143579244613647 | Accuracy = 67.56756756756756 | Accuracy_orders = 52.552552552552555 | Accuracy_mmap = 94.4860312207251\n","Val: Epoch = 141 | Loss 1.574156641960144 | Accuracy = 53.44827586206896\n","Train: Epoch = 142 | Loss = 2.901955582878806 | Loss_orders = 2.037062168121338 | Accuracy = 69.66966966966966 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 94.91590716080512\n","Val: Epoch = 142 | Loss 1.5739352107048035 | Accuracy = 53.44827586206896\n","Train: Epoch = 143 | Loss = 2.8922310959209097 | Loss_orders = 1.7371480464935303 | Accuracy = 69.36936936936937 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.40023113492502\n","Val: Epoch = 143 | Loss 1.5753453373908997 | Accuracy = 54.310344827586206\n","Train: Epoch = 144 | Loss = 2.945292364467274 | Loss_orders = 1.6373738050460815 | Accuracy = 69.06906906906907 | Accuracy_orders = 52.85285285285285 | Accuracy_mmap = 94.97456640313783\n","Val: Epoch = 144 | Loss 1.5783708691596985 | Accuracy = 54.310344827586206\n","Train: Epoch = 145 | Loss = 2.9251361976970327 | Loss_orders = 1.2368031740188599 | Accuracy = 69.96996996996997 | Accuracy_orders = 49.549549549549546 | Accuracy_mmap = 94.47902713208836\n","Val: Epoch = 145 | Loss 1.582522988319397 | Accuracy = 53.44827586206896\n","Train: Epoch = 146 | Loss = 3.077702435580167 | Loss_orders = 2.117361545562744 | Accuracy = 69.66966966966966 | Accuracy_orders = 52.25225225225225 | Accuracy_mmap = 95.0253460457542\n","Val: Epoch = 146 | Loss 1.5858687162399292 | Accuracy = 52.58620689655172\n","Train: Epoch = 147 | Loss = 3.089724367315119 | Loss_orders = 1.9557068347930908 | Accuracy = 70.27027027027027 | Accuracy_orders = 49.549549549549546 | Accuracy_mmap = 94.21024523065338\n","Val: Epoch = 147 | Loss 1.5880218744277954 | Accuracy = 52.58620689655172\n","Train: Epoch = 148 | Loss = 3.1231304082003506 | Loss_orders = 1.564788579940796 | Accuracy = 67.56756756756756 | Accuracy_orders = 47.44744744744745 | Accuracy_mmap = 94.90802756108879\n","Val: Epoch = 148 | Loss 1.5887913703918457 | Accuracy = 53.44827586206896\n","Train: Epoch = 149 | Loss = 3.158922542225231 | Loss_orders = 2.00620174407959 | Accuracy = 67.56756756756756 | Accuracy_orders = 53.453453453453456 | Accuracy_mmap = 94.16121661019619\n","Val: Epoch = 149 | Loss 1.5856386423110962 | Accuracy = 53.44827586206896\n","Train: Epoch = 150 | Loss = 2.8945408084175805 | Loss_orders = 1.8387843370437622 | Accuracy = 72.97297297297297 | Accuracy_orders = 50.45045045045045 | Accuracy_mmap = 94.80033969829888\n","Val: Epoch = 150 | Loss 1.5826515555381775 | Accuracy = 53.44827586206896\n","Best accuracy after 149 epochs = 54.310344827586206\n"],"name":"stdout"}]}]}