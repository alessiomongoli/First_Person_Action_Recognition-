{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[7]main-run-self-supervision-order-frame-task-4frame.ipynb","provenance":[{"file_id":"1_kL7S7gV2ViVkfDpl2Yu7sfXQ7qEiQyM","timestamp":1593361825687},{"file_id":"1yY2yCYV2x_mc_2G8p0AAGvsGleOUzWR4","timestamp":1593341228163},{"file_id":"1_jLW1lBjVXQP7dzTVxRPbe0R0mwmxQD8","timestamp":1593331106754},{"file_id":"1TDK4af2_QYZFGad4A_FuUWOPmwDG9Jsm","timestamp":1593288338250},{"file_id":"1STeTl111HNDVstz3no9L3XEYu-h0VgP-","timestamp":1593273590149},{"file_id":"17k1c8DNm4_OqwAZZvpfGGtDX0xiRiiGJ","timestamp":1593154626125},{"file_id":"1c8zt-uJk3GrWvhejPlyge3p1OzqIY13Y","timestamp":1593123364356},{"file_id":"1usVuxmxfl5_nyCEHzaTY1OmZ1tYP26RF","timestamp":1593112974129},{"file_id":"17pIXf2DMmnxHCFPE2q7MTUWaL7OO6agh","timestamp":1592993427869},{"file_id":"1qKvOEF_HpFgfNeLIVccrQkPvdpsntD13","timestamp":1592578578043},{"file_id":"1AUBzt934w_qGM2iFZ1W1E-shHOsrZ7xd","timestamp":1591609652291},{"file_id":"1mUQO5jmnTOUFlkOJ_bByUyBmf1UQz4yN","timestamp":1590686870832}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Y1PXD2NL4Nxf","colab_type":"text"},"source":["**Install requirements**"]},{"cell_type":"code","metadata":{"id":"HjRb9K14hW_l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1593419652734,"user_tz":-120,"elapsed":3513,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"65f0e2dc-6da9-45c0-f98b-d763cb806e47"},"source":["!pip3 install 'tensorboardX' "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (47.3.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jBdMq5aF4YHP","colab_type":"text"},"source":["**Import Google Drive**"]},{"cell_type":"code","metadata":{"id":"4Db3Jwa4tG-q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593419652735,"user_tz":-120,"elapsed":3498,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"080a779d-fd44-4bd6-92d7-67788710d108"},"source":["# Load the Drive helper and mount\n","from google.colab import drive\n","import os\n","drive.mount('/content/drive')\n","\n","path = 'drive/My Drive/ego-rnn/'\n","os.chdir(path)\n","cwd = os.getcwd()\n","print(\"Current dir: \"+cwd)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Current dir: /content/drive/My Drive/ego-rnn\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"KhQZjOdN4Unu","colab_type":"text"},"source":["**Import libraries**"]},{"cell_type":"code","metadata":{"id":"t3mf6kG2OBPO","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","from spatial_transforms import (Compose, ToTensor, CenterCrop, Scale, Normalize, MultiScaleCornerCrop,\n","                                RandomHorizontalFlip)\n","from tensorboardX import SummaryWriter\n","from makeDatasetRGB import *\n","from MyConvLSTMCell import *\n","\n","import argparse\n","import sys\n","import matplotlib.pyplot as plt\n","\n","import os\n","import torch\n","from torch.utils.data import Dataset\n","from PIL import Image\n","import numpy as np\n","import glob\n","from random import random\n","\n","import torch.nn as nn\n","import math\n","import torch.utils.model_zoo as model_zoo\n","import torchvision\n","\n","from torchvision import transforms\n","from itertools import permutations, combinations\n","import spatial_transforms \n","\n","from torch.autograd import Variable\n","from torch.nn import functional as F\n","from resnetMod import *"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MtG7gqJQ8c8i","colab_type":"code","colab":{}},"source":["def build_permutations(frame, classes=12):\n","  a_list = np.linspace(0, frame, frame, endpoint=False, dtype=int)\n","\n","  permutations_object = permutations(a_list)\n","  permutations_list = np.array(list(permutations_object))\n","  hamming_dist = []\n","\n","  for i,(A) in enumerate(permutations_list):\n","    hamming_dist.append(sum([np.count_nonzero((A == B) == False) for B in permutations_list]))\n","\n","  permutations_list = np.array([permutations_list[i] for i in sorted(range(len(hamming_dist)), key=hamming_dist.__getitem__, reverse=True)])[:classes]\n","  np.random.shuffle(permutations_list)\n","\n","  return permutations_list\n","\n","def gen_split_mmaps(root_dir, stackSize, dir_users):\n","    Dataset = []\n","    Mmaps = []\n","    Labels = []\n","    \n","    classes = []\n","    \n","    for user in ['S1','S2','S3','S4']:\n","        user_dir = os.path.join(root_dir, user)\n","        classes.extend(dir for dir in os.listdir(user_dir) if os.path.isdir(os.path.join(user_dir, dir)))\n","    \n","    classes = list(set(classes))\n","    classes.sort()\n","    class_to_idx = {classes[i]: i for i in range(len(classes))}\n","        \n","    for dir_user in dir_users:\n","\n","        dir = os.path.join(root_dir, dir_user)\n","\n","        for target in sorted(os.listdir(dir)): # into folder user\n","            dir1 = os.path.join(dir, target) \n","            if os.path.isdir(dir1):\n","                insts = sorted(os.listdir(dir1)) # into single action folder\n","                if insts != []:\n","                    for inst in insts:\n","                        inst_dir = os.path.join(dir1, inst+'/mmaps') # into element folder of action\n","                        numFrames_mmaps = len(glob.glob1(inst_dir, '*.png'))\n","                        numFrames_rgb = len(glob.glob1(os.path.join(dir1, inst+'/rgb'), '*.png'))\n","                        if numFrames_mmaps >= stackSize and numFrames_mmaps >= stackSize  >= stackSize:\n","                            Mmaps.append(inst_dir)\n","                            Dataset.append(os.path.join(dir1, inst+'/rgb'))\n","                            Labels.append(class_to_idx[target])\n","                \n","    return Dataset, Mmaps, Labels\n","\n","class makeDatasetMmaps(Dataset):\n","    def __init__(self, root_dir, dir_users, numFrame, orders_classes = 12, spatial_transform=None, normalize=None, seqLen=20,\n","                 train=True, mulSeg=False, numSeg=1, fmt='.png'):\n","\n","        self.images, self.mmaps, self.labels = gen_split_mmaps(root_dir, numFrame, dir_users)\n","        self.spatial_transform = spatial_transform \n","        self.normalize = normalize\n","        self.train = train\n","        self.mulSeg = mulSeg\n","        self.numSeg = numSeg\n","        self.numFrame = numFrame\n","        self.seqLen = seqLen\n","        self.fmt = fmt\n","\n","        self.spatial_transform_rgb = spatial_transforms.Compose([spatial_transforms.ToTensor(), self.normalize])\n","        self.spatial_transform_mmaps = transforms.Compose([transforms.Resize(7), transforms.ToTensor()])\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        vid_name = self.images[idx]\n","        vid_mmaps = self.mmaps[idx]\n","        label = self.labels[idx]\n","        inpSeq = []\n","        inpSeq_mmaps = []\n","\n","        order = np.random.randint(orders_classes)\n","        \n","        self.spatial_transform.randomize_parameters()\n","\n","        for i in np.linspace(1, self.numFrame, self.numFrame, endpoint=True):\n","            fl_name = vid_name + '/' + 'rgb' + str(int(np.floor(i))).zfill(4) + self.fmt\n","            img = Image.open(fl_name)\n","            inpSeq.append(self.spatial_transform_rgb(self.spatial_transform(img.convert('RGB'))))\n","            \n","\n","            fl_name_mmaps = vid_mmaps + '/' + 'map' + str(int(np.floor(i))).zfill(4) + self.fmt\n","            if not os.path.exists(fl_name_mmaps):\n","                fl_name_mmaps = vid_mmaps + '/' + 'map' + str(int(np.floor(i+1))).zfill(4) + self.fmt\n","            \n","            img_mmap = Image.open(fl_name_mmaps)\n","            inpSeq_mmaps.append(self.spatial_transform_mmaps(self.spatial_transform(img_mmap.convert('1'))))\n","\n","        inpSeq = torch.stack(inpSeq, 0)\n","        inpSeq_mmaps = torch.stack(inpSeq_mmaps, 0)\n","        return inpSeq, inpSeq_mmaps, label, int(order)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KRoOMlKgKWEZ","colab_type":"code","colab":{}},"source":["class MyMotionSegCell(nn.Module):\n","\n","    def __init__(self, kernel_size=1, stride=1, padding=0):\n","        super(MyMotionSegCell, self).__init__()\n","\n","        self.relu = nn.ReLU()\n","        self.ms_conv = nn.Conv2d(512, 100, kernel_size=1, stride=1, padding=0, bias=False)\n","        self.ms_fc = nn.Linear(100 * 7 * 7, 2 * 7 * 7)\n","\n","    def forward(self, x):\n","        x = self.relu(x)\n","        x = self.ms_conv(x)\n","        x = x.view(x.size(0),100*7*7)\n","        x = self.ms_fc(x)\n","        x = x.view(x.size(0),2,7,7)\n","\n","        return x\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxsAZ6NXUOvc","colab_type":"code","colab":{}},"source":["def build_combinations(frame):\n","  a_list = np.linspace(0, frame, frame, endpoint=False, dtype=int)\n","  combinations_list = np.array(list(combinations(a_list, 2)))\n","  return combinations_list\n","\n","\n","class ordersModel(nn.Module):\n","    def __init__(self, mem_size=512, orders_classes = 12, frame = 7):\n","        super(ordersModel, self).__init__()\n","        self.mem_size = mem_size\n","        self.frame = frame\n","        self.combinations = build_combinations(4)\n","        self.permutations = build_permutations(4,orders_classes)\n","        self.fc6 = nn.Linear(mem_size*7*7, mem_size*2)\n","        self.fc7 = nn.Sequential(nn.Linear(mem_size*4, mem_size))\n","        self.orders_classifier = nn.Linear(mem_size*len(self.combinations), orders_classes)\n","\n","    def forward(self, feat_orders, orderVariable):\n","      feat_orders_shuffle = []\n","      \n","      for t in range(feat_orders.size(0)):\n","        order = orderVariable[t].item()\n","        frmStart = np.random.randint(frame-4)\n","        \n","        feat = self.fc6(feat_orders[t].view(feat_orders[t].size(0),self.mem_size*7*7))\n","        feat_orders_shuffle.append(torch.index_select(feat, 0, torch.LongTensor(self.permutations[order]+frmStart).cuda()))\n","\n","      feat_orders_shuffle = torch.stack(feat_orders_shuffle, 0)\n","\n","      feat_orders = [self.fc7(torch.index_select(feat_orders_shuffle, 1, torch.LongTensor([r,c]).cuda()).view(feat_orders_shuffle.size(0),self.mem_size*4)) for r,c in self.combinations]\n","      feat_orders = torch.stack(feat_orders, 0).permute(1,0,2)\n","\n","      feat_orders = torch.reshape(feat_orders,(feat_orders.size(0),self.mem_size*len(self.combinations)))\n","      \n","      return self.orders_classifier(feat_orders)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fs6-NQYvMAsK","colab_type":"code","colab":{}},"source":["class convLSTMModel(nn.Module):\n","    def __init__(self, num_classes=61, mem_size=512, orders_classes = 12, frame = 7):\n","        super(convLSTMModel, self).__init__()\n","        self.num_classes = num_classes\n","        self.resNet = resnet34(True, True)\n","        self.mem_size = mem_size\n","        self.weight_softmax = self.resNet.fc.weight\n","        self.lstm_cell = MyConvLSTMCell(512, mem_size)\n","        self.ms_cell = MyMotionSegCell()\n","        self.avgpool = nn.AvgPool2d(7)\n","        self.dropout = nn.Dropout(0.7)\n","        self.fc = nn.Linear(mem_size, self.num_classes)\n","        self.classifier = nn.Sequential(self.dropout, self.fc)\n","        self.orders_classifier = ordersModel(mem_size, orders_classes, frame)\n","\n","    def forward(self, inputVariable, orderVariable = None, ORD = True, CAM = False, MS = False):\n","        state = (Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()),\n","                 Variable(torch.zeros((inputVariable.size(1), self.mem_size, 7, 7)).cuda()))\n","        \n","        feats_ms = []\n","        feat_orders = []\n","\n","        for t in range(inputVariable.size(0)):\n","            logit, feature_conv, feature_convNBN = self.resNet(inputVariable[t])\n","            feat_orders.append(feature_conv)\n","\n","            if MS: \n","              feats_ms.append(self.ms_cell(feature_conv))\n","\n","            if CAM:\n","              bz, nc, h, w = feature_conv.size()\n","              feature_conv1 = feature_conv.view(bz, nc, h*w)\n","              probs, idxs = logit.sort(1, True)\n","              class_idx = idxs[:, 0]\n","              cam = torch.bmm(self.weight_softmax[class_idx].unsqueeze(1), feature_conv1)\n","              attentionMAP = F.softmax(cam.squeeze(1), dim=1)\n","              attentionMAP = attentionMAP.view(attentionMAP.size(0), 1, 7, 7)\n","              attentionFeat = feature_convNBN * attentionMAP.expand_as(feature_conv)\n","              state = self.lstm_cell(attentionFeat, state)\n","            else:\n","              state = self.lstm_cell(feature_conv, state)\n","        \n","        if MS:\n","          feats_ms = torch.stack(feats_ms, 0)\n","\n","        feats1 = self.avgpool(state[1]).view(state[1].size(0), -1)\n","        feats = self.classifier(feats1)\n","\n","        if ORD:\n","          feat_orders = self.orders_classifier(torch.stack(feat_orders, 0).permute(1,0,2,3,4),orderVariable)\n","\n","        return feats, feats_ms, feats1, feat_orders\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S6NIyeyZDWOM","colab_type":"text"},"source":["**Set Arguments**"]},{"cell_type":"code","metadata":{"id":"wV7T6n-Iqecv","colab_type":"code","colab":{}},"source":["data_dir = \"GTEA61/processed_frames2\"\n","out_dir = 'experiments'\n","\n","user_train = ['S1','S3','S4']\n","user_val = ['S2']\n","trainBatchSize = 32\n","valBatchSize = 64\n","memSize = 512\n","num_classes = 61\n","\n","frame = 7\n","seqLen = frame\n","\n","orders_classes = 12\n","\n","CAM = False"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"05aii3lCDt_4","colab_type":"text"},"source":["**Prepare Dataset and Dataloader**"]},{"cell_type":"code","metadata":{"id":"4EaY--DY7a-f","colab_type":"code","colab":{}},"source":["numEpochs = 150\n","lr1 = 1e-4\n","decay_step = [25, 75]\n","decay_factor = 0.1\n","MS = True\n","weight_jig = 1\n","\n","model_folder = os.path.join('./', out_dir, 'self-supervised-orders', 'Conv', 'stage2', '5frm')  # Dir for saving models and log files\n","stage1_dict = (out_dir + '/rgb/ConvLSMT/16frame/stage1/model_rgb_state_dict.pth')\n","\n","weight_decay = 4e-5\n","weight_mmaps = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wzBtJm6BsiHA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593419654937,"user_tz":-120,"elapsed":5621,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"b70fffb5-b0a5-4942-e96f-ef936754fc7a"},"source":["# Data loader\n","normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","spatial_transform = Compose([Scale(256), RandomHorizontalFlip(), MultiScaleCornerCrop([1, 0.875, 0.75, 0.65625], 224)])\n","\n","vid_seq_train = makeDatasetMmaps(data_dir, user_train, frame, orders_classes = orders_classes,\n","                            spatial_transform=spatial_transform, normalize=normalize, seqLen=seqLen, fmt='.png')\n","\n","train_loader = torch.utils.data.DataLoader(vid_seq_train, batch_size=trainBatchSize,\n","                        shuffle=True, num_workers=4, pin_memory=True)\n","\n","\n","vid_seq_val = makeDataset(data_dir, user_val, frame, \n","                            spatial_transform=Compose([Scale(256), CenterCrop(224), ToTensor(), normalize]),\n","                            seqLen=seqLen, fmt='.png')\n","\n","val_loader = torch.utils.data.DataLoader(vid_seq_val, batch_size=valBatchSize, \n","                        shuffle=False, num_workers=2, pin_memory=True)\n","\n","valInstances = vid_seq_val.__len__()\n","trainInstances = vid_seq_train.__len__()\n","\n","print('Number of samples in the dataset: training = {} | validation = {}'.format(trainInstances, valInstances))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of samples in the dataset: training = 333 | validation = 116\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kULTC6MA5TSC","colab_type":"text"},"source":["**Set Parameters**"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"FNoKjb1v6Ey4","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593419654938,"user_tz":-120,"elapsed":5616,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"768093e2-6aeb-48df-b686-2271fd4ecf69"},"source":["# Create the dir\n","if os.path.exists(model_folder):\n","    print('Directory {} exists!'.format(model_folder))\n","    sys.exit()\n","os.makedirs(model_folder)\n","\n","# Log files\n","writer = SummaryWriter(model_folder)\n","train_log_loss = open((model_folder + '/train_log_loss.txt'), 'w')\n","train_log_acc = open((model_folder + '/train_log_acc.txt'), 'w')\n","val_log_loss = open((model_folder + '/val_log_loss.txt'), 'w')\n","val_log_acc = open((model_folder + '/val_log_acc.txt'), 'w')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Directory ./experiments/self-supervised-orders/Conv/stage2/5frm exists!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9QW6v8Fk5Ysd","colab_type":"text"},"source":["**Prepare Network and Train**"]},{"cell_type":"code","metadata":{"id":"4o1qNkv63MgT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593419659541,"user_tz":-120,"elapsed":10210,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"443c3d60-68ab-49e1-e62d-e03117ab52af"},"source":["train_params = []\n","\n","model = convLSTMModel(num_classes=num_classes, orders_classes=orders_classes, mem_size=memSize, frame=frame)\n","model.load_state_dict(torch.load(stage1_dict), strict=False)\n","model.train(False)\n","for params in model.parameters():\n","    params.requires_grad = False\n","#\n","for params in model.resNet.layer4[0].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[0].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[1].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[1].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.resNet.layer4[2].conv1.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","#\n","for params in model.resNet.layer4[2].conv2.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","#\n","for params in model.resNet.fc.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.resNet.layer4[0].conv1.train(True)\n","model.resNet.layer4[0].conv2.train(True)\n","model.resNet.layer4[1].conv1.train(True)\n","model.resNet.layer4[1].conv2.train(True)\n","model.resNet.layer4[2].conv1.train(True)\n","model.resNet.layer4[2].conv2.train(True)\n","model.resNet.fc.train(True)\n","\n","for params in model.ms_cell.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.lstm_cell.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.classifier.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","for params in model.orders_classifier.parameters():\n","    params.requires_grad = True\n","    train_params += [params]\n","\n","model.lstm_cell.train(True)\n","model.ms_cell.train(True)\n","\n","model.classifier.train(True)\n","model.orders_classifier.train(True)\n","model.cuda()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["convLSTMModel(\n","  (resNet): ResNet(\n","    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (relu): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (3): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (4): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (5): BasicBlock(\n","        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): BasicBlock(\n","        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (downsample): Sequential(\n","          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","      (2): BasicBlock(\n","        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (relu): ReLU(inplace=True)\n","        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (avgpool): AvgPool2d(kernel_size=7, stride=1, padding=0)\n","    (fc): Linear(in_features=512, out_features=1000, bias=True)\n","  )\n","  (lstm_cell): MyConvLSTMCell(\n","    (conv_i_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_i_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_f_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_f_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_c_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_c_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (conv_o_xx): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (conv_o_hh): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (ms_cell): MyMotionSegCell(\n","    (relu): ReLU()\n","    (ms_conv): Conv2d(512, 100, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","    (ms_fc): Linear(in_features=4900, out_features=98, bias=True)\n","  )\n","  (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n","  (dropout): Dropout(p=0.7, inplace=False)\n","  (fc): Linear(in_features=512, out_features=61, bias=True)\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.7, inplace=False)\n","    (1): Linear(in_features=512, out_features=61, bias=True)\n","  )\n","  (orders_classifier): ordersModel(\n","    (fc6): Linear(in_features=25088, out_features=1024, bias=True)\n","    (fc7): Sequential(\n","      (0): Linear(in_features=2048, out_features=512, bias=True)\n","    )\n","    (orders_classifier): Linear(in_features=3072, out_features=12, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"GK9_SZbs5hMB","colab_type":"text"},"source":["**Define Data Preprocessing**"]},{"cell_type":"code","metadata":{"id":"9v9OXl9mLw80","colab_type":"code","colab":{}},"source":["loss_fn = nn.CrossEntropyLoss()\n","\n","optimizer_fn = torch.optim.Adam(train_params, lr=lr1, weight_decay=weight_decay, eps=1e-4)\n","\n","optim_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer_fn, milestones=decay_step,\n","                                                        gamma=decay_factor)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HoF8FCyj5jnh","colab_type":"text"},"source":["**Train**"]},{"cell_type":"code","metadata":{"id":"ButMUOcS3qvI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593422401946,"user_tz":-120,"elapsed":2752595,"user":{"displayName":"Action R","photoUrl":"","userId":"00086723448689883456"}},"outputId":"054f924b-1bd6-4dd8-ce72-10abe160d309"},"source":["train_iter = 0\n","min_accuracy = 0\n","\n","\n","for epoch in range(numEpochs):\n","    epoch_loss = 0\n","    epoch_loss_ord = 0\n","    numCorrTrain = 0\n","    numCorrTrainOrd = 0\n","    numCorrTrainMmap = 0\n","    \n","    trainSamples = 0\n","    iterPerEpoch = 0\n","\n","    model.lstm_cell.train(True)\n","    model.ms_cell.train(True)\n","    model.orders_classifier.train(True)\n","    model.classifier.train(True)\n","    writer.add_scalar('lr', optimizer_fn.param_groups[0]['lr'], epoch+1)\n","    \n","    model.resNet.layer4[0].conv1.train(True)\n","    model.resNet.layer4[0].conv2.train(True)\n","    model.resNet.layer4[1].conv1.train(True)\n","    model.resNet.layer4[1].conv2.train(True)\n","    model.resNet.layer4[2].conv1.train(True)\n","    model.resNet.layer4[2].conv2.train(True)\n","    model.resNet.fc.train(True)\n","\n","    for i, (inputs, mmaps, targets, ords_lb) in enumerate(train_loader):\n","        train_iter += 1\n","        iterPerEpoch += 1\n","        optimizer_fn.zero_grad()\n","\n","        inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","        labelVariable = Variable(targets.cuda())\n","        ords_lbVariable = Variable(torch.squeeze(ords_lb).cuda())\n","        trainSamples += inputs.size(0)\n","\n","        output_label, output_mmaps, _ , orders_logit = model(inputVariable,ords_lbVariable,CAM=CAM, MS=MS)\n","        \n","        loss = loss_fn(output_label, labelVariable) + loss_fn(orders_logit, ords_lbVariable) * weight_jig\n","        \n","        if MS:\n","          mmapsVariable = Variable(torch.squeeze(mmaps).cuda())\n","          output_mmaps = output_mmaps.permute(1, 2, 0, 3, 4)\n","          loss+=loss_fn(output_mmaps, mmapsVariable.long()) * weight_mmaps\n","\n","          _, predictedMmap = torch.max(output_mmaps.data, 1)\n","          numCorrTrainMmap += (predictedMmap == mmapsVariable.cuda()).sum()\n","          mmapAccuracy = (numCorrTrainMmap.item() / (trainSamples*frame*49)) * 100\n","          \n","        \n","        loss.backward()\n","        optimizer_fn.step()\n","        _, predicted = torch.max(output_label.data, 1)\n","        _, predictedOrd = torch.max(orders_logit.data, 1)\n","        numCorrTrain += (predicted == targets.cuda()).sum()\n","        numCorrTrainOrd += (predictedOrd == ords_lb.cuda()).sum()\n","\n","        epoch_loss += loss.item()\n","    \n","    avg_loss = epoch_loss/iterPerEpoch\n","    trainAccuracy = (numCorrTrain.item() / trainSamples) * 100\n","    ordersAccuracy = (numCorrTrainOrd.item() / (trainSamples)) * 100\n","\n","    print('Train: Epoch = {} | Loss = {} | Loss_orders = {} | Accuracy = {} | Accuracy_orders = {} | Accuracy_mmap = {}'.format(epoch+1, avg_loss, loss_fn(orders_logit, ords_lbVariable).item(), trainAccuracy, ordersAccuracy, mmapAccuracy))\n","    \n","    train_log_loss.write('Train Loss after {} epochs = {}\\n'.format(epoch + 1, avg_loss))\n","    train_log_acc.write('Train Accuracy after {} epochs = {}%\\n'.format(epoch + 1, trainAccuracy))\n","    writer.add_scalar('train/epoch_loss', avg_loss, epoch+1)\n","    writer.add_scalar('train/accuracy', trainAccuracy, epoch+1)\n","    \n","    if (epoch+1) % 1 == 0:\n","        model.train(False)\n","        val_loss_epoch = 0\n","        val_iter = 0\n","        val_samples = 0\n","        numCorr = 0\n","        for j, (inputs, targets) in enumerate(val_loader):\n","            val_iter += 1\n","            val_samples += inputs.size(0)\n","            inputVariable = Variable(inputs.permute(1, 0, 2, 3, 4).cuda())\n","            labelVariable = Variable(targets.cuda(non_blocking=True))\n","            output_label, _, _, _ = model(inputVariable, ORD=False, CAM=CAM, MS=False)\n","            val_loss = loss_fn(output_label, labelVariable)\n","            val_loss_epoch += val_loss.item()\n","            _, predicted = torch.max(output_label.data, 1)\n","            numCorr += (predicted == targets.cuda()).sum()\n","\n","        val_accuracy = (numCorr.item() / val_samples) * 100\n","\n","        avg_val_loss = val_loss_epoch / val_iter\n","        print('Val: Epoch = {} | Loss {} | Accuracy = {}'.format(epoch + 1, avg_val_loss, val_accuracy))\n","        writer.add_scalar('val/epoch_loss', avg_val_loss, epoch + 1)\n","        writer.add_scalar('val/accuracy', val_accuracy, epoch + 1)\n","        val_log_loss.write('Val Loss after {} epochs = {}\\n'.format(epoch + 1, avg_val_loss))\n","        val_log_acc.write('Val Accuracy after {} epochs = {}%\\n'.format(epoch + 1, val_accuracy))\n","        \n","        if val_accuracy > min_accuracy:\n","            save_path_model = (model_folder + '/model_rgb_state_dict.pth')\n","            torch.save(model.state_dict(), save_path_model)\n","            min_accuracy = val_accuracy\n","    \n","    # Step the scheduler\n","    optim_scheduler.step()\n","    \n","\n","train_log_loss.close()\n","train_log_acc.close()\n","val_log_acc.close()\n","val_log_loss.close()\n","writer.export_scalars_to_json(model_folder + \"/all_scalars.json\")\n","writer.close()\n","\n","print('Best accuracy after {} epochs = {}'.format(epoch, min_accuracy))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train: Epoch = 1 | Loss = 6.42456579208374 | Loss_orders = 2.4419658184051514 | Accuracy = 23.123123123123122 | Accuracy_orders = 12.012012012012011 | Accuracy_mmap = 85.62148153984889\n","Val: Epoch = 1 | Loss 3.1430892944335938 | Accuracy = 16.379310344827587\n","Train: Epoch = 2 | Loss = 5.962495803833008 | Loss_orders = 2.565729856491089 | Accuracy = 21.62162162162162 | Accuracy_orders = 13.213213213213212 | Accuracy_mmap = 94.62786401561912\n","Val: Epoch = 2 | Loss 2.7603927850723267 | Accuracy = 27.586206896551722\n","Train: Epoch = 3 | Loss = 5.701921116222035 | Loss_orders = 2.9723117351531982 | Accuracy = 24.024024024024023 | Accuracy_orders = 12.012012012012011 | Accuracy_mmap = 94.76794578835394\n","Val: Epoch = 3 | Loss 2.700952887535095 | Accuracy = 37.93103448275862\n","Train: Epoch = 4 | Loss = 5.46664589101618 | Loss_orders = 2.452479839324951 | Accuracy = 32.732732732732735 | Accuracy_orders = 8.108108108108109 | Accuracy_mmap = 94.61298032726604\n","Val: Epoch = 4 | Loss 2.6226179599761963 | Accuracy = 29.310344827586203\n","Train: Epoch = 5 | Loss = 5.281874136491255 | Loss_orders = 2.7122979164123535 | Accuracy = 33.933933933933936 | Accuracy_orders = 7.5075075075075075 | Accuracy_mmap = 94.59021703919663\n","Val: Epoch = 5 | Loss 2.467344045639038 | Accuracy = 34.48275862068966\n","Train: Epoch = 6 | Loss = 5.301316304640337 | Loss_orders = 2.4105467796325684 | Accuracy = 34.234234234234236 | Accuracy_orders = 7.807807807807808 | Accuracy_mmap = 94.45889037725772\n","Val: Epoch = 6 | Loss 2.3791816234588623 | Accuracy = 40.51724137931034\n","Train: Epoch = 7 | Loss = 5.235939025878906 | Loss_orders = 2.49570894241333 | Accuracy = 33.633633633633636 | Accuracy_orders = 8.408408408408409 | Accuracy_mmap = 94.74518250028454\n","Val: Epoch = 7 | Loss 2.4347153902053833 | Accuracy = 32.758620689655174\n","Train: Epoch = 8 | Loss = 5.09653260491111 | Loss_orders = 2.6392672061920166 | Accuracy = 30.630630630630627 | Accuracy_orders = 14.414414414414415 | Accuracy_mmap = 94.46676997697406\n","Val: Epoch = 8 | Loss 2.2956786155700684 | Accuracy = 36.206896551724135\n","Train: Epoch = 9 | Loss = 5.08957763151689 | Loss_orders = 2.6741600036621094 | Accuracy = 34.83483483483483 | Accuracy_orders = 8.408408408408409 | Accuracy_mmap = 95.13303390854412\n","Val: Epoch = 9 | Loss 2.2292529344558716 | Accuracy = 37.06896551724138\n","Train: Epoch = 10 | Loss = 5.00444880398837 | Loss_orders = 2.5650925636291504 | Accuracy = 37.23723723723724 | Accuracy_orders = 10.81081081081081 | Accuracy_mmap = 94.79246009858254\n","Val: Epoch = 10 | Loss 2.115704357624054 | Accuracy = 41.37931034482759\n","Train: Epoch = 11 | Loss = 4.727334759452126 | Loss_orders = 2.5036873817443848 | Accuracy = 43.54354354354354 | Accuracy_orders = 16.516516516516518 | Accuracy_mmap = 94.74518250028454\n","Val: Epoch = 11 | Loss 2.01346892118454 | Accuracy = 45.689655172413794\n","Train: Epoch = 12 | Loss = 4.7363262610002 | Loss_orders = 2.4037370681762695 | Accuracy = 42.04204204204204 | Accuracy_orders = 10.51051051051051 | Accuracy_mmap = 94.56132517357008\n","Val: Epoch = 12 | Loss 2.0255345702171326 | Accuracy = 44.827586206896555\n","Train: Epoch = 13 | Loss = 4.68822752345692 | Loss_orders = 2.3689913749694824 | Accuracy = 40.84084084084084 | Accuracy_orders = 12.312312312312311 | Accuracy_mmap = 94.83623565256218\n","Val: Epoch = 13 | Loss 2.0444263219833374 | Accuracy = 43.96551724137931\n","Train: Epoch = 14 | Loss = 4.60654319416393 | Loss_orders = 2.258307695388794 | Accuracy = 45.04504504504504 | Accuracy_orders = 9.90990990990991 | Accuracy_mmap = 94.47727610992918\n","Val: Epoch = 14 | Loss 2.198711633682251 | Accuracy = 40.51724137931034\n","Train: Epoch = 15 | Loss = 4.52147202058272 | Loss_orders = 2.444276809692383 | Accuracy = 44.74474474474475 | Accuracy_orders = 19.51951951951952 | Accuracy_mmap = 94.33631882611473\n","Val: Epoch = 15 | Loss 1.9526081681251526 | Accuracy = 50.86206896551724\n","Train: Epoch = 16 | Loss = 4.459176887165416 | Loss_orders = 2.239448308944702 | Accuracy = 41.44144144144144 | Accuracy_orders = 16.816816816816818 | Accuracy_mmap = 94.82572951960707\n","Val: Epoch = 16 | Loss 2.0258466005325317 | Accuracy = 39.6551724137931\n","Train: Epoch = 17 | Loss = 4.261375210501931 | Loss_orders = 1.841224193572998 | Accuracy = 45.94594594594595 | Accuracy_orders = 21.32132132132132 | Accuracy_mmap = 94.50354144231696\n","Val: Epoch = 17 | Loss 1.8554455637931824 | Accuracy = 47.41379310344828\n","Train: Epoch = 18 | Loss = 4.227175019004128 | Loss_orders = 2.5602667331695557 | Accuracy = 45.04504504504504 | Accuracy_orders = 22.822822822822822 | Accuracy_mmap = 94.63486810425586\n","Val: Epoch = 18 | Loss 1.826554536819458 | Accuracy = 46.55172413793103\n","Train: Epoch = 19 | Loss = 4.179576938802546 | Loss_orders = 2.3768389225006104 | Accuracy = 52.85285285285285 | Accuracy_orders = 22.22222222222222 | Accuracy_mmap = 94.53943739658025\n","Val: Epoch = 19 | Loss 1.943870723247528 | Accuracy = 45.689655172413794\n","Train: Epoch = 20 | Loss = 4.030513590032404 | Loss_orders = 2.2069289684295654 | Accuracy = 53.753753753753756 | Accuracy_orders = 22.822822822822822 | Accuracy_mmap = 94.82923156392545\n","Val: Epoch = 20 | Loss 1.884091079235077 | Accuracy = 47.41379310344828\n","Train: Epoch = 21 | Loss = 4.063406575809825 | Loss_orders = 1.9788538217544556 | Accuracy = 48.348348348348345 | Accuracy_orders = 28.22822822822823 | Accuracy_mmap = 95.14003799718085\n","Val: Epoch = 21 | Loss 1.9785213470458984 | Accuracy = 40.51724137931034\n","Train: Epoch = 22 | Loss = 3.996566317298196 | Loss_orders = 2.3645758628845215 | Accuracy = 47.147147147147145 | Accuracy_orders = 26.126126126126124 | Accuracy_mmap = 94.87650916222344\n","Val: Epoch = 22 | Loss 2.0539382696151733 | Accuracy = 43.96551724137931\n","Train: Epoch = 23 | Loss = 3.827168031172319 | Loss_orders = 2.063384771347046 | Accuracy = 53.453453453453456 | Accuracy_orders = 31.53153153153153 | Accuracy_mmap = 94.7031579684641\n","Val: Epoch = 23 | Loss 1.9992241263389587 | Accuracy = 39.6551724137931\n","Train: Epoch = 24 | Loss = 3.8149640560150146 | Loss_orders = 2.3981590270996094 | Accuracy = 54.35435435435435 | Accuracy_orders = 30.630630630630627 | Accuracy_mmap = 94.7145396124988\n","Val: Epoch = 24 | Loss 1.7987189292907715 | Accuracy = 50.0\n","Train: Epoch = 25 | Loss = 3.7839398817582564 | Loss_orders = 1.895869493484497 | Accuracy = 54.65465465465466 | Accuracy_orders = 28.82882882882883 | Accuracy_mmap = 94.59109255027623\n","Val: Epoch = 25 | Loss 1.7393895387649536 | Accuracy = 51.724137931034484\n","Train: Epoch = 26 | Loss = 3.6718413829803467 | Loss_orders = 2.0414958000183105 | Accuracy = 56.75675675675676 | Accuracy_orders = 32.732732732732735 | Accuracy_mmap = 94.88438876193979\n","Val: Epoch = 26 | Loss 1.6739205718040466 | Accuracy = 50.0\n","Train: Epoch = 27 | Loss = 3.4902710914611816 | Loss_orders = 1.5890026092529297 | Accuracy = 58.25825825825825 | Accuracy_orders = 32.13213213213213 | Accuracy_mmap = 94.74080494488658\n","Val: Epoch = 27 | Loss 1.6668039560317993 | Accuracy = 50.0\n","Train: Epoch = 28 | Loss = 3.3569603833285244 | Loss_orders = 1.193627119064331 | Accuracy = 57.95795795795796 | Accuracy_orders = 33.633633633633636 | Accuracy_mmap = 94.76969681051314\n","Val: Epoch = 28 | Loss 1.6316797733306885 | Accuracy = 50.0\n","Train: Epoch = 29 | Loss = 3.338969252326272 | Loss_orders = 1.5654232501983643 | Accuracy = 57.95795795795796 | Accuracy_orders = 39.33933933933934 | Accuracy_mmap = 94.57620886192315\n","Val: Epoch = 29 | Loss 1.63386869430542 | Accuracy = 45.689655172413794\n","Train: Epoch = 30 | Loss = 3.346926602450284 | Loss_orders = 2.627692222595215 | Accuracy = 61.261261261261254 | Accuracy_orders = 39.33933933933934 | Accuracy_mmap = 94.3284392263984\n","Val: Epoch = 30 | Loss 1.6331588625907898 | Accuracy = 46.55172413793103\n","Train: Epoch = 31 | Loss = 3.280615069649436 | Loss_orders = 1.7808412313461304 | Accuracy = 57.95795795795796 | Accuracy_orders = 39.63963963963964 | Accuracy_mmap = 94.76444374403557\n","Val: Epoch = 31 | Loss 1.6383955478668213 | Accuracy = 48.275862068965516\n","Train: Epoch = 32 | Loss = 3.251529108394276 | Loss_orders = 1.6238083839416504 | Accuracy = 60.96096096096096 | Accuracy_orders = 39.33933933933934 | Accuracy_mmap = 94.54118841873944\n","Val: Epoch = 32 | Loss 1.6263741254806519 | Accuracy = 50.0\n","Train: Epoch = 33 | Loss = 3.133943124250932 | Loss_orders = 1.8271268606185913 | Accuracy = 63.06306306306306 | Accuracy_orders = 43.24324324324324 | Accuracy_mmap = 94.27503305054326\n","Val: Epoch = 33 | Loss 1.6191008687019348 | Accuracy = 50.86206896551724\n","Train: Epoch = 34 | Loss = 3.1402143131602895 | Loss_orders = 1.6528589725494385 | Accuracy = 61.56156156156156 | Accuracy_orders = 38.73873873873874 | Accuracy_mmap = 94.48690673180468\n","Val: Epoch = 34 | Loss 1.6079429388046265 | Accuracy = 50.86206896551724\n","Train: Epoch = 35 | Loss = 3.2184247103604404 | Loss_orders = 1.936511754989624 | Accuracy = 60.66066066066066 | Accuracy_orders = 36.63663663663664 | Accuracy_mmap = 94.49215979828224\n","Val: Epoch = 35 | Loss 1.6097872257232666 | Accuracy = 50.0\n","Train: Epoch = 36 | Loss = 3.2159319574182685 | Loss_orders = 1.762904405593872 | Accuracy = 64.86486486486487 | Accuracy_orders = 42.04204204204204 | Accuracy_mmap = 94.94742555967046\n","Val: Epoch = 36 | Loss 1.623607099056244 | Accuracy = 49.137931034482754\n","Train: Epoch = 37 | Loss = 3.1458850773898037 | Loss_orders = 1.5384438037872314 | Accuracy = 67.56756756756756 | Accuracy_orders = 38.43843843843844 | Accuracy_mmap = 94.51579859743126\n","Val: Epoch = 37 | Loss 1.603374719619751 | Accuracy = 53.44827586206896\n","Train: Epoch = 38 | Loss = 3.060682340101762 | Loss_orders = 2.1258556842803955 | Accuracy = 66.96696696696696 | Accuracy_orders = 43.84384384384384 | Accuracy_mmap = 93.89068368660205\n","Val: Epoch = 38 | Loss 1.5942999124526978 | Accuracy = 51.724137931034484\n","Train: Epoch = 39 | Loss = 3.1518994678150523 | Loss_orders = 1.5206952095031738 | Accuracy = 62.76276276276276 | Accuracy_orders = 40.54054054054054 | Accuracy_mmap = 94.77932743238865\n","Val: Epoch = 39 | Loss 1.6338739395141602 | Accuracy = 52.58620689655172\n","Train: Epoch = 40 | Loss = 3.136954654346813 | Loss_orders = 1.6230233907699585 | Accuracy = 62.46246246246246 | Accuracy_orders = 38.73873873873874 | Accuracy_mmap = 94.85637240739283\n","Val: Epoch = 40 | Loss 1.6107141375541687 | Accuracy = 51.724137931034484\n","Train: Epoch = 41 | Loss = 2.973774953321977 | Loss_orders = 1.1205633878707886 | Accuracy = 67.26726726726727 | Accuracy_orders = 43.84384384384384 | Accuracy_mmap = 94.78895805426417\n","Val: Epoch = 41 | Loss 1.5918349027633667 | Accuracy = 52.58620689655172\n","Train: Epoch = 42 | Loss = 3.032349716533314 | Loss_orders = 1.2754347324371338 | Accuracy = 63.36336336336337 | Accuracy_orders = 43.24324324324324 | Accuracy_mmap = 94.352953536627\n","Val: Epoch = 42 | Loss 1.5947320461273193 | Accuracy = 54.310344827586206\n","Train: Epoch = 43 | Loss = 2.8617501692338423 | Loss_orders = 1.1934006214141846 | Accuracy = 64.26426426426426 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 94.5823374394803\n","Val: Epoch = 43 | Loss 1.594858705997467 | Accuracy = 51.724137931034484\n","Train: Epoch = 44 | Loss = 3.087104168805209 | Loss_orders = 1.863611102104187 | Accuracy = 66.36636636636636 | Accuracy_orders = 42.04204204204204 | Accuracy_mmap = 94.56832926220682\n","Val: Epoch = 44 | Loss 1.563262403011322 | Accuracy = 52.58620689655172\n","Train: Epoch = 45 | Loss = 2.9397354992953213 | Loss_orders = 2.4000909328460693 | Accuracy = 64.56456456456456 | Accuracy_orders = 46.846846846846844 | Accuracy_mmap = 94.48340468748631\n","Val: Epoch = 45 | Loss 1.552324891090393 | Accuracy = 53.44827586206896\n","Train: Epoch = 46 | Loss = 3.0596708817915483 | Loss_orders = 1.9595856666564941 | Accuracy = 67.56756756756756 | Accuracy_orders = 40.24024024024024 | Accuracy_mmap = 95.14354004149924\n","Val: Epoch = 46 | Loss 1.5531514286994934 | Accuracy = 53.44827586206896\n","Train: Epoch = 47 | Loss = 2.9754088791933926 | Loss_orders = 1.6926350593566895 | Accuracy = 66.36636636636636 | Accuracy_orders = 43.24324324324324 | Accuracy_mmap = 94.75306210000088\n","Val: Epoch = 47 | Loss 1.5535797476768494 | Accuracy = 56.03448275862068\n","Train: Epoch = 48 | Loss = 2.978665915402499 | Loss_orders = 1.7509617805480957 | Accuracy = 67.26726726726727 | Accuracy_orders = 45.34534534534534 | Accuracy_mmap = 94.38359642441276\n","Val: Epoch = 48 | Loss 1.54360693693161 | Accuracy = 55.172413793103445\n","Train: Epoch = 49 | Loss = 3.10796536098827 | Loss_orders = 2.1748178005218506 | Accuracy = 62.46246246246246 | Accuracy_orders = 41.44144144144144 | Accuracy_mmap = 94.57971090624152\n","Val: Epoch = 49 | Loss 1.5674330592155457 | Accuracy = 53.44827586206896\n","Train: Epoch = 50 | Loss = 3.0011576305736196 | Loss_orders = 1.7173175811767578 | Accuracy = 62.46246246246246 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.78895805426417\n","Val: Epoch = 50 | Loss 1.5572006106376648 | Accuracy = 52.58620689655172\n","Train: Epoch = 51 | Loss = 2.9139374819668857 | Loss_orders = 1.2796870470046997 | Accuracy = 67.26726726726727 | Accuracy_orders = 41.14114114114114 | Accuracy_mmap = 94.69527836874776\n","Val: Epoch = 51 | Loss 1.5615787506103516 | Accuracy = 56.03448275862068\n","Train: Epoch = 52 | Loss = 2.8808660290457984 | Loss_orders = 1.419290542602539 | Accuracy = 66.06606606606607 | Accuracy_orders = 43.54354354354354 | Accuracy_mmap = 94.41511482327809\n","Val: Epoch = 52 | Loss 1.5813499689102173 | Accuracy = 54.310344827586206\n","Train: Epoch = 53 | Loss = 2.871486403725364 | Loss_orders = 1.3482972383499146 | Accuracy = 67.26726726726727 | Accuracy_orders = 40.24024024024024 | Accuracy_mmap = 94.69440285766815\n","Val: Epoch = 53 | Loss 1.5694524645805359 | Accuracy = 52.58620689655172\n","Train: Epoch = 54 | Loss = 2.8976048122752798 | Loss_orders = 1.8911375999450684 | Accuracy = 66.06606606606607 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.6891497911906\n","Val: Epoch = 54 | Loss 1.5640022158622742 | Accuracy = 55.172413793103445\n","Train: Epoch = 55 | Loss = 2.8786439028653232 | Loss_orders = 1.8187998533248901 | Accuracy = 66.66666666666666 | Accuracy_orders = 46.846846846846844 | Accuracy_mmap = 94.86512751818874\n","Val: Epoch = 55 | Loss 1.5416749119758606 | Accuracy = 54.310344827586206\n","Train: Epoch = 56 | Loss = 2.7323496775193648 | Loss_orders = 1.6483632326126099 | Accuracy = 69.96996996996997 | Accuracy_orders = 48.94894894894895 | Accuracy_mmap = 94.65237832584772\n","Val: Epoch = 56 | Loss 1.534909963607788 | Accuracy = 55.172413793103445\n","Train: Epoch = 57 | Loss = 2.8705134175040503 | Loss_orders = 1.9778096675872803 | Accuracy = 67.86786786786787 | Accuracy_orders = 45.94594594594595 | Accuracy_mmap = 94.54031290765985\n","Val: Epoch = 57 | Loss 1.5262174606323242 | Accuracy = 55.172413793103445\n","Train: Epoch = 58 | Loss = 2.8726230534640225 | Loss_orders = 2.0020010471343994 | Accuracy = 67.56756756756756 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.91152960540715\n","Val: Epoch = 58 | Loss 1.5305896997451782 | Accuracy = 52.58620689655172\n","Train: Epoch = 59 | Loss = 2.7584070509130303 | Loss_orders = 1.7374024391174316 | Accuracy = 69.96996996996997 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.6777681471559\n","Val: Epoch = 59 | Loss 1.537215232849121 | Accuracy = 54.310344827586206\n","Train: Epoch = 60 | Loss = 2.643409555608576 | Loss_orders = 1.3344130516052246 | Accuracy = 69.66966966966966 | Accuracy_orders = 49.849849849849846 | Accuracy_mmap = 94.20849420849422\n","Val: Epoch = 60 | Loss 1.536686658859253 | Accuracy = 58.620689655172406\n","Train: Epoch = 61 | Loss = 2.6974810578606347 | Loss_orders = 1.7257790565490723 | Accuracy = 70.57057057057057 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.4142393121985\n","Val: Epoch = 61 | Loss 1.5527552962303162 | Accuracy = 55.172413793103445\n","Train: Epoch = 62 | Loss = 2.6831013072620737 | Loss_orders = 1.6145052909851074 | Accuracy = 67.26726726726727 | Accuracy_orders = 47.74774774774775 | Accuracy_mmap = 94.64099668181301\n","Val: Epoch = 62 | Loss 1.5416285395622253 | Accuracy = 56.896551724137936\n","Train: Epoch = 63 | Loss = 2.7187541723251343 | Loss_orders = 1.24666428565979 | Accuracy = 67.86786786786787 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.97193986989906\n","Val: Epoch = 63 | Loss 1.5230583548545837 | Accuracy = 57.758620689655174\n","Train: Epoch = 64 | Loss = 2.6650409264998003 | Loss_orders = 1.4028830528259277 | Accuracy = 68.16816816816817 | Accuracy_orders = 48.348348348348345 | Accuracy_mmap = 94.71804165681716\n","Val: Epoch = 64 | Loss 1.5309266448020935 | Accuracy = 56.896551724137936\n","Train: Epoch = 65 | Loss = 2.8763075958598745 | Loss_orders = 1.6393128633499146 | Accuracy = 66.66666666666666 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.74168045596618\n","Val: Epoch = 65 | Loss 1.5337965488433838 | Accuracy = 50.86206896551724\n","Train: Epoch = 66 | Loss = 2.8564660765907983 | Loss_orders = 1.8806458711624146 | Accuracy = 67.86786786786787 | Accuracy_orders = 48.348348348348345 | Accuracy_mmap = 94.48690673180468\n","Val: Epoch = 66 | Loss 1.5456401109695435 | Accuracy = 54.310344827586206\n","Train: Epoch = 67 | Loss = 2.624649914828214 | Loss_orders = 1.614852786064148 | Accuracy = 68.16816816816817 | Accuracy_orders = 51.651651651651655 | Accuracy_mmap = 94.52630473038637\n","Val: Epoch = 67 | Loss 1.4955943822860718 | Accuracy = 56.896551724137936\n","Train: Epoch = 68 | Loss = 2.6561373580585825 | Loss_orders = 1.1402236223220825 | Accuracy = 70.87087087087087 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.72854778977228\n","Val: Epoch = 68 | Loss 1.5113885402679443 | Accuracy = 59.48275862068966\n","Train: Epoch = 69 | Loss = 2.76231050491333 | Loss_orders = 1.2906227111816406 | Accuracy = 67.86786786786787 | Accuracy_orders = 45.645645645645644 | Accuracy_mmap = 94.45538833293935\n","Val: Epoch = 69 | Loss 1.5380969047546387 | Accuracy = 54.310344827586206\n","Train: Epoch = 70 | Loss = 2.6161779273640025 | Loss_orders = 1.3707607984542847 | Accuracy = 67.86786786786787 | Accuracy_orders = 53.153153153153156 | Accuracy_mmap = 94.85724791847241\n","Val: Epoch = 70 | Loss 1.5260074734687805 | Accuracy = 55.172413793103445\n","Train: Epoch = 71 | Loss = 2.776347030292858 | Loss_orders = 1.5270518064498901 | Accuracy = 69.96996996996997 | Accuracy_orders = 49.849849849849846 | Accuracy_mmap = 94.75218658892129\n","Val: Epoch = 71 | Loss 1.5485841631889343 | Accuracy = 53.44827586206896\n","Train: Epoch = 72 | Loss = 2.611860578710383 | Loss_orders = 0.8560632467269897 | Accuracy = 69.66966966966966 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.28904122781674\n","Val: Epoch = 72 | Loss 1.5746626257896423 | Accuracy = 57.758620689655174\n","Train: Epoch = 73 | Loss = 2.6285401474345815 | Loss_orders = 1.418602705001831 | Accuracy = 71.17117117117117 | Accuracy_orders = 50.750750750750754 | Accuracy_mmap = 94.87213160682548\n","Val: Epoch = 73 | Loss 1.5540849566459656 | Accuracy = 54.310344827586206\n","Train: Epoch = 74 | Loss = 2.6272649331526323 | Loss_orders = 0.9059098958969116 | Accuracy = 68.76876876876878 | Accuracy_orders = 51.651651651651655 | Accuracy_mmap = 94.60072317215175\n","Val: Epoch = 74 | Loss 1.5451700687408447 | Accuracy = 56.03448275862068\n","Train: Epoch = 75 | Loss = 2.8158395940607246 | Loss_orders = 2.000795841217041 | Accuracy = 66.06606606606607 | Accuracy_orders = 48.94894894894895 | Accuracy_mmap = 94.81697440881113\n","Val: Epoch = 75 | Loss 1.5378718376159668 | Accuracy = 51.724137931034484\n","Train: Epoch = 76 | Loss = 2.6760827844793145 | Loss_orders = 1.122646450996399 | Accuracy = 69.36936936936937 | Accuracy_orders = 46.546546546546544 | Accuracy_mmap = 94.91678267188472\n","Val: Epoch = 76 | Loss 1.533088207244873 | Accuracy = 52.58620689655172\n","Train: Epoch = 77 | Loss = 2.5682096264579077 | Loss_orders = 1.1961020231246948 | Accuracy = 69.66966966966966 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 95.04898484490322\n","Val: Epoch = 77 | Loss 1.5268845558166504 | Accuracy = 52.58620689655172\n","Train: Epoch = 78 | Loss = 2.5503023971210825 | Loss_orders = 1.4330203533172607 | Accuracy = 71.77177177177178 | Accuracy_orders = 52.85285285285285 | Accuracy_mmap = 94.77232334375192\n","Val: Epoch = 78 | Loss 1.5228012800216675 | Accuracy = 52.58620689655172\n","Train: Epoch = 79 | Loss = 2.5954442674463447 | Loss_orders = 1.3106968402862549 | Accuracy = 67.86786786786787 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.90365000569082\n","Val: Epoch = 79 | Loss 1.5192904472351074 | Accuracy = 52.58620689655172\n","Train: Epoch = 80 | Loss = 2.613273403861306 | Loss_orders = 1.4864332675933838 | Accuracy = 66.96696696696696 | Accuracy_orders = 54.35435435435435 | Accuracy_mmap = 94.4974128647598\n","Val: Epoch = 80 | Loss 1.515567660331726 | Accuracy = 53.44827586206896\n","Train: Epoch = 81 | Loss = 2.599798245863481 | Loss_orders = 1.272058367729187 | Accuracy = 71.17117117117117 | Accuracy_orders = 49.249249249249246 | Accuracy_mmap = 94.70578450170287\n","Val: Epoch = 81 | Loss 1.5167579054832458 | Accuracy = 53.44827586206896\n","Train: Epoch = 82 | Loss = 2.5218898816542192 | Loss_orders = 1.348713755607605 | Accuracy = 73.27327327327328 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.88789080625816\n","Val: Epoch = 82 | Loss 1.516639769077301 | Accuracy = 53.44827586206896\n","Train: Epoch = 83 | Loss = 2.5574722940271553 | Loss_orders = 1.7034223079681396 | Accuracy = 68.16816816816817 | Accuracy_orders = 53.453453453453456 | Accuracy_mmap = 94.63311708209667\n","Val: Epoch = 83 | Loss 1.5160664916038513 | Accuracy = 53.44827586206896\n","Train: Epoch = 84 | Loss = 2.525113495913419 | Loss_orders = 1.5373337268829346 | Accuracy = 72.07207207207207 | Accuracy_orders = 50.45045045045045 | Accuracy_mmap = 94.98069498069498\n","Val: Epoch = 84 | Loss 1.5149981379508972 | Accuracy = 54.310344827586206\n","Train: Epoch = 85 | Loss = 2.356802463531494 | Loss_orders = 1.1180672645568848 | Accuracy = 73.27327327327328 | Accuracy_orders = 56.15615615615616 | Accuracy_mmap = 94.78020294346825\n","Val: Epoch = 85 | Loss 1.5124033093452454 | Accuracy = 54.310344827586206\n","Train: Epoch = 86 | Loss = 2.4926918853412974 | Loss_orders = 1.292541265487671 | Accuracy = 69.96996996996997 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.76444374403557\n","Val: Epoch = 86 | Loss 1.5128446817398071 | Accuracy = 52.58620689655172\n","Train: Epoch = 87 | Loss = 2.532452843405984 | Loss_orders = 1.9759373664855957 | Accuracy = 72.07207207207207 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.47902713208836\n","Val: Epoch = 87 | Loss 1.51065993309021 | Accuracy = 52.58620689655172\n","Train: Epoch = 88 | Loss = 2.543093377893621 | Loss_orders = 1.4283849000930786 | Accuracy = 69.66966966966966 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.62173543806198\n","Val: Epoch = 88 | Loss 1.5091735124588013 | Accuracy = 53.44827586206896\n","Train: Epoch = 89 | Loss = 2.58433951031078 | Loss_orders = 0.9599521160125732 | Accuracy = 70.57057057057057 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.56570272896803\n","Val: Epoch = 89 | Loss 1.5095182657241821 | Accuracy = 53.44827586206896\n","Train: Epoch = 90 | Loss = 2.6465087695555254 | Loss_orders = 1.2389118671417236 | Accuracy = 67.86786786786787 | Accuracy_orders = 54.65465465465466 | Accuracy_mmap = 94.70753552386205\n","Val: Epoch = 90 | Loss 1.5110449194908142 | Accuracy = 53.44827586206896\n","Train: Epoch = 91 | Loss = 2.705228242007169 | Loss_orders = 2.939762592315674 | Accuracy = 71.77177177177178 | Accuracy_orders = 52.552552552552555 | Accuracy_mmap = 94.73467636732943\n","Val: Epoch = 91 | Loss 1.511953890323639 | Accuracy = 53.44827586206896\n","Train: Epoch = 92 | Loss = 2.53573861989108 | Loss_orders = 1.2549464702606201 | Accuracy = 71.47147147147147 | Accuracy_orders = 48.048048048048045 | Accuracy_mmap = 94.77757641022947\n","Val: Epoch = 92 | Loss 1.5103394985198975 | Accuracy = 54.310344827586206\n","Train: Epoch = 93 | Loss = 2.287983764301647 | Loss_orders = 1.0125234127044678 | Accuracy = 73.87387387387388 | Accuracy_orders = 56.15615615615616 | Accuracy_mmap = 94.48953326504346\n","Val: Epoch = 93 | Loss 1.5085965991020203 | Accuracy = 55.172413793103445\n","Train: Epoch = 94 | Loss = 2.634133208881725 | Loss_orders = 1.7176268100738525 | Accuracy = 69.06906906906907 | Accuracy_orders = 52.552552552552555 | Accuracy_mmap = 94.58058641732111\n","Val: Epoch = 94 | Loss 1.509118378162384 | Accuracy = 55.172413793103445\n","Train: Epoch = 95 | Loss = 2.5362237583507192 | Loss_orders = 1.8437247276306152 | Accuracy = 72.07207207207207 | Accuracy_orders = 56.15615615615616 | Accuracy_mmap = 94.881762228701\n","Val: Epoch = 95 | Loss 1.5109261274337769 | Accuracy = 54.310344827586206\n","Train: Epoch = 96 | Loss = 2.4794637940146704 | Loss_orders = 0.9191983938217163 | Accuracy = 72.37237237237237 | Accuracy_orders = 50.45045045045045 | Accuracy_mmap = 94.81347236449277\n","Val: Epoch = 96 | Loss 1.5134243369102478 | Accuracy = 54.310344827586206\n","Train: Epoch = 97 | Loss = 2.5612368366935034 | Loss_orders = 1.2219250202178955 | Accuracy = 72.67267267267268 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.49478633152103\n","Val: Epoch = 97 | Loss 1.515210747718811 | Accuracy = 53.44827586206896\n","Train: Epoch = 98 | Loss = 2.7208655964244497 | Loss_orders = 1.8894473314285278 | Accuracy = 68.16816816816817 | Accuracy_orders = 50.750750750750754 | Accuracy_mmap = 95.06561955541547\n","Val: Epoch = 98 | Loss 1.513970136642456 | Accuracy = 53.44827586206896\n","Train: Epoch = 99 | Loss = 2.588291059840809 | Loss_orders = 1.217666506767273 | Accuracy = 72.07207207207207 | Accuracy_orders = 51.35135135135135 | Accuracy_mmap = 94.60072317215175\n","Val: Epoch = 99 | Loss 1.516372263431549 | Accuracy = 53.44827586206896\n","Train: Epoch = 100 | Loss = 2.5920972390608354 | Loss_orders = 0.9635420441627502 | Accuracy = 71.77177177177178 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.21900034144932\n","Val: Epoch = 100 | Loss 1.5151707530021667 | Accuracy = 53.44827586206896\n","Train: Epoch = 101 | Loss = 2.6191282055594702 | Loss_orders = 1.618940830230713 | Accuracy = 72.67267267267268 | Accuracy_orders = 48.94894894894895 | Accuracy_mmap = 94.59021703919663\n","Val: Epoch = 101 | Loss 1.514760434627533 | Accuracy = 54.310344827586206\n","Train: Epoch = 102 | Loss = 2.3506892919540405 | Loss_orders = 1.494167447090149 | Accuracy = 74.47447447447448 | Accuracy_orders = 54.65465465465466 | Accuracy_mmap = 94.69527836874776\n","Val: Epoch = 102 | Loss 1.5118613243103027 | Accuracy = 54.310344827586206\n","Train: Epoch = 103 | Loss = 2.596488670869307 | Loss_orders = 0.9880260229110718 | Accuracy = 67.26726726726727 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 95.02709706791339\n","Val: Epoch = 103 | Loss 1.5077612400054932 | Accuracy = 55.172413793103445\n","Train: Epoch = 104 | Loss = 2.559486150741577 | Loss_orders = 1.632145643234253 | Accuracy = 72.07207207207207 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.67339059175794\n","Val: Epoch = 104 | Loss 1.5055468082427979 | Accuracy = 54.310344827586206\n","Train: Epoch = 105 | Loss = 2.6228778687390415 | Loss_orders = 1.5595276355743408 | Accuracy = 68.46846846846847 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 94.66638650312119\n","Val: Epoch = 105 | Loss 1.5069828629493713 | Accuracy = 54.310344827586206\n","Train: Epoch = 106 | Loss = 2.6785909696058794 | Loss_orders = 1.6586488485336304 | Accuracy = 70.57057057057057 | Accuracy_orders = 50.750750750750754 | Accuracy_mmap = 95.0139644017195\n","Val: Epoch = 106 | Loss 1.506930947303772 | Accuracy = 55.172413793103445\n","Train: Epoch = 107 | Loss = 2.5708553574301978 | Loss_orders = 1.3207192420959473 | Accuracy = 70.57057057057057 | Accuracy_orders = 54.65465465465466 | Accuracy_mmap = 94.54731699629659\n","Val: Epoch = 107 | Loss 1.5032501220703125 | Accuracy = 54.310344827586206\n","Train: Epoch = 108 | Loss = 2.5476260727102105 | Loss_orders = 1.6182503700256348 | Accuracy = 71.47147147147147 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 94.49303530936184\n","Val: Epoch = 108 | Loss 1.5033848285675049 | Accuracy = 54.310344827586206\n","Train: Epoch = 109 | Loss = 2.5138986110687256 | Loss_orders = 1.0735751390457153 | Accuracy = 72.37237237237237 | Accuracy_orders = 54.054054054054056 | Accuracy_mmap = 94.82135196420911\n","Val: Epoch = 109 | Loss 1.5040175914764404 | Accuracy = 54.310344827586206\n","Train: Epoch = 110 | Loss = 2.5544789270921187 | Loss_orders = 1.357410192489624 | Accuracy = 69.06906906906907 | Accuracy_orders = 53.153153153153156 | Accuracy_mmap = 94.68652325795183\n","Val: Epoch = 110 | Loss 1.504298210144043 | Accuracy = 53.44827586206896\n","Train: Epoch = 111 | Loss = 2.568582697348161 | Loss_orders = 1.82145094871521 | Accuracy = 70.57057057057057 | Accuracy_orders = 52.85285285285285 | Accuracy_mmap = 94.62873952669871\n","Val: Epoch = 111 | Loss 1.5046459436416626 | Accuracy = 54.310344827586206\n","Train: Epoch = 112 | Loss = 2.506006284193559 | Loss_orders = 2.044982433319092 | Accuracy = 73.87387387387388 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.38359642441276\n","Val: Epoch = 112 | Loss 1.5056259632110596 | Accuracy = 54.310344827586206\n","Train: Epoch = 113 | Loss = 2.4738849076357754 | Loss_orders = 1.0180968046188354 | Accuracy = 70.27027027027027 | Accuracy_orders = 53.453453453453456 | Accuracy_mmap = 95.00083173552561\n","Val: Epoch = 113 | Loss 1.5093132257461548 | Accuracy = 52.58620689655172\n","Train: Epoch = 114 | Loss = 2.3238479007374155 | Loss_orders = 1.1163767576217651 | Accuracy = 73.27327327327328 | Accuracy_orders = 57.05705705705706 | Accuracy_mmap = 94.27678407270244\n","Val: Epoch = 114 | Loss 1.5101216435432434 | Accuracy = 54.310344827586206\n","Train: Epoch = 115 | Loss = 2.520466371016069 | Loss_orders = 1.0481679439544678 | Accuracy = 71.17117117117117 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.89051733949692\n","Val: Epoch = 115 | Loss 1.5101808905601501 | Accuracy = 54.310344827586206\n","Train: Epoch = 116 | Loss = 2.637558091770519 | Loss_orders = 1.493560791015625 | Accuracy = 69.66966966966966 | Accuracy_orders = 51.35135135135135 | Accuracy_mmap = 94.82835605284585\n","Val: Epoch = 116 | Loss 1.509339690208435 | Accuracy = 53.44827586206896\n","Train: Epoch = 117 | Loss = 2.4349554018540815 | Loss_orders = 1.9888379573822021 | Accuracy = 74.47447447447448 | Accuracy_orders = 53.153153153153156 | Accuracy_mmap = 94.63136605993749\n","Val: Epoch = 117 | Loss 1.5070707201957703 | Accuracy = 55.172413793103445\n","Train: Epoch = 118 | Loss = 2.473747730255127 | Loss_orders = 1.5254641771316528 | Accuracy = 71.77177177177178 | Accuracy_orders = 54.054054054054056 | Accuracy_mmap = 94.3538290477066\n","Val: Epoch = 118 | Loss 1.5072283148765564 | Accuracy = 56.03448275862068\n","Train: Epoch = 119 | Loss = 2.4926096851175483 | Loss_orders = 1.6464415788650513 | Accuracy = 74.77477477477478 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.91415613864594\n","Val: Epoch = 119 | Loss 1.5081846117973328 | Accuracy = 56.03448275862068\n","Train: Epoch = 120 | Loss = 2.536455262791027 | Loss_orders = 1.4488580226898193 | Accuracy = 70.27027027027027 | Accuracy_orders = 54.65465465465466 | Accuracy_mmap = 94.80209072045807\n","Val: Epoch = 120 | Loss 1.5065773129463196 | Accuracy = 55.172413793103445\n","Train: Epoch = 121 | Loss = 2.483264272863215 | Loss_orders = 1.0103625059127808 | Accuracy = 70.27027027027027 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.68739876903142\n","Val: Epoch = 121 | Loss 1.5074554085731506 | Accuracy = 55.172413793103445\n","Train: Epoch = 122 | Loss = 2.55753772908991 | Loss_orders = 1.9304726123809814 | Accuracy = 73.27327327327328 | Accuracy_orders = 49.849849849849846 | Accuracy_mmap = 95.08575631024611\n","Val: Epoch = 122 | Loss 1.5069515109062195 | Accuracy = 54.310344827586206\n","Train: Epoch = 123 | Loss = 2.563004407015714 | Loss_orders = 1.653171420097351 | Accuracy = 71.47147147147147 | Accuracy_orders = 54.35435435435435 | Accuracy_mmap = 94.57533335084356\n","Val: Epoch = 123 | Loss 1.5048415064811707 | Accuracy = 55.172413793103445\n","Train: Epoch = 124 | Loss = 2.460419015450911 | Loss_orders = 1.1112786531448364 | Accuracy = 72.37237237237237 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.74518250028454\n","Val: Epoch = 124 | Loss 1.504376471042633 | Accuracy = 55.172413793103445\n","Train: Epoch = 125 | Loss = 2.499728961424394 | Loss_orders = 2.050358295440674 | Accuracy = 73.27327327327328 | Accuracy_orders = 52.25225225225225 | Accuracy_mmap = 94.69965592414572\n","Val: Epoch = 125 | Loss 1.5060076713562012 | Accuracy = 55.172413793103445\n","Train: Epoch = 126 | Loss = 2.4960263642397793 | Loss_orders = 1.6595025062561035 | Accuracy = 72.97297297297297 | Accuracy_orders = 52.552552552552555 | Accuracy_mmap = 94.89577040597449\n","Val: Epoch = 126 | Loss 1.5094237327575684 | Accuracy = 55.172413793103445\n","Train: Epoch = 127 | Loss = 2.587101091038097 | Loss_orders = 1.8077902793884277 | Accuracy = 70.27027027027027 | Accuracy_orders = 48.64864864864865 | Accuracy_mmap = 94.59284357243541\n","Val: Epoch = 127 | Loss 1.5103473663330078 | Accuracy = 55.172413793103445\n","Train: Epoch = 128 | Loss = 2.527925664728338 | Loss_orders = 1.3952761888504028 | Accuracy = 72.37237237237237 | Accuracy_orders = 50.45045045045045 | Accuracy_mmap = 94.40023113492502\n","Val: Epoch = 128 | Loss 1.51146399974823 | Accuracy = 55.172413793103445\n","Train: Epoch = 129 | Loss = 2.413069725036621 | Loss_orders = 1.2624397277832031 | Accuracy = 70.27027027027027 | Accuracy_orders = 57.35735735735735 | Accuracy_mmap = 94.1717227431513\n","Val: Epoch = 129 | Loss 1.5141823291778564 | Accuracy = 55.172413793103445\n","Train: Epoch = 130 | Loss = 2.361401156945662 | Loss_orders = 0.9743010401725769 | Accuracy = 75.07507507507508 | Accuracy_orders = 57.95795795795796 | Accuracy_mmap = 94.7731988548315\n","Val: Epoch = 130 | Loss 1.514951467514038 | Accuracy = 55.172413793103445\n","Train: Epoch = 131 | Loss = 2.6409775994040747 | Loss_orders = 1.4936060905456543 | Accuracy = 72.37237237237237 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.66726201420079\n","Val: Epoch = 131 | Loss 1.5131672620773315 | Accuracy = 55.172413793103445\n","Train: Epoch = 132 | Loss = 2.4214568679982964 | Loss_orders = 1.017825961112976 | Accuracy = 72.97297297297297 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 94.9684378255807\n","Val: Epoch = 132 | Loss 1.5104353427886963 | Accuracy = 55.172413793103445\n","Train: Epoch = 133 | Loss = 2.60946588082747 | Loss_orders = 1.4288395643234253 | Accuracy = 71.17117117117117 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.78983356534377\n","Val: Epoch = 133 | Loss 1.5111387372016907 | Accuracy = 55.172413793103445\n","Train: Epoch = 134 | Loss = 2.3439088517969306 | Loss_orders = 1.0427769422531128 | Accuracy = 74.47447447447448 | Accuracy_orders = 57.65765765765766 | Accuracy_mmap = 94.44050464458627\n","Val: Epoch = 134 | Loss 1.513843297958374 | Accuracy = 55.172413793103445\n","Train: Epoch = 135 | Loss = 2.453124696558172 | Loss_orders = 1.1413496732711792 | Accuracy = 72.97297297297297 | Accuracy_orders = 52.25225225225225 | Accuracy_mmap = 94.84323974119893\n","Val: Epoch = 135 | Loss 1.5121760964393616 | Accuracy = 56.03448275862068\n","Train: Epoch = 136 | Loss = 2.3710558739575474 | Loss_orders = 1.5662615299224854 | Accuracy = 74.77477477477478 | Accuracy_orders = 57.35735735735735 | Accuracy_mmap = 94.39497806844746\n","Val: Epoch = 136 | Loss 1.5083903074264526 | Accuracy = 56.03448275862068\n","Train: Epoch = 137 | Loss = 2.42852981524034 | Loss_orders = 0.9966967701911926 | Accuracy = 70.27027027027027 | Accuracy_orders = 52.85285285285285 | Accuracy_mmap = 95.01221337956032\n","Val: Epoch = 137 | Loss 1.5081120729446411 | Accuracy = 55.172413793103445\n","Train: Epoch = 138 | Loss = 2.41465145891363 | Loss_orders = 0.9560715556144714 | Accuracy = 72.97297297297297 | Accuracy_orders = 56.45645645645646 | Accuracy_mmap = 94.4728985545312\n","Val: Epoch = 138 | Loss 1.5079922080039978 | Accuracy = 55.172413793103445\n","Train: Epoch = 139 | Loss = 2.2320766665718774 | Loss_orders = 1.242121934890747 | Accuracy = 78.37837837837837 | Accuracy_orders = 53.453453453453456 | Accuracy_mmap = 94.42737197839239\n","Val: Epoch = 139 | Loss 1.5078187584877014 | Accuracy = 55.172413793103445\n","Train: Epoch = 140 | Loss = 2.402238434011286 | Loss_orders = 1.0346760749816895 | Accuracy = 74.47447447447448 | Accuracy_orders = 55.85585585585585 | Accuracy_mmap = 94.9045255167704\n","Val: Epoch = 140 | Loss 1.5055501461029053 | Accuracy = 56.03448275862068\n","Train: Epoch = 141 | Loss = 2.5022657459432427 | Loss_orders = 1.0878127813339233 | Accuracy = 69.96996996996997 | Accuracy_orders = 53.753753753753756 | Accuracy_mmap = 94.83098258608462\n","Val: Epoch = 141 | Loss 1.5054340362548828 | Accuracy = 56.03448275862068\n","Train: Epoch = 142 | Loss = 2.7063643715598364 | Loss_orders = 1.0429203510284424 | Accuracy = 67.86786786786787 | Accuracy_orders = 52.552552552552555 | Accuracy_mmap = 94.69615387982735\n","Val: Epoch = 142 | Loss 1.5059248805046082 | Accuracy = 56.03448275862068\n","Train: Epoch = 143 | Loss = 2.5800395878878506 | Loss_orders = 1.3203390836715698 | Accuracy = 67.56756756756756 | Accuracy_orders = 57.65765765765766 | Accuracy_mmap = 94.55344557385374\n","Val: Epoch = 143 | Loss 1.5055091977119446 | Accuracy = 56.03448275862068\n","Train: Epoch = 144 | Loss = 2.540962891145186 | Loss_orders = 1.6136291027069092 | Accuracy = 70.87087087087087 | Accuracy_orders = 51.051051051051054 | Accuracy_mmap = 94.89139285057652\n","Val: Epoch = 144 | Loss 1.5066195726394653 | Accuracy = 56.03448275862068\n","Train: Epoch = 145 | Loss = 2.521804029291326 | Loss_orders = 1.6644502878189087 | Accuracy = 71.17117117117117 | Accuracy_orders = 51.95195195195195 | Accuracy_mmap = 94.52542921930677\n","Val: Epoch = 145 | Loss 1.5087975859642029 | Accuracy = 56.03448275862068\n","Train: Epoch = 146 | Loss = 2.472981322895397 | Loss_orders = 1.33324134349823 | Accuracy = 69.66966966966966 | Accuracy_orders = 54.65465465465466 | Accuracy_mmap = 94.51754961959044\n","Val: Epoch = 146 | Loss 1.5086862444877625 | Accuracy = 56.896551724137936\n","Train: Epoch = 147 | Loss = 2.409337347204035 | Loss_orders = 0.8417602181434631 | Accuracy = 75.07507507507508 | Accuracy_orders = 50.150150150150154 | Accuracy_mmap = 94.72854778977228\n","Val: Epoch = 147 | Loss 1.509754240512848 | Accuracy = 56.896551724137936\n","Train: Epoch = 148 | Loss = 2.346553824164651 | Loss_orders = 1.0130623579025269 | Accuracy = 73.57357357357357 | Accuracy_orders = 49.249249249249246 | Accuracy_mmap = 94.79158458750295\n","Val: Epoch = 148 | Loss 1.510641634464264 | Accuracy = 55.172413793103445\n","Train: Epoch = 149 | Loss = 2.5457816340706567 | Loss_orders = 1.1970819234848022 | Accuracy = 71.17117117117117 | Accuracy_orders = 45.94594594594595 | Accuracy_mmap = 95.22146052758298\n","Val: Epoch = 149 | Loss 1.5119312405586243 | Accuracy = 54.310344827586206\n","Train: Epoch = 150 | Loss = 2.64297797463157 | Loss_orders = 1.2102515697479248 | Accuracy = 69.06906906906907 | Accuracy_orders = 48.348348348348345 | Accuracy_mmap = 94.5814619284007\n","Val: Epoch = 150 | Loss 1.5102080702781677 | Accuracy = 55.172413793103445\n","Best accuracy after 149 epochs = 59.48275862068966\n"],"name":"stdout"}]}]}